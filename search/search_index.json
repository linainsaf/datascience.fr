{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Introduction \u00e0 la Data Science","text":""},{"location":"#cest-quoi-la-data-science","title":"C'est quoi la Data Science","text":"<p>La data science est un domaine qui s'int\u00e9resse \u00e0 l'extraction de connaissances \u00e0 partir de donn\u00e9es. Il utilise des techniques statistiques, math\u00e9matiques et informatiques pour analyser, interpr\u00e9ter et mod\u00e9liser des donn\u00e9es.</p> <p></p> <p></p> <p>La data science est utilis\u00e9e dans plusieurs domaines tels que la finance, la sant\u00e9, la vente au d\u00e9tail, le marketing, les transports et bien d'autres. C'est devenu de plus en plus important \u00e0 mesure que la quantit\u00e9 de donn\u00e9es g\u00e9n\u00e9r\u00e9es par la technologie moderne continue de cro\u00eetre.</p> <p></p> <p></p>"},{"location":"#les-differentes-etapes-dun-projet-de-data-science","title":"Les diff\u00e9rentes \u00e9tapes d'un projet de Data Science","text":""},{"location":"#collecte-de-donnees","title":"Collecte de donn\u00e9es","text":"<p>Le premier pas dans le processus de data science est de collecter des donn\u00e9es. Les donn\u00e9es peuvent provenir de diff\u00e9rentes sources telles que des fichiers, des bases de donn\u00e9es, des capteurs, des sondages, des enregistrements de transactions, des images, etc. Il est important de choisir des donn\u00e9es de qualit\u00e9 qui sont pertinentes pour le probl\u00e8me que vous souhaitez r\u00e9soudre.</p> <p></p> <p>Par exemple, pour pr\u00e9dire si un client d'une entreprise va acheter un produit, vous pouvez collecter des donn\u00e9es sur les achats pass\u00e9s, les pr\u00e9f\u00e9rences de produits, les habitudes de navigation en ligne, les interactions avec la marque sur les r\u00e9seaux sociaux, etc.</p>"},{"location":"#exploration-des-donnees","title":"Exploration des donn\u00e9es","text":"<p>Une fois les donn\u00e9es collect\u00e9es, il est important de les explorer pour comprendre leur nature, leur qualit\u00e9 et leur contenu. Cette \u00e9tape permet de d\u00e9tecter les valeurs manquantes, les donn\u00e9es aberrantes, les corr\u00e9lations, les distributions, etc. Cela peut se faire en utilisant des outils statistiques et graphiques.</p> <p></p> <p>Par exemple, pour comprendre les habitudes d'achat des clients, vous pouvez visualiser la distribution des prix d'achat, la corr\u00e9lation entre l'\u00e2ge et le montant d'achat, ou encore la fr\u00e9quence d'achat selon le canal de vente.</p>"},{"location":"#types-de-donnees","title":"Types de donn\u00e9es","text":"<p>Les donn\u00e9es sont le fondement de la data science, et elles peuvent \u00eatre de diff\u00e9rents types. Comprendre la nature des donn\u00e9es est important pour choisir les m\u00e9thodes d'analyse appropri\u00e9es.</p>"},{"location":"#donnees-numeriques","title":"Donn\u00e9es num\u00e9riques","text":"<p>Les donn\u00e9es num\u00e9riques sont des nombres, et peuvent \u00eatre continues ou discr\u00e8tes. Les donn\u00e9es continues peuvent prendre n'importe quelle valeur dans un intervalle donn\u00e9, tandis que les donn\u00e9es discr\u00e8tes sont limit\u00e9es \u00e0 des valeurs enti\u00e8res. Les donn\u00e9es num\u00e9riques peuvent \u00eatre utilis\u00e9es pour mesurer des grandeurs physiques, financi\u00e8res, ou pour quantifier des caract\u00e9ristiques. Exemples :</p> <ul> <li>La temp\u00e9rature en degr\u00e9s Celsius est une donn\u00e9e num\u00e9rique continue.</li> <li>Le nombre de produits vendus est une donn\u00e9e num\u00e9rique discr\u00e8te.</li> <li>Le montant d'une transaction financi\u00e8re est une donn\u00e9e num\u00e9rique continue.</li> </ul>"},{"location":"#donnees-categorielles","title":"Donn\u00e9es cat\u00e9gorielles","text":"<p>Les donn\u00e9es cat\u00e9gorielles sont des valeurs qui peuvent \u00eatre regroup\u00e9es en cat\u00e9gories. Elles peuvent \u00eatre nominales ou ordinales. Les donn\u00e9es cat\u00e9gorielles sont souvent utilis\u00e9es pour d\u00e9crire des caract\u00e9ristiques qualitatives. Exemples :</p> <ul> <li>La couleur des yeux est une donn\u00e9e cat\u00e9gorielle nominale.</li> <li>La taille des v\u00eatements est une donn\u00e9e cat\u00e9gorielle ordinale.</li> <li>La marque d'un produit est une donn\u00e9e cat\u00e9gorielle nominale.</li> </ul>"},{"location":"#donnees-temporelles","title":"Donn\u00e9es temporelles","text":"<p>Les donn\u00e9es temporelles sont des valeurs qui d\u00e9crivent des moments dans le temps. Elles peuvent \u00eatre des instants pr\u00e9cis, des p\u00e9riodes, ou des fr\u00e9quences. Les donn\u00e9es temporelles sont souvent utilis\u00e9es pour analyser des ph\u00e9nom\u00e8nes qui \u00e9voluent dans le temps. Exemples :</p> <ul> <li>La date de naissance est une donn\u00e9e temporelle de type instant.</li> <li>La dur\u00e9e d'une p\u00e9riode de vente est une donn\u00e9e temporelle de type p\u00e9riode.</li> <li>La fr\u00e9quence d'achat est une donn\u00e9e temporelle de type fr\u00e9quence.</li> </ul>"},{"location":"#donnees-textuelles","title":"Donn\u00e9es textuelles","text":"<p>Les donn\u00e9es textuelles sont des valeurs qui d\u00e9crivent du texte. Elles peuvent \u00eatre des phrases, des paragraphes, ou des documents entiers. Les donn\u00e9es textuelles sont souvent utilis\u00e9es pour analyser le langage naturel, ou pour extraire des informations de textes non structur\u00e9s. Exemples :</p> <ul> <li>Les avis des clients sur un produit sont des donn\u00e9es textuelles.</li> <li>Les descriptions des produits dans un catalogue sont des donn\u00e9es textuelles.</li> <li>Les articles de journaux sont des donn\u00e9es textuelles.</li> </ul>"},{"location":"#donnees-geospatiales","title":"Donn\u00e9es g\u00e9ospatiales","text":"<p>Les donn\u00e9es g\u00e9ospatiales sont des valeurs qui d\u00e9crivent des positions dans l'espace. Elles peuvent \u00eatre des coordonn\u00e9es g\u00e9ographiques, des adresses, ou des noms de lieux. Les donn\u00e9es g\u00e9ospatiales sont souvent utilis\u00e9es pour cartographier des donn\u00e9es, ou pour analyser des ph\u00e9nom\u00e8nes qui varient dans l'espace. Exemples :</p> <ul> <li>Les adresses des clients sont des donn\u00e9es g\u00e9ospatiales.</li> <li>Les coordonn\u00e9es GPS d'un point de vente sont des donn\u00e9es g\u00e9ospatiales.</li> <li>Les noms de villes dans un tableau de donn\u00e9es sont des donn\u00e9es g\u00e9ospatiales.</li> </ul>"},{"location":"#donnees-en-images","title":"Donn\u00e9es en images","text":"<p>Les donn\u00e9es en images sont des valeurs qui d\u00e9crivent des images. Elles sont souvent stock\u00e9es sous forme de pixels qui repr\u00e9sentent les couleurs ou les niveaux de gris des diff\u00e9rents points de l'image. Les donn\u00e9es en images sont souvent utilis\u00e9es dans des applications telles que la reconnaissance d'objets, la d\u00e9tection de fraudes et la surveillance. Exemples :</p> <ul> <li>Les images m\u00e9dicales sont des donn\u00e9es en images, comme les radiographies et les IRM.</li> <li>Les images satellites sont des donn\u00e9es en images qui peuvent \u00eatre utilis\u00e9es pour cartographier les zones g\u00e9ographiques et surveiller les changements dans les environnements naturels.</li> <li>Les images de surveillance de la circulation routi\u00e8re sont des donn\u00e9es en images qui peuvent \u00eatre utilis\u00e9es pour d\u00e9tecter les violations du code de la route.</li> </ul>"},{"location":"#donnees-en-audio","title":"Donn\u00e9es en audio","text":"<p>Les donn\u00e9es en audio sont des valeurs qui d\u00e9crivent des enregistrements sonores. Elles peuvent \u00eatre stock\u00e9es sous forme de signaux num\u00e9riques qui repr\u00e9sentent la fr\u00e9quence et l'amplitude du son \u00e0 diff\u00e9rents moments. Les donn\u00e9es en audio sont souvent utilis\u00e9es dans des applications telles que la reconnaissance vocale, la d\u00e9tection de fraudes et la surveillance. Exemples :</p> <ul> <li>Les enregistrements de voix sont des donn\u00e9es en audio qui peuvent \u00eatre utilis\u00e9es pour la reconnaissance vocale, telle que la conversion de la parole en texte.</li> <li>Les enregistrements de musique sont des donn\u00e9es en audio qui peuvent \u00eatre utilis\u00e9es pour la recommandation de musique et la classification de genres musicaux.</li> <li>Les enregistrements de surveillance audio sont des donn\u00e9es en audio qui peuvent \u00eatre utilis\u00e9es pour d\u00e9tecter les menaces et les comportements suspects.</li> </ul> <p>En tant que data scientist, il est important de comprendre les diff\u00e9rents types de donn\u00e9es, car cela peut avoir une incidence sur les m\u00e9thodes de collecte, de stockage, de traitement et d'analyse. En fonction des donn\u00e9es, les algorithmes de machine learning et les outils d'analyse peuvent varier consid\u00e9rablement.</p>"},{"location":"#selection-de-caracteristiques","title":"S\u00e9lection de caract\u00e9ristiques","text":"<p>Si le nombre de caract\u00e9ristiques est tr\u00e8s \u00e9lev\u00e9, il peut \u00eatre judicieux de s\u00e9lectionner les caract\u00e9ristiques les plus importantes pour am\u00e9liorer l'efficacit\u00e9 du mod\u00e8le.</p>"},{"location":"#separation-des-donnees","title":"S\u00e9paration des donn\u00e9es","text":"<p>Les donn\u00e9es doivent \u00eatre divis\u00e9es en deux parties, l'ensemble d'entra\u00eenement et l'ensemble de test. L'ensemble d'entra\u00eenement est utilis\u00e9 pour entra\u00eener le mod\u00e8le et l'ensemble de test est utilis\u00e9 pour \u00e9valuer les performances du mod\u00e8le.</p>"},{"location":"#construction-de-notre-modele-ia","title":"Construction de notre mod\u00e8le (IA)","text":"<p>Une fois les donn\u00e9es nettoy\u00e9es et pr\u00e9trait\u00e9es, il est temps de choisir un mod\u00e8le d'IA et de l'entra\u00eener sur l'ensemble d'entra\u00eenement. Le choix du mod\u00e8le d\u00e9pend du type de probl\u00e8me \u00e0 r\u00e9soudre et du type de donn\u00e9es.</p> <p></p> <p>L'intelligence artificielle (IA) est un domaine de l'informatique qui vise \u00e0 cr\u00e9er des machines capables de r\u00e9aliser des t\u00e2ches qui n\u00e9cessitent normalement l'intelligence humaine. Cette discipline est bas\u00e9e sur le d\u00e9veloppement de programmes informatiques qui peuvent apprendre et s'adapter \u00e0 de nouvelles situations, et ainsi ex\u00e9cuter des t\u00e2ches sans intervention humaine.</p> <p></p> <p>Il existe plusieurs modes d'apprentissage :</p> <ul> <li> <p>Le Machine Learning (apprentissage automatique en fran\u00e7ais) est une branche de l'intelligence artificielle qui se concentre sur l'apprentissage de mod\u00e8les \u00e0 partir de donn\u00e9es, afin de r\u00e9aliser des t\u00e2ches de pr\u00e9diction ou de classification. Les mod\u00e8les peuvent \u00eatre entra\u00een\u00e9s \u00e0 l'aide de diff\u00e9rentes techniques, notamment l'apprentissage supervis\u00e9 (o\u00f9 les donn\u00e9es sont \u00e9tiquet\u00e9es pour indiquer la r\u00e9ponse souhait\u00e9e) et l'apprentissage non supervis\u00e9 (o\u00f9 les donn\u00e9es ne sont pas \u00e9tiquet\u00e9es). Le Machine Learning est utilis\u00e9 dans de nombreux domaines, notamment la reconnaissance vocale, la reconnaissance d'images, la recommandation de produits et la d\u00e9tection de fraudes.</p> </li> <li> <p>Le Reinforcement Learning (apprentissage par renforcement en fran\u00e7ais) est une branche sp\u00e9cifique du Machine Learning qui se concentre sur l'apprentissage par essais et erreurs. Dans ce type d'apprentissage, un agent est plac\u00e9 dans un environnement et doit apprendre \u00e0 prendre des d\u00e9cisions pour maximiser une r\u00e9compense. L'agent prend une action, re\u00e7oit une r\u00e9compense ou une p\u00e9nalit\u00e9, et utilise cette information pour ajuster sa strat\u00e9gie. Le Reinforcement Learning est utilis\u00e9 pour des applications comme les jeux vid\u00e9o, les robots, et les syst\u00e8mes de recommandation personnalis\u00e9e.</p> </li> <li> <p>Le Deep Learning (apprentissage profond en fran\u00e7ais) est une sous-branche du Machine Learning qui utilise des r\u00e9seaux de neurones artificiels pour apprendre \u00e0 partir de donn\u00e9es. Les r\u00e9seaux de neurones artificiels sont des mod\u00e8les computationnels qui sont con\u00e7us pour imiter le fonctionnement du cerveau humain. Les r\u00e9seaux de neurones sont compos\u00e9s de plusieurs couches, chacune traitant une partie de l'information en entr\u00e9e pour produire une sortie. Le Deep Learning est utilis\u00e9 dans de nombreux domaines, notamment la reconnaissance vocale, la reconnaissance d'images, la traduction automatique et la reconnaissance de caract\u00e8res manuscrits.</p> </li> </ul>"},{"location":"#evaluation-du-modele","title":"\u00c9valuation du mod\u00e8le","text":"<p>Apr\u00e8s l'entra\u00eenement du mod\u00e8le, il est important d'\u00e9valuer sa performance sur l'ensemble de test. Il existe de nombreuses mesures pour \u00e9valuer les performances d'un mod\u00e8le, telles que l'exactitude, la pr\u00e9cision, le rappel et le F1-score.</p>"},{"location":"#optimisation-du-modele","title":"Optimisation du mod\u00e8le","text":"<p>Si les performances du mod\u00e8le ne sont pas satisfaisantes, il peut \u00eatre n\u00e9cessaire de le r\u00e9ajuster ou de r\u00e9gler ses param\u00e8tres pour am\u00e9liorer ses performances.</p>"},{"location":"#deploiement-du-modele","title":"D\u00e9ploiement du mod\u00e8le","text":"<p>Une fois que le mod\u00e8le a \u00e9t\u00e9 entra\u00een\u00e9 et \u00e9valu\u00e9 avec succ\u00e8s, il peut \u00eatre d\u00e9ploy\u00e9 dans un environnement de production. Cela peut inclure l'int\u00e9gration du mod\u00e8le dans une application ou un syst\u00e8me existant.</p>"},{"location":"api/","title":"API (Application Programmable Interface)","text":""},{"location":"api/#api-application-programming-interface","title":"API (Application Programming Interface)","text":""},{"location":"api/#cest-quoi","title":"C'est quoi ?","text":"<p>API (Application Programmable Interface) est un ensemble de fonctions permettant d'utiliser les services d\u2019une application. Une API est peut \u00eatre distribu\u00e9 localement dans un programme informatique (accessible uniquement par un algorithme), ou au contraire peut avoir vocation a \u00eatre utilis\u00e9e par un plus grand nombre d'acteurs.</p> <p></p> <p>Il y a diff\u00e9rents type d'API. Dans ce cours, nous nous int\u00e9ressons surtout au API Web, c'est-\u00e0-dire celles qui permettent de fournir une interface accessible en ligne. Cela est le cas lorsque l'on effectue une requ\u00eate \u00e0 un serveur afin que l'on re\u00e7oive le r\u00e9sultat d'un traitement.</p>"},{"location":"api/#les-api-restful","title":"Les API RESTful","text":"<p>Une API RESTful (Representational State Transfer) est une architecture d'API Web qui repose sur le protocole HTTP et qui utilise ses m\u00e9thodes (GET, POST, PUT, DELETE) pour permettre aux clients de communiquer avec les serveurs et de r\u00e9cup\u00e9rer des donn\u00e9es. Les API RESTful sont largement utilis\u00e9es dans les applications Web et mobiles pour fournir une interface standardis\u00e9e et facile \u00e0 utiliser pour acc\u00e9der aux donn\u00e9es.</p> <p></p> <p></p> <p></p> <p>Voici les principaux concepts de l'architecture RESTful :</p> <p></p> <ul> <li> <p>Ressources : les ressources sont les entit\u00e9s expos\u00e9es par l'API, telles que les utilisateurs, les produits, les commandes, etc.</p> </li> <li> <p>Verbes HTTP : les verbes HTTP (GET, POST, PUT, DELETE) sont utilis\u00e9s pour d\u00e9crire les op\u00e9rations sur les ressources. Le verbe GET est utilis\u00e9 pour r\u00e9cup\u00e9rer une ressource, POST pour cr\u00e9er une nouvelle ressource, PUT pour mettre \u00e0 jour une ressource existante et DELETE pour supprimer une ressource.</p> </li> <li> <p>Les routes : Les routes dans une RESTful API sont des points d'entr\u00e9e sp\u00e9cifiques dans l'API qui d\u00e9finissent les op\u00e9rations disponibles et les ressources accessibles. Une route est g\u00e9n\u00e9ralement un URI (Uniform Resource Identifier) qui identifie de mani\u00e8re unique une ressource et une m\u00e9thode HTTP qui sp\u00e9cifie l'action \u00e0 effectuer sur cette ressource.</p> </li> <li> <p>Repr\u00e9sentations : les repr\u00e9sentations sont les formats de donn\u00e9es utilis\u00e9s pour repr\u00e9senter les ressources, tels que JSON, XML, ou YAML. Le format le plus couramment utilis\u00e9 est le JSON (JavaScript Object Notation), car il est l\u00e9ger, facile \u00e0 lire et \u00e0 \u00e9crire.</p> </li> <li> <p>Les codes de r\u00e9ponse HTTP : les codes de r\u00e9ponse HTTP sont utilis\u00e9s pour indiquer le r\u00e9sultat d'une op\u00e9ration sur une ressource. Par exemple, le code 200 indique que la demande a \u00e9t\u00e9 trait\u00e9e avec succ\u00e8s, le code 201 indique que la ressource a \u00e9t\u00e9 cr\u00e9\u00e9e avec succ\u00e8s, le code 404 indique que la ressource n'a pas \u00e9t\u00e9 trouv\u00e9e, etc.</p> </li> </ul> <p>En utilisant ces concepts, une API RESTful peut fournir une interface simple, coh\u00e9rente et facile \u00e0 utiliser pour acc\u00e9der aux donn\u00e9es et aux services d'un serveur. Les clients peuvent utiliser des requ\u00eates HTTP standard pour acc\u00e9der aux ressources et interagir avec le serveur, ce qui rend l'API RESTful tr\u00e8s flexible et facile \u00e0 int\u00e9grer dans des applications Web et mobiles.</p>"},{"location":"api/#flask","title":"Flask","text":"<p>Flask est une biblioth\u00e8que Python qui permet de cr\u00e9er des applications Web et des API RESTful. Voici un exemple de code pour cr\u00e9er une API RESTful simple avec Flask :</p> <pre><code>\nfrom flask import Flask, jsonify, request\n\napp = Flask(__name__)\n\n# D\u00e9finition de quelques donn\u00e9es pour notre API\nstudents = [\n    {\n        'id': 1,\n        'name': 'Alice',\n        'age': 20\n    },\n    {\n        'id': 2,\n        'name': 'Bob',\n        'age': 22\n    },\n    {\n        'id': 3,\n        'name': 'Charlie',\n        'age': 21\n    }\n]\n\n# Route pour r\u00e9cup\u00e9rer tous les \u00e9tudiants\n@app.route('/students', methods=['GET'])\ndef get_students():\n    return jsonify(students)\n\n# Route pour r\u00e9cup\u00e9rer un \u00e9tudiant en particulier\n@app.route('/students/&lt;int:id&gt;', methods=['GET'])\ndef get_student(id):\n    student = [student for student in students if student['id'] == id]\n    return jsonify(student)\n\n# Route pour cr\u00e9er un nouvel \u00e9tudiant\n@app.route('/students', methods=['POST'])\ndef create_student():\n    student = {\n        'id': request.json['id'],\n        'name': request.json['name'],\n        'age': request.json['age']\n    }\n    students.append(student)\n    return jsonify(student)\n\n# Route pour mettre \u00e0 jour un \u00e9tudiant existant\n@app.route('/students/&lt;int:id&gt;', methods=['PUT'])\ndef update_student(id):\n    student = [student for student in students if student['id'] == id]\n    student[0]['name'] = request.json.get('name', student[0]['name'])\n    student[0]['age'] = request.json.get('age', student[0]['age'])\n    return jsonify(student[0])\n\n# Route pour supprimer un \u00e9tudiant existant\n@app.route('/students/&lt;int:id&gt;', methods=['DELETE'])\ndef delete_student(id):\n    student = [student for student in students if student['id'] == id]\n    students.remove(student[0])\n    return jsonify({'result': True})\n\n# Lancement de l'application Flask\nif __name__ == '__main__':\n    app.run(debug=True)\n</code></pre> <p>Dans cet exemple, nous avons cr\u00e9\u00e9 une API RESTful simple qui permet de r\u00e9cup\u00e9rer, cr\u00e9er, mettre \u00e0 jour et supprimer des \u00e9tudiants. Nous avons utilis\u00e9 les d\u00e9corateurs @app.route pour d\u00e9finir les diff\u00e9rentes routes de notre API, ainsi que les m\u00e9thodes HTTP correspondantes (GET, POST, PUT, DELETE). Nous avons \u00e9galement utilis\u00e9 la fonction jsonify de Flask pour retourner des donn\u00e9es JSON \u00e0 partir de notre API.</p> <p></p> <p>Pour tester notre API, nous pouvons utiliser un outil comme Postman ou simplement effectuer des requ\u00eates HTTP en utilisant l'URL de notre API (par exemple http://localhost:5000/students pour r\u00e9cup\u00e9rer tous les \u00e9tudiants).</p>"},{"location":"dl/","title":"Introduction au Deep Learning","text":""},{"location":"dl/#cest-quoi-le-deep-learning","title":"C'est quoi le Deep Learning","text":"<p>Le Deep Learning est une sous-branche du Machine Learning qui utilise des r\u00e9seaux de neurones profonds pour apprendre des repr\u00e9sentations hi\u00e9rarchiques de donn\u00e9es complexes. Contrairement au Machine Learning classique, qui se concentre sur l'extraction de caract\u00e9ristiques manuellement con\u00e7ues \u00e0 partir de donn\u00e9es, le Deep Learning permet aux mod\u00e8les d'apprendre automatiquement \u00e0 partir de donn\u00e9es brutes sans la n\u00e9cessit\u00e9 d'ing\u00e9nierie de caract\u00e9ristiques.</p> <p></p> <p>Les avantages du Deep Learning incluent :</p> <ul> <li>Performance am\u00e9lior\u00e9e : Les mod\u00e8les de Deep Learning peuvent apprendre \u00e0 partir de donn\u00e9es brutes et trouver des caract\u00e9ristiques importantes pour une t\u00e2che donn\u00e9e, ce qui peut conduire \u00e0 des performances am\u00e9lior\u00e9es sur une grande vari\u00e9t\u00e9 de t\u00e2ches, y compris la vision par ordinateur, la reconnaissance vocale et le traitement du langage naturel.</li> <li>Scalabilit\u00e9 : Les r\u00e9seaux de neurones profonds peuvent \u00eatre con\u00e7us pour traiter des donn\u00e9es massives et peuvent \u00eatre utilis\u00e9s dans des environnements distribu\u00e9s pour am\u00e9liorer encore les performances.</li> <li>Adaptabilit\u00e9 : Les mod\u00e8les de Deep Learning peuvent \u00eatre adapt\u00e9s \u00e0 de nouveaux jeux de donn\u00e9es sans avoir besoin de modifications majeures de l'architecture du mod\u00e8le, ce qui les rend plus flexibles et adaptables que les mod\u00e8les de Machine Learning classiques.</li> </ul> <p>Cependant, le Deep Learning pr\u00e9sente \u00e9galement quelques inconv\u00e9nients, notamment :</p> <ul> <li> <p>Co\u00fbt en ressources : L'entra\u00eenement de mod\u00e8les de Deep Learning peut \u00eatre tr\u00e8s co\u00fbteux en temps et en ressources informatiques, en particulier pour des jeux de donn\u00e9es massifs. L'inf\u00e9rence peut \u00e9galement \u00eatre co\u00fbteuse, en particulier sur des dispositifs mobiles ou des syst\u00e8mes embarqu\u00e9s.</p> </li> <li> <p>Manque de transparence : Les mod\u00e8les de Deep Learning peuvent \u00eatre difficiles \u00e0 interpr\u00e9ter, car ils sont souvent con\u00e7us avec des couches cach\u00e9es qui rendent difficile la compr\u00e9hension de la mani\u00e8re dont le mod\u00e8le prend des d\u00e9cisions. Cela peut rendre le d\u00e9beugage et le d\u00e9pannage plus difficiles.</p> </li> <li> <p>Besoin de donn\u00e9es de haute qualit\u00e9 : Les mod\u00e8les de Deep Learning n\u00e9cessitent souvent des ensembles de donn\u00e9es massifs et de haute qualit\u00e9 pour obtenir des performances optimales. Cela peut rendre l'entra\u00eenement de mod\u00e8les de Deep Learning difficile pour les domaines o\u00f9 les donn\u00e9es sont rares ou co\u00fbteuses \u00e0 collecter.</p> </li> </ul>"},{"location":"dl/#cest-quoi-un-neurone","title":"C'est quoi un Neurone","text":"<p>Un neurone est la plus petite unit\u00e9 de traitement dans un r\u00e9seau de neurones. Il re\u00e7oit des entr\u00e9es pond\u00e9r\u00e9es, les somme et les passe \u00e0 travers une fonction d'activation non-lin\u00e9aire pour produire une sortie. Les poids sont des param\u00e8tres qui sont ajust\u00e9s par le mod\u00e8le pendant l'apprentissage pour minimiser une fonction de co\u00fbt.</p> <p></p>"},{"location":"dl/#cest-quoi-les-couches-de-neurones","title":"C'est quoi les couches de Neurones","text":"<p>Pour un probl\u00e8me non lin\u00e9aire ou utilise des couches. Une couche de neurones est un groupe de neurones qui traitent simultan\u00e9ment les entr\u00e9es qu'ils re\u00e7oivent. Les couches de neurones sont g\u00e9n\u00e9ralement organis\u00e9es en s\u00e9quences, avec chaque couche prenant en entr\u00e9e les sorties de la couche pr\u00e9c\u00e9dente. On peut distingue distinguer deux blocs de couches : </p> <ul> <li>Une ou plusieurs couches cach\u00e9es compos\u00e9es de plusieurs neurones</li> <li>Une couche de sortie compos\u00e9e de K neurones \\(y = [y_1, ...,y_k]\\)</li> </ul> <p></p> <ul> <li> <p>En r\u00e9gression: Sortie continue/un seule neurone =&gt; la derni\u00e9re couche a une fonction d'activation lin\u00e9aire</p> </li> <li> <p>En classification: La derniere couche a K neurones (K = Nombre de classes) =&gt; La derni\u00e8re couche a une fonction d'activation softmax qui transforme la sortie du r\u00e9seau en probabilit\u00e9s d'appartenance aux classes.</p> </li> </ul>"},{"location":"dl/#cest-quoi-les-fonctions-dactivation","title":"C'est quoi les fonctions d'activation","text":"<p>Une fonction d\u2019activation est une fonction math\u00e9matique utilis\u00e9 sur un signal. Elle va reproduire le potentiel d\u2019activation que l\u2019on retrouve dans le domaine de la biologie du cerveau humain. Elle va permettre le passage d\u2019information ou non de l\u2019information si le seuil de stimulation est atteint. Concr\u00e8tement, elle va avoir pour r\u00f4le de d\u00e9cider si on active ou non une r\u00e9ponse du neurone. Voici les principales fonctions d\u2019activations que l\u2019on peut trouver dans des r\u00e9seaux de neurones :</p> <ul> <li> <p>Linear: Utilis\u00e9 en couche de sortie pour une utilisation pour une r\u00e9gression. On peut la caract\u00e9riser de nulle, puisque les unit\u00e9s de sortie seront identiques \u00e0 leur niveau d\u2019entr\u00e9. Intervalle de sortie (-\u221e;+\u221e).</p> </li> <li> <p>Sigmoid (logistic) : Fonction la plus populaire depuis des d\u00e9cennies. Mais aujourd\u2019hui, elle devient beaucoup moins efficace par rapport \u00e0 d\u2019autre pour une utilisation pour les couches cach\u00e9es. Utilis\u00e9 en couche de sortie pour de la classification binaire. Intervalle de sortie : {0,1}</p> </li> <li> <p>TanH : Utilis\u00e9 pour des RNN pour des donn\u00e9es en continue. Intervalle de sortie : (-1,1)</p> </li> <li> <p>Softmax : Utilis\u00e9 pour de la multi classification en couche de sortie. Intervalle de sortie (-\u221e;+\u221e).</p> </li> <li> <p>ReLU ( Rectified Linear Unit ) : Ce sont les fonctions les plus populaires de nos jours. Elles permettent un entrainement plus rapide compar\u00e9 aux fonctions sigmoid et tanh, \u00e9tant plus l\u00e9g\u00e8res. Attention au ph\u00e9nom\u00e8ne de \u2018Dying ReLU\u2019, auquel on pr\u00e9f\u00e9rera les variations de ReLU. Tr\u00e8s utilis\u00e9 pour les CNN, RBM, et les r\u00e9seaux de multi perceptron. Intervalle de sortie (0;+\u221e).</p> </li> <li> <p>Leaky ReLU : La Leakey Relu permet d\u2019ajouter une variante pour les nombres n\u00e9gatifs, ainsi les neurones ne meurent jamais. Ils entrent dans un long coma mais on toujours la chance de se r\u00e9veiller \u00e0 un moment donn\u00e9. Intervalle de sortie (-\u221e;+\u221e).</p> </li> </ul> <p></p>"},{"location":"dl/#cest-quoi-la-backpropagation-comment-un-reseau-sentraine","title":"C'est quoi la backpropagation (Comment un r\u00e9seau s'entraine)","text":"<p>La r\u00e9tropropagation (backpropagation en anglais) est l'algorithme d'optimisation utilis\u00e9 pour entra\u00eener les r\u00e9seaux de neurones. Il s'agit d'une m\u00e9thode de calcul de gradient qui permet de calculer les gradients de l'erreur par rapport aux poids de chaque neurone dans le r\u00e9seau, en utilisant la r\u00e8gle de la cha\u00eene.</p> <p></p> <p>Le processus de r\u00e9tropropagation commence par une \u00e9tape de propagation avant (forward pass) dans laquelle les entr\u00e9es sont pr\u00e9sent\u00e9es au r\u00e9seau et les pr\u00e9dictions sont calcul\u00e9es en passant successivement \u00e0 travers chaque couche du r\u00e9seau.</p> <p></p> <p>Ensuite, l'erreur de pr\u00e9diction est calcul\u00e9e en comparant les pr\u00e9dictions du r\u00e9seau aux valeurs r\u00e9elles de sortie. L'objectif de l'apprentissage est de minimiser cette erreur.</p> <p></p> <p>\u00c0 partir de l'erreur de pr\u00e9diction, la r\u00e9tropropagation calcule le gradient de l'erreur par rapport \u00e0 chaque poids dans le r\u00e9seau, en utilisant la r\u00e8gle de la cha\u00eene pour calculer les gradients \u00e0 travers les couches du r\u00e9seau en partant de la derni\u00e8re couche vers la premi\u00e8re.</p> <p></p> <p>Une fois que les gradients ont \u00e9t\u00e9 calcul\u00e9s, ils peuvent \u00eatre utilis\u00e9s pour ajuster les poids dans le r\u00e9seau en utilisant une m\u00e9thode d'optimisation telle que la descente de gradient stochastique (SGD en anglais).</p> <p></p> <p>L'ensemble du processus de r\u00e9tropropagation est r\u00e9p\u00e9t\u00e9 de nombreuses fois, en pr\u00e9sentant diff\u00e9rentes donn\u00e9es d'entra\u00eenement au r\u00e9seau \u00e0 chaque it\u00e9ration, jusqu'\u00e0 ce que le r\u00e9seau converge vers une solution qui minimise l'erreur de pr\u00e9diction moyenne sur l'ensemble des donn\u00e9es d'entra\u00eenement.</p> <p></p> <p>Terminologie : </p> <ul> <li>Batch : sous ensemble de la base train</li> <li>Epoch : nombre de fois que tous les exemples sont vus en apprentissage</li> <li>It\u00e9ration : nombre de batchs vus en apprentissage</li> </ul>"},{"location":"dl/#comprendre-loverfitting-et-underfitting","title":"Comprendre l'overfitting et underfitting","text":"<p>On souhaite avoir un r\u00e9seau qui puisse effectuer des pr\u00e9dictions sur de nouvelles donn\u00e9es. Selon la fa\u00e7on dont est entrain\u00e9 le model, on peut se heurter \u00e0 2 probl\u00e8mes :</p> <ul> <li> <p>Sur apprentissage : Cela repr\u00e9sente un mod\u00e8le qui a appris par c\u0153ur ses donn\u00e9es d\u2019entrainement, qui fonctionne donc bien sur le jeu d\u2019entrainement mais pas de validation. Il effectue alors de mauvaise pr\u00e9diction sur de nouvelles, car elles ne sont pas exactement les m\u00eames que celle du jeu d\u2019entrainement. Pour y rem\u00e9dier, il faut am\u00e9liorer la flexibilit\u00e9 du mod\u00e8le, et donc jouer sur des concept de r\u00e9gularisation par exemple, ou encore d\u2019early stopping.</p> </li> <li> <p>Sous apprentissage : Ce cas-ci repr\u00e9sente un mod\u00e8le qui n\u2019arrive pas \u00e0 d\u00e9duire des informations du jeu de donn\u00e9es. Il n\u2019apprend donc pas assez et r\u00e9alise de mauvaise pr\u00e9diction sur le jeu d\u2019entrainement. Il faut donc complexifier le r\u00e9seau, car il ne taille pas bien par rapport aux types de donn\u00e9es d\u2019entr\u00e9es. En effet, il n\u2019arrive pas \u00e0 capter la relation entre les donn\u00e9es d\u2019entr\u00e9es et leur label.</p> </li> </ul> <p></p> <p>Dans le cas o\u00f9 la pr\u00e9cision du r\u00e9seau n\u2019est ni bonne sur le jeu d\u2019entrainement, ni sur celui de validation, c\u2019est que le r\u00e9seau n\u2019a pas eu assez de temps pour apprendre des donn\u00e9es. Il faut donc augmenter le nombre d\u2019it\u00e9ration, ou augmenter la taille du jeu de donn\u00e9e.</p>"},{"location":"dl/#regularisation-du-reseau-avec-les-dropout","title":"R\u00e9gularisation du r\u00e9seau avec les Dropout","text":"<p>Le Dropout est une technique de r\u00e9gularisation utilis\u00e9e pour r\u00e9duire le surapprentissage dans les r\u00e9seaux de neurones profonds. On va souhaiter favoriser l\u2019extraction de caract\u00e9ristique de fa\u00e7on ind\u00e9pendante, afin d\u2019apprendre des caract\u00e9ristique plus g\u00e9n\u00e9ral et plus diverse. Cela va consister \u00e0 \u2018\u00e9teindre\u2019, \u00e0 d\u00e9sactiver certains neurones du mod\u00e8le, et ce de fa\u00e7on al\u00e9atoire d\u2019une m\u00eame couche, qui ne contribuera donc ni \u00e0 la phase de feedforward, ni \u00e0 la phase de backpropagation. D\u2019un point de vue du r\u00e9seau, cela revient \u00e0 instancier la valeur en sortie d\u2019une fonction d\u2019activation \u00e0 0</p> <p></p>"},{"location":"dltypes/","title":"Les diff\u00e9rents types de r\u00e9seaux de neurones","text":"<p>Il existe diff\u00e9rents types de r\u00e9seaux de neurones, chacune ayant sa propre fonction et sa propre m\u00e9thode de traitement des donn\u00e9es d'entr\u00e9e. Voici un aper\u00e7u de quelques types courants de couches de neurones :</p>"},{"location":"dltypes/#les-reseaux-de-neurones-denses-fully-connected-layers","title":"Les r\u00e9seaux de neurones denses (Fully Connected Layers)","text":"<p>Un r\u00e9seau de neurones dense, \u00e9galement appel\u00e9 r\u00e9seau de neurones \u00e0 couches enti\u00e8rement connect\u00e9es, est un type de r\u00e9seau de neurones o\u00f9 chaque neurone dans une couche est connect\u00e9 \u00e0 tous les neurones de la couche pr\u00e9c\u00e9dente et de la couche suivante. Cela signifie que chaque neurone de la couche actuelle prend en compte toutes les activations de la couche pr\u00e9c\u00e9dente et renvoie une activation qui est propag\u00e9e \u00e0 tous les neurones de la couche suivante.</p> <p></p> <p></p> <p></p> <p>La sortie d'une couche dense est calcul\u00e9e comme suit :</p> \\[y_j = f\\left(\\sum_{i=1}^n w_{ji}x_i + b_j\\right)\\] <p>o\u00f9 :</p> <ul> <li>\\(y_j\\) est la sortie du \\(j\\)-\u00e8me neurone de la couche dense.</li> <li>\\(x_i\\) est l'activation du \\(i\\)-\u00e8me neurone de la couche pr\u00e9c\u00e9dente.</li> <li>\\(w_{ji}\\) est le poids de la connexion entre le \\(i\\)-\u00e8me neurone de la couche pr\u00e9c\u00e9dente et le \\(j\\)-\u00e8me neurone de la couche dense.</li> <li>\\(b_j\\) est le biais (un param\u00e8tre suppl\u00e9mentaire) du \\(j\\)-\u00e8me neurone de la couche dense.</li> <li>\\(f\\) est la fonction d'activation appliqu\u00e9e \u00e0 la somme pond\u00e9r\u00e9e des entr\u00e9es.</li> <li>La fonction d'activation \\(f\\) peut \u00eatre choisie en fonction du probl\u00e8me \u00e0 r\u00e9soudre.</li> </ul>"},{"location":"dltypes/#les-reseaux-de-neurones-convolutifs-convolutional-neural-networks","title":"Les r\u00e9seaux de neurones convolutifs (Convolutional Neural Networks)","text":"<p>Les r\u00e9seaux de neurones convolutifs (Convolutional Neural Networks ou CNNs) sont un type de r\u00e9seau de neurones sp\u00e9cialement con\u00e7us pour le traitement des images. Ils ont \u00e9t\u00e9 introduits pour la premi\u00e8re fois par Yann LeCun et ses coll\u00e8gues en 1998 pour la reconnaissance de caract\u00e8res manuscrits.</p> <p></p> <p>Les CNNs sont bas\u00e9s sur des filtres de convolution, qui sont des matrices de poids qui sont appliqu\u00e9es \u00e0 des r\u00e9gions de l'image. Les filtres de convolution permettent d'extraire des caract\u00e9ristiques visuelles \u00e0 diff\u00e9rentes \u00e9chelles. Par exemple, un filtre de convolution peut \u00eatre con\u00e7u pour d\u00e9tecter les bords dans une image, tandis qu'un autre filtre peut \u00eatre con\u00e7u pour d\u00e9tecter les coins.</p> <p></p> <p>Un r\u00e9seau de neurones convolutif se compose de plusieurs couches. La premi\u00e8re couche est la couche d'entr\u00e9e, qui contient l'image brute. Les couches suivantes sont des couches de convolution, qui appliquent des filtres de convolution \u00e0 l'image. Chaque filtre de convolution produit une carte de caract\u00e9ristiques, qui est une image qui met en \u00e9vidence les caract\u00e9ristiques sp\u00e9cifiques d\u00e9tect\u00e9es par le filtre. Les cartes de caract\u00e9ristiques sont ensuite pass\u00e9es \u00e0 une fonction d'activation, qui introduit une non-lin\u00e9arit\u00e9 dans le mod\u00e8le.</p> <p></p> <p>Apr\u00e8s les couches de convolution, il y a g\u00e9n\u00e9ralement des couches de regroupement (pooling layers), qui r\u00e9duisent la dimensionnalit\u00e9 de l'image en prenant le maximum, la moyenne ou la somme de petites r\u00e9gions de l'image. Les couches de regroupement permettent de r\u00e9duire le temps de calcul et de rendre le mod\u00e8le plus robuste aux variations mineures dans l'image.</p> <p></p> <p>Apr\u00e8s les couches de regroupement, il y a g\u00e9n\u00e9ralement des couches enti\u00e8rement connect\u00e9es (Fully Connected Layers), qui sont similaires aux couches de neurones denses des r\u00e9seaux de neurones classiques. Les couches enti\u00e8rement connect\u00e9es prennent les cartes de caract\u00e9ristiques en entr\u00e9e et les transforment en une repr\u00e9sentation de sortie qui est utilis\u00e9e pour la classification ou la r\u00e9gression.</p> <p></p> <p>Les CNNs sont entra\u00een\u00e9s \u00e0 l'aide d'un algorithme d'optimisation, tel que la descente de gradient stochastique (Stochastic Gradient Descent), pour minimiser une fonction de perte (loss function) qui mesure la diff\u00e9rence entre la sortie pr\u00e9dite et la sortie r\u00e9elle. Pendant l'entra\u00eenement, les poids des filtres de convolution et des couches enti\u00e8rement connect\u00e9es sont ajust\u00e9s pour minimiser la fonction de perte.</p> <p></p> <p></p> <p></p> <p>L'\u00e9quation pour la sortie d'une couche de convolution:</p> \\[y(i,j,k) = \\text{activation}\\left(\\sum_{l=1}^{p}\\sum_{m=1}^{q}\\sum_{n=1}^{r} w(m,n,l,k) x(i+m-1,j+n-1,l)\\right)\\] <p>o\u00f9 :</p> <ul> <li>\\(y(i,j,k)\\) est la sortie du \\(k\\)-\u00e8me filtre \u00e0 la position \\((i,j)\\) dans la carte de caract\u00e9ristiques de sortie.</li> <li>\\(\\text{activation}\\) est la fonction d'activation appliqu\u00e9e \u00e9l\u00e9ment par \u00e9l\u00e9ment \u00e0 la somme des entr\u00e9es pond\u00e9r\u00e9es.</li> <li>\\(w(m,n,l,k)\\) est le poids du \\(k\\)-\u00e8me filtre \u00e0 la position \\((m,n)\\) dans le \\(l\\)-\u00e8me canal d'entr\u00e9e.</li> <li>\\(x(i+m-1,j+n-1,l)\\) est l'activation d'entr\u00e9e \u00e0 la position \\((i+m-1,j+n-1)\\) dans le \\(l\\)-\u00e8me canal d'entr\u00e9e.</li> <li>\\(p,q,r\\) sont les dimensions du filtre.</li> </ul>"},{"location":"dltypes/#les-reseaux-de-neurones-recurrents-recurrent-neural-networks","title":"Les r\u00e9seaux de neurones r\u00e9currents (Recurrent Neural Networks)","text":"<p>Un r\u00e9seau de neurones r\u00e9currents (RNN) est un type de r\u00e9seau de neurones qui est capable de traiter des s\u00e9quences de donn\u00e9es en utilisant la r\u00e9troaction (feedback) des sorties pr\u00e9c\u00e9dentes comme entr\u00e9e pour les calculs futurs. Contrairement aux r\u00e9seaux de neurones classiques, les RNN ont des connexions de neurones cycliques, ce qui leur permet de stocker une m\u00e9moire interne de l'information trait\u00e9e jusqu'\u00e0 pr\u00e9sent.</p> <p></p> <p>Un RNN peut \u00eatre repr\u00e9sent\u00e9 comme une s\u00e9quence de cellules, o\u00f9 chaque cellule est une copie du m\u00eame r\u00e9seau de neurones. Chaque cellule prend en entr\u00e9e les donn\u00e9es de la s\u00e9quence et l'\u00e9tat cach\u00e9 de la cellule pr\u00e9c\u00e9dente. L'\u00e9tat cach\u00e9 est une repr\u00e9sentation vectorielle de la m\u00e9moire interne de la cellule, qui est mise \u00e0 jour \u00e0 chaque \u00e9tape de la s\u00e9quence.</p> <p></p> <p>La sortie de chaque cellule est renvoy\u00e9e \u00e0 la cellule suivante et est \u00e9galement utilis\u00e9e pour la pr\u00e9diction finale. La pr\u00e9diction finale est donc bas\u00e9e sur l'ensemble des sorties de toutes les cellules de la s\u00e9quence.</p> <p></p> <p></p> <p></p> <p>La sortie d'une cellule RNN est calcul\u00e9e comme suit :</p> \\[ h_t = f(W_{xh}x_t + W_{hh}h_{t-1} + b_h) \\] <p>o\u00f9 :</p> <ul> <li>\\(h_t\\) est l'\u00e9tat cach\u00e9 de la cellule \u00e0 l'\u00e9tape \\(t\\).</li> <li>\\(x_t\\) est l'entr\u00e9e \u00e0 l'\u00e9tape \\(t\\).</li> <li>\\(W_{xh}\\) est la matrice de poids pour les connexions entre les entr\u00e9es et l'\u00e9tat cach\u00e9.</li> <li>\\(W_{hh}\\) est la matrice de poids pour les connexions entre l'\u00e9tat cach\u00e9 de l'\u00e9tape pr\u00e9c\u00e9dente et l'\u00e9tat cach\u00e9 actuel.</li> <li>\\(b_h\\) est le biais ajout\u00e9 \u00e0 l'\u00e9tat cach\u00e9.</li> <li>\\(f\\) est la fonction d'activation appliqu\u00e9e \u00e0 la somme pond\u00e9r\u00e9e des entr\u00e9es.</li> </ul> <p>La sortie de la cellule peut \u00e9galement \u00eatre utilis\u00e9e pour pr\u00e9dire la prochaine valeur de la s\u00e9quence :</p> \\[ y_t = g(W_{hy}h_t + b_y) \\] <p>o\u00f9 :</p> <ul> <li>\\(y_t\\) est la pr\u00e9diction de la valeur de la s\u00e9quence \u00e0 l'\u00e9tape \\(t\\).</li> <li>\\(W_{hy}\\) est la matrice de poids pour les connexions entre l'\u00e9tat cach\u00e9 et la pr\u00e9diction.</li> <li>\\(b_y\\) est le biais ajout\u00e9 \u00e0 la pr\u00e9diction.</li> <li>\\(g\\) est la fonction d'activation appliqu\u00e9e \u00e0 la somme pond\u00e9r\u00e9e des entr\u00e9es.</li> </ul> <p>Les RNN sont largement utilis\u00e9s pour la mod\u00e9lisation de s\u00e9quences, notamment pour la reconnaissance de la parole, la traduction automatique et la g\u00e9n\u00e9ration de texte.</p>"},{"location":"dltypes/#les-reseaux-de-neurones-de-memoire-a-court-terme-long-short-term-memory-networks","title":"Les r\u00e9seaux de neurones de m\u00e9moire \u00e0 court terme (Long Short-Term Memory Networks)","text":"<p>Ce sont des r\u00e9seaux de neurones r\u00e9currents am\u00e9lior\u00e9s qui permettent de traiter des s\u00e9quences de donn\u00e9es plus longues. Les r\u00e9seaux de neurones de m\u00e9moire \u00e0 court terme utilisent des unit\u00e9s de m\u00e9moire qui leur permettent de retenir l'information importante sur une longue p\u00e9riode de temps, et sont utilis\u00e9s pour la g\u00e9n\u00e9ration de texte, la pr\u00e9diction de la prochaine valeur dans une s\u00e9rie temporelle, etc.</p>"},{"location":"dltypes/#les-reseaux-de-neurones-auto-encodeurs-autoencoder-neural-networks","title":"Les r\u00e9seaux de neurones auto-encodeurs (Autoencoder Neural Networks)","text":"<p>Ce sont des r\u00e9seaux de neurones qui apprennent \u00e0 reconstruire une entr\u00e9e \u00e0 partir d'une repr\u00e9sentation latente, en comprimant l'information dans une couche cach\u00e9e de neurones. Les r\u00e9seaux de neurones auto-encodeurs sont utilis\u00e9s pour la compression de donn\u00e9es, la d\u00e9tection d'anomalies, etc.</p>"},{"location":"dltypes/#les-reseaux-de-neurones-generatifs-generative-neural-networks","title":"Les r\u00e9seaux de neurones g\u00e9n\u00e9ratifs (Generative Neural Networks)","text":"<p>Ce sont des r\u00e9seaux de neurones qui apprennent \u00e0 g\u00e9n\u00e9rer de nouvelles donn\u00e9es \u00e0 partir d'un ensemble de donn\u00e9es d'entra\u00eenement. Les r\u00e9seaux de neurones g\u00e9n\u00e9ratifs sont utilis\u00e9s pour la g\u00e9n\u00e9ration de texte, d'images, de musique, etc.</p>"},{"location":"eval/","title":"Comment evaluer mon mod\u00e9le","text":""},{"location":"eval/#evaluation-dun-modele-de-regression","title":"\u00c9valuation d'un mod\u00e8le de r\u00e9gression","text":""},{"location":"eval/#les-coefficients-de-regression","title":"Les coefficients de r\u00e9gression","text":"<p>L'\u00e9quation d'une r\u00e9gression lin\u00e9aire simple peut \u00eatre \u00e9crite comme :</p> <pre><code>y = \u03b20 + \u03b21x + \u03b5\n</code></pre> <p>o\u00f9 :</p> <ul> <li>y est la variable d\u00e9pendante,</li> <li>x est la variable ind\u00e9pendante,</li> <li>\u03b20 est l'interception ou constante,</li> <li>\u03b21 est la pente ou coefficient de r\u00e9gression,</li> <li>\u03b5 est l'erreur r\u00e9siduelle.</li> </ul> <p>L'\u00e9quation indique que la valeur de y d\u00e9pend de la valeur de x multipli\u00e9e par le coefficient de r\u00e9gression \u03b21 et ajout\u00e9e \u00e0 l'interception \u03b20, avec une certaine erreur r\u00e9siduelle \u03b5. La r\u00e9gression lin\u00e9aire multiple peut \u00eatre \u00e9tendue pour inclure plusieurs variables ind\u00e9pendantes, ce qui donnerait une \u00e9quation de la forme :</p> <pre><code>y = \u03b20 + \u03b21x1 + \u03b22x2 + ... + \u03b2pxp + \u03b5\n</code></pre> <p>o\u00f9 p est le nombre de variables ind\u00e9pendantes.</p> <p></p> <p>Les coefficients de r\u00e9gression sont utilis\u00e9s pour mesurer la relation entre les variables ind\u00e9pendantes et la variable d\u00e9pendante dans un mod\u00e8le de r\u00e9gression. Un coefficient positif indique une relation positive entre les variables, tandis qu'un coefficient n\u00e9gatif indique une relation inverse. En r\u00e9gression lin\u00e9aire simple, le coefficient de pente mesure la variation de la variable d\u00e9pendante pour une unit\u00e9 de variation de la variable ind\u00e9pendante, tandis que le coefficient d'interception indique la valeur de la variable d\u00e9pendante lorsque la variable ind\u00e9pendante est \u00e9gale \u00e0 z\u00e9ro. Cependant, l'interpr\u00e9tation des coefficients d\u00e9pend du type de mod\u00e8le et de la nature des donn\u00e9es.</p>"},{"location":"eval/#mean-absolute-error-mae","title":"Mean Absolute Error (MAE)","text":"<p>La MAE mesure l'erreur absolue moyenne entre les pr\u00e9visions et les observations r\u00e9elles. Elle est calcul\u00e9e en faisant la somme des valeurs absolues des diff\u00e9rences entre chaque pr\u00e9diction et la valeur r\u00e9elle, puis en divisant cette somme par le nombre total de pr\u00e9dictions. Elle est souvent utilis\u00e9e pour des mod\u00e8les de r\u00e9gression simples, Plus le MAE est faible, meilleure est la performance du mod\u00e8le.</p> <p></p> <p>L'\u00e9quation de la MAE est la suivante :</p> <pre><code>MAE = (1/n) * \u03a3|i=1 \u00e0 n|(|y_i - \u0177_i|)\n\n</code></pre> <p>O\u00f9 :</p> <ul> <li>n : le nombre d'observations dans l'ensemble de donn\u00e9es de test</li> <li>y_i : la valeur r\u00e9elle de la variable cible pour la i-\u00e8me observation</li> <li>\u0177_i : la valeur pr\u00e9dite de la variable cible pour la i-\u00e8me observation</li> </ul> <p>Exemple de code Python pour calculer la MAE :</p> <pre><code>from sklearn.metrics import mean_absolute_error\n\ny_true = [3, -0.5, 2, 7]\ny_pred = [2.5, 0.0, 2, 8]\n\nmae = mean_absolute_error(y_true, y_pred)\n\nprint(\"MAE: \", mae) #R\u00e9sultat : MAE: 0.5\n</code></pre>"},{"location":"eval/#mean-squared-error-mse","title":"Mean Squared Error (MSE)","text":"<p>La MSE mesure la moyenne des carr\u00e9s des erreurs entre les pr\u00e9visions et les observations r\u00e9elles. Elle est calcul\u00e9e en faisant la somme des carr\u00e9s des diff\u00e9rences entre chaque pr\u00e9diction et la valeur r\u00e9elle, puis en divisant cette somme par le nombre total de pr\u00e9dictions. Elle est souvent utilis\u00e9e pour des mod\u00e8les de r\u00e9gression plus complexes.  Il est plus sensible aux grandes erreurs que le MAE. Plus le MSE est faible, meilleure est la performance du mod\u00e8le.</p> <p></p> <p>L'\u00e9quation de la MSE est la suivante :</p> <pre><code>MSE = (1/n) * \u03a3|i=1 \u00e0 n|(y_i - \u0177_i)^2\n</code></pre> <p>O\u00f9 :</p> <ul> <li>n : le nombre d'observations dans l'ensemble de donn\u00e9es de test</li> <li>y_i : la valeur r\u00e9elle de la variable cible pour la i-\u00e8me observation</li> <li>\u0177_i : la valeur pr\u00e9dite de la variable cible pour la i-\u00e8me observation</li> </ul> <p>Exemple de code Python pour calculer la MSE :</p> <pre><code>from sklearn.metrics import mean_squared_error\n\ny_true = [3, -0.5, 2, 7]\ny_pred = [2.5, 0.0, 2, 8]\n\nmse = mean_squared_error(y_true, y_pred)\n\nprint(\"MSE: \", mse) #R\u00e9sultat : MSE: 0.375\n\n</code></pre>"},{"location":"eval/#root-mean-squared-error-rmse","title":"Root Mean Squared Error (RMSE)","text":"<p>Le RMSE est la racine carr\u00e9e du MSE et repr\u00e9sente l'erreur moyenne entre les pr\u00e9dictions du mod\u00e8le et les valeurs r\u00e9elles de la variable cible. Il est souvent utilis\u00e9 pour des mod\u00e8les de r\u00e9gression plus complexes. Plus le RMSE est faible, meilleure est la performance du mod\u00e8le.</p> <p></p> <p>L'\u00e9quation du RMSE est la suivante :</p> <pre><code>RMSE = sqrt(MSE)\n</code></pre> <p>Exemple de code Python pour calculer le RMSE :</p> <pre><code>from sklearn.metrics import mean_squared_error\nimport numpy as np\n\ny_true = [3, -0.5, 2, 7]\ny_pred = [2.5, 0.0, 2, 8]\n\nmse = mean_squared_error(y_true, y_pred)\nrmse = np.sqrt(mse)\n\nprint(\"RMSE: \", rmse) # R\u00e9sultat : RMSE: 0.6123724356957945\n</code></pre>"},{"location":"eval/#coefficient-de-determination-r2","title":"Coefficient de d\u00e9termination R\u00b2","text":"<p>Le coefficient de d\u00e9termination R\u00b2 mesure la proportion de variance expliqu\u00e9e par le mod\u00e8le. Il varie de 0 \u00e0 1, o\u00f9 0 signifie que le mod\u00e8le ne parvient pas \u00e0 expliquer la variance de la variable cible et 1 signifie qu'il explique toute la variance. Plus le R\u00b2 est \u00e9lev\u00e9, meilleure est la performance du mod\u00e8le. Equation : </p> <pre><code>R\u00b2 = 1 - SSE / SST\n</code></pre> <p>o\u00f9 SSE est la somme des carr\u00e9s des r\u00e9sidus (c'est-\u00e0-dire la somme des carr\u00e9s des diff\u00e9rences entre les valeurs pr\u00e9dites et les valeurs r\u00e9elles), et SST est la somme des carr\u00e9s des diff\u00e9rences entre les valeurs r\u00e9elles et la moyenne des valeurs r\u00e9elles.</p> <ul> <li>Somme des carr\u00e9s des erreurs (SSE) :</li> </ul> <pre><code>SSE = \u03a3(yi - \u0177i)\u00b2\n</code></pre> <p>o\u00f9 yi est la valeur r\u00e9elle de la variable d\u00e9pendante, et \u0177i est la valeur pr\u00e9dite par le mod\u00e8le.</p> <ul> <li>Somme totale des carr\u00e9s (SST) :</li> </ul> <pre><code>SST = \u03a3(yi - \u0233)\u00b2\n</code></pre> <p>o\u00f9 yi est la valeur r\u00e9elle de la variable d\u00e9pendante, et \u0233 est la moyenne des valeurs r\u00e9elles.</p> <pre><code>from sklearn.metrics import r2_score\n\ny_true = [3, -0.5, 2, 7]\ny_pred = [2.5, 0.0, 2, 8]\n\n# Calcul du coefficient de d\u00e9termination R\u00b2\nr2 = r2_score(y_train, y_pred)\n\nprint(\"Coefficient de d\u00e9termination R\u00b2 :\", r2)\n</code></pre>"},{"location":"eval/#interpretation-des-resultats","title":"Interpr\u00e9tation des r\u00e9sultats","text":"<ul> <li> <p>MAE : Un MAE de 0 signifie que le mod\u00e8le pr\u00e9dit parfaitement les valeurs de la variable cible. En g\u00e9n\u00e9ral, un MAE faible indique une bonne performance, mais cela d\u00e9pend du contexte et de la plage de valeurs de la variable cible.</p> </li> <li> <p>MSE et RMSE : Comme mentionn\u00e9 pr\u00e9c\u00e9demment, ces deux m\u00e9triques sont plus sensibles aux grandes erreurs que le MAE. Par cons\u00e9quent, un MSE ou un RMSE \u00e9lev\u00e9 peut indiquer qu'il y a des valeurs aberrantes dans les donn\u00e9es ou que le mod\u00e8le ne parvient pas \u00e0 pr\u00e9dire correctement les valeurs extr\u00eames de la variable cible.</p> </li> <li> <p>R\u00b2 : indique la proportion de la variance totale des donn\u00e9es qui est expliqu\u00e9e par le mod\u00e8le. Un R\u00b2 de 1 signifie que le mod\u00e8le explique parfaitement la variance des donn\u00e9es, tandis qu'un R\u00b2 de 0 signifie que le mod\u00e8le n'explique aucune variance des donn\u00e9es. Dans la pratique, un R\u00b2 \u00e9lev\u00e9 (g\u00e9n\u00e9ralement sup\u00e9rieur \u00e0 0,7 ou 0,8) est consid\u00e9r\u00e9 comme un bon ajustement du mod\u00e8le aux donn\u00e9es.</p> </li> <li> <p>SSE indique la quantit\u00e9 d'erreur r\u00e9siduelle dans le mod\u00e8le. En g\u00e9n\u00e9ral, plus SSE est faible, mieux c'est, car cela signifie que les pr\u00e9dictions du mod\u00e8le sont plus proches des valeurs r\u00e9elles.</p> </li> <li> <p>SST indique la quantit\u00e9 de variation totale dans les donn\u00e9es. Il est souvent utilis\u00e9 comme mesure de la variabilit\u00e9 des donn\u00e9es de r\u00e9f\u00e9rence. Un mod\u00e8le qui explique une grande partie de la variation totale de SST est consid\u00e9r\u00e9 comme un bon ajustement aux donn\u00e9es.</p> </li> </ul>"},{"location":"eval/#evaluation-dun-modele-de-classification","title":"\u00c9valuation d'un mod\u00e8le de classification","text":""},{"location":"eval/#accuracy","title":"Accuracy","text":"<p>L'accuracy est la m\u00e9trique la plus simple pour \u00e9valuer les mod\u00e8les de classification. Elle mesure la proportion de pr\u00e9dictions correctes sur l'ensemble de donn\u00e9es de test.</p> <p></p> <p>L'\u00e9quation de l'accuracy est la suivante :</p> <pre><code>Accuracy = (TP + TN) / (TP + TN + FP + FN)\n</code></pre> <p>O\u00f9 :</p> <ul> <li>TP : True Positives, le nombre de pr\u00e9dictions positives correctes</li> <li>TN : True Negatives, le nombre de pr\u00e9dictions n\u00e9gatives correctes</li> <li>FP : False Positives, le nombre de pr\u00e9dictions positives incorrectes</li> <li>FN : False Negatives, le nombre de pr\u00e9dictions n\u00e9gatives incorrectes</li> </ul> <p>Exemple de code Python pour calculer l'accuracy :</p> <pre><code>from sklearn.metrics import accuracy_score\n\ny_true = [0, 1, 2, 0, 1, 2]\ny_pred = [0, 2, 1, 0, 0, 1]\n\naccuracy = accuracy_score(y_true, y_pred)\n\nprint(\"Accuracy: \", accuracy) #R\u00e9sultat : Accuracy: 0.3333333333333333\n</code></pre>"},{"location":"eval/#precision-recall-et-f1-score","title":"Precision, Recall et F1-score","text":"<p>La pr\u00e9cision (precision), le rappel (recall) et le score F1 (F1-score) sont des m\u00e9triques plus avanc\u00e9es pour \u00e9valuer les mod\u00e8les de classification. Elles sont particuli\u00e8rement utiles pour les probl\u00e8mes de classification binaire, o\u00f9 l'on souhaite pr\u00e9dire la pr\u00e9sence ou l'absence d'une classe.</p> <ul> <li>La pr\u00e9cision mesure la proportion de pr\u00e9dictions positives qui sont correctes. Elle est calcul\u00e9e en divisant le nombre de vrais positifs par le nombre de vrais positifs plus le nombre de faux positifs.L'\u00e9quation de la pr\u00e9cision est la suivante :</li> </ul> <pre><code>Precision = TP / (TP + FP)\n</code></pre> <ul> <li>Le rappel mesure la proportion de vrais positifs qui sont correctement identifi\u00e9s. Il est calcul\u00e9 en divisant le nombre de vrais positifs par le nombre de vrais positifs plus le nombre de faux n\u00e9gatifs. L'\u00e9quation du rappel est la suivante :</li> </ul> <pre><code>Recall = TP / (TP + FN)\n</code></pre> <ul> <li>Le score F1 est une moyenne harmonique de la pr\u00e9cision et du rappel. Il est calcul\u00e9 en prenant la moyenne pond\u00e9r\u00e9e de la pr\u00e9cision et du rappel, o\u00f9 la pond\u00e9ration est donn\u00e9e par l'harmonique de la pr\u00e9cision et du rappel. L'\u00e9quation du score F1 est la suivante :</li> </ul> <pre><code>F1 = 2 * (Precision * Recall) / (Precision + Recall)\n</code></pre> <p>Exemple de code Python pour calculer la pr\u00e9cision, le rappel et le score F1 :</p> <pre><code>from sklearn.metrics import precision_score, recall_score, f1_score\n\ny_true = [0, 1, 2, 0, 1, 2]\ny_pred = [0, 2, 1, 0, 0, 1]\n\nprecision = precision_score(y_true, y_pred, average='macro')\nrecall = recall_score(y_true, y_pred, average='macro')\nf1 = f1_score(y_true, y_pred, average='macro')\n\nprint(\"Precision: \", precision)\nprint(\"Recall: \", recall)\nprint(\"F1-score: \", f1)\n\n</code></pre>"},{"location":"eval/#matrice-de-confusion","title":"Matrice de confusion","text":"<p>La matrice de confusion est un outil visuel pour \u00e9valuer les performances d'un mod\u00e8le de classification. Elle montre le nombre de pr\u00e9dictions correctes et incorrectes pour chaque classe.</p> <p></p> <p>Exemple de code Python pour afficher la matrice de confusion :</p> <pre><code>from sklearn.metrics import confusion_matrix\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\ny_true = [0, 1, 2, 0, 1, 2]\ny_pred = [0, 2, 1, 0, 0, 1]\n\ncm = confusion_matrix(y_true, y_pred)\n\nsns.heatmap(cm, annot=True, cmap=\"Blues\")\nplt.xlabel('Pr\u00e9dictions')\nplt.ylabel('Valeurs r\u00e9elles')\nplt.show()\n\n</code></pre>"},{"location":"eval/#interpreter-les-metriques-devaluation-de-classification","title":"Interpr\u00e9ter les m\u00e9triques d'\u00e9valuation de classification:","text":"<p>Tout d\u00e9pend du contexte sp\u00e9cifique de chaque projet de machine learning. Cependant, voici quelques points g\u00e9n\u00e9raux \u00e0 prendre en compte lors de l'interpr\u00e9tation de ces m\u00e9triques :</p> <ul> <li> <p>Pr\u00e9cision : La pr\u00e9cision mesure le taux de pr\u00e9dictions positives correctes parmi toutes les pr\u00e9dictions positives. Par exemple, une pr\u00e9cision de 0,8 signifie que le mod\u00e8le a correctement pr\u00e9dit 80% des r\u00e9sultats positifs. Cependant, si la pr\u00e9cision est \u00e9lev\u00e9e mais que le rappel est faible, cela peut indiquer que le mod\u00e8le pr\u00e9dit trop peu de r\u00e9sultats positifs, manquant ainsi des r\u00e9sultats positifs r\u00e9els.</p> </li> <li> <p>Rappel : Le rappel mesure le taux de pr\u00e9dictions positives correctes parmi tous les r\u00e9sultats positifs r\u00e9els. Par exemple, un rappel de 0,7 signifie que le mod\u00e8le a correctement pr\u00e9dit 70% des r\u00e9sultats positifs. Cependant, si le rappel est \u00e9lev\u00e9 mais que la pr\u00e9cision est faible, cela peut indiquer que le mod\u00e8le pr\u00e9dit trop de r\u00e9sultats positifs, y compris des r\u00e9sultats faux positifs.</p> </li> <li> <p>Score F1 : Le score F1 est une moyenne harmonique de la pr\u00e9cision et du rappel. Il est g\u00e9n\u00e9ralement utilis\u00e9 lorsque l'on souhaite trouver un \u00e9quilibre entre la pr\u00e9cision et le rappel.</p> </li> <li> <p>Matrice de confusion : La matrice de confusion montre le nombre de pr\u00e9dictions correctes et incorrectes pour chaque classe. Elle permet de voir o\u00f9 le mod\u00e8le est en train de se tromper. Par exemple, si le mod\u00e8le pr\u00e9dit souvent la classe 0 alors qu'elle est r\u00e9ellement la classe 1, il peut y avoir une confusion entre ces deux classes.</p> </li> </ul> <p>En g\u00e9n\u00e9ral, il est important d'\u00e9valuer le mod\u00e8le avec plusieurs m\u00e9triques pour avoir une vue d'ensemble de ses performances. Selon le contexte, certaines m\u00e9triques peuvent \u00eatre plus importantes que d'autres. Par exemple, dans les probl\u00e8mes de d\u00e9tection de fraude, un rappel \u00e9lev\u00e9 peut \u00eatre plus important que la pr\u00e9cision, car il est crucial de ne pas manquer de cas de fraude, m\u00eame si cela signifie avoir plus de faux positifs.</p>"},{"location":"ml/","title":"Les taches et mod\u00e9les de ML","text":""},{"location":"ml/#on-fait-quoi-avec","title":"On fait quoi avec ?","text":"<p>Le machine learning peut \u00eatre utilis\u00e9 pour diff\u00e9rentes t\u00e2ches, selon le type de donn\u00e9es que vous avez et le probl\u00e8me que vous essayez de r\u00e9soudre. Voici un aper\u00e7u de quelques-unes des t\u00e2ches les plus courantes :</p> <ul> <li> <p>R\u00e9gression : la r\u00e9gression consiste \u00e0 pr\u00e9dire une valeur num\u00e9rique en fonction d'un ou plusieurs param\u00e8tres. Par exemple, vous pouvez utiliser la r\u00e9gression pour pr\u00e9dire le prix d'une maison en fonction de son emplacement, de sa taille et de ses caract\u00e9ristiques. </p> </li> <li> <p>Classification : la classification consiste \u00e0 pr\u00e9dire une \u00e9tiquette discr\u00e8te en fonction d'un ensemble de caract\u00e9ristiques. Par exemple, vous pouvez utiliser la classification pour pr\u00e9dire si un email est du spam ou non, en fonction de son contenu et de ses caract\u00e9ristiques.</p> </li> <li> <p>Clustering : le clustering consiste \u00e0 regrouper des points de donn\u00e9es similaires dans des groupes, sans \u00e9tiquettes de classe pr\u00e9d\u00e9finies. Par exemple, vous pouvez utiliser le clustering pour regrouper les clients de votre boutique en fonction de leurs habitudes d'achat.</p> </li> <li> <p>R\u00e9duction de dimension : la r\u00e9duction de dimension consiste \u00e0 r\u00e9duire la complexit\u00e9 des donn\u00e9es en r\u00e9duisant le nombre de variables ou de caract\u00e9ristiques. Par exemple, vous pouvez utiliser la r\u00e9duction de dimension pour visualiser des donn\u00e9es \u00e0 haute dimension en deux ou trois dimensions.</p> </li> </ul>"},{"location":"ml/#types-de-m-l","title":"Types de M L","text":"<p>Il existe deux types principaux :</p>"},{"location":"ml/#lapprentissage-supervise","title":"L'apprentissage supervis\u00e9","text":"<p>Dans ce type d'apprentissage, le mod\u00e8le apprend \u00e0 pr\u00e9dire une sortie \u00e0 partir d'une entr\u00e9e, en utilisant un ensemble de donn\u00e9es d'apprentissage qui contient des exemples d'entr\u00e9es et de sorties connues. Le mod\u00e8le ajuste ensuite ses param\u00e8tres pour minimiser l'erreur de pr\u00e9diction. </p> <p></p> <p>Voici quelques mod\u00e8les de machine learning supervis\u00e9s :</p>"},{"location":"ml/#regression-lineaire","title":"R\u00e9gression lin\u00e9aire","text":"<p>La r\u00e9gression lin\u00e9aire est une m\u00e9thode de pr\u00e9diction qui permet de mod\u00e9liser la relation entre une variable cible continue et une ou plusieurs variables pr\u00e9dictives continues ou cat\u00e9gorielles. Le but de la r\u00e9gression lin\u00e9aire est de trouver la meilleure droite (ou hyperplan en dimension sup\u00e9rieure) qui repr\u00e9sente la relation entre les variables. </p> <p></p> <p>Le mod\u00e8le peut \u00eatre utilis\u00e9 pour la pr\u00e9diction ou pour comprendre la relation entre les variables. Par exemple, dans le cas de la pr\u00e9diction de prix de vente d'une maison, les variables pr\u00e9dictives pourraient \u00eatre la superficie, le nombre de chambres, la localisation, etc.</p> <p></p> <p>Exemple de code :</p> <pre><code>from sklearn.linear_model import LinearRegression\n\n# Cr\u00e9ation d'un mod\u00e8le de r\u00e9gression lin\u00e9aire\nregression_model = LinearRegression()\n\n# Entra\u00eenement du mod\u00e8le sur les donn\u00e9es d'entra\u00eenement\nregression_model.fit(X_train, y_train)\n\n# Pr\u00e9diction des valeurs pour les donn\u00e9es de test\ny_pred = regression_model.predict(X_test)\n</code></pre>"},{"location":"ml/#regression-logistique","title":"R\u00e9gression logistique","text":"<p>La r\u00e9gression logistique est une m\u00e9thode de classification qui permet de pr\u00e9dire la probabilit\u00e9 qu'une observation appartienne \u00e0 une classe particuli\u00e8re (binaire ou multi-classes). La sortie est une probabilit\u00e9, donc la valeur pr\u00e9dite est toujours comprise entre 0 et 1. </p> <p></p> <p>Le mod\u00e8le estime la probabilit\u00e9 de l'appartenance \u00e0 chaque classe en fonction des variables pr\u00e9dictives. Le mod\u00e8le est souvent utilis\u00e9 pour la classification de clients potentiels, de mails comme spam ou non, etc.</p> <p></p> <p>Exemple de code :</p> <pre><code>from sklearn.linear_model import LogisticRegression\n\n# Cr\u00e9ation d'un mod\u00e8le de r\u00e9gression logistique\nlogistic_model = LogisticRegression()\n\n# Entra\u00eenement du mod\u00e8le sur les donn\u00e9es d'entra\u00eenement\nlogistic_model.fit(X_train, y_train)\n\n# Pr\u00e9diction des classes pour les donn\u00e9es de test\ny_pred = logistic_model.predict(X_test)\n</code></pre>"},{"location":"ml/#arbre-de-decision","title":"Arbre de d\u00e9cision","text":"<p>Les arbres de d\u00e9cision sont une m\u00e9thode de classification et de r\u00e9gression qui permettent de cr\u00e9er un mod\u00e8le \u00e0 partir des donn\u00e9es en formes d'arbre. Les noeuds internes de l'arbre repr\u00e9sentent une condition sur les variables pr\u00e9dictives, les feuilles de l'arbre repr\u00e9sentent les pr\u00e9dictions de la variable cible. Le mod\u00e8le est facilement interpr\u00e9table et permet de comprendre comment les variables sont utilis\u00e9es pour la pr\u00e9diction.</p> <p></p> <p>Exemple de code :</p> <pre><code>from sklearn.tree import DecisionTreeClassifier\n\n# Cr\u00e9ation d'un mod\u00e8le d'arbre de d\u00e9cision\ntree_model = DecisionTreeClassifier()\n\n# Entra\u00eenement du mod\u00e8le sur les donn\u00e9es d'entra\u00eenement\ntree_model.fit(X_train, y_train)\n\n# Pr\u00e9diction des classes pour les donn\u00e9es de test\ny_pred = tree_model.predict(X_test)\n</code></pre>"},{"location":"ml/#foret-darbres-decisionnels","title":"For\u00eat d'arbres d\u00e9cisionnels","text":"<p>Les for\u00eats d'arbres d\u00e9cisionnels sont une m\u00e9thode de classification et de r\u00e9gression qui combine les r\u00e9sultats de plusieurs arbres de d\u00e9cision. Chaque arbre dans la for\u00eat est entra\u00een\u00e9 sur un \u00e9chantillon al\u00e9atoire des donn\u00e9es d'entra\u00eenement. Le mod\u00e8le agr\u00e8ge les pr\u00e9dictions des diff\u00e9rents arbres pour donner une pr\u00e9diction finale. Les for\u00eats d'arbres d\u00e9cisionnels sont souvent plus pr\u00e9cises que les arbres de d\u00e9cision.</p> <p></p> <p>Voici un exemple de code utilisant Scikit-learn pour entra\u00eener un mod\u00e8le de for\u00eat al\u00e9atoire pour la classification :</p> <pre><code>from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.datasets import make_classification\n\nX, y = make_classification(n_features=4, random_state=0)\nclf = RandomForestClassifier(max_depth=2, random_state=0)\nclf.fit(X, y)\n</code></pre>"},{"location":"ml/#les-machines-a-vecteurs-de-support-svm","title":"Les Machines \u00e0 Vecteurs de Support (SVM)","text":"<p>Les SVM sont un algorithme d'apprentissage supervis\u00e9 utilis\u00e9 pour la classification et la r\u00e9gression. Les SVM trouvent une fronti\u00e8re de d\u00e9cision qui maximise la marge entre les deux classes. Cette fronti\u00e8re de d\u00e9cision est appel\u00e9e un hyperplan. Les SVM peuvent \u00eatre utilis\u00e9es pour des t\u00e2ches de classification avec deux classes ou plus.</p> <p></p> <p>Les SVM ont une grande pr\u00e9cision et sont populaires dans les t\u00e2ches de classification. Ils peuvent \u00e9galement \u00eatre utilis\u00e9s pour la r\u00e9gression.</p> <p></p> <p>Voici un exemple de code utilisant Scikit-learn pour entra\u00eener un mod\u00e8le SVM pour la classification :</p> <pre><code>from sklearn import svm\nfrom sklearn.datasets import make_classification\n\nX, y = make_classification(n_features=4, random_state=0)\nclf = svm.SVC(kernel='linear', C=1, random_state=0)\nclf.fit(X, y)\n</code></pre>"},{"location":"ml/#lapprentissage-non-supervise","title":"L'apprentissage non supervis\u00e9","text":"<p>Les mod\u00e8les non supervis\u00e9s sont des algorithmes de machine learning qui n'ont pas besoin de donn\u00e9es \u00e9tiquet\u00e9es pour fonctionner. Ils sont utilis\u00e9s pour explorer les donn\u00e9es et trouver des structures cach\u00e9es, des mod\u00e8les et des corr\u00e9lations. Voici quelques exemples de mod\u00e8les non supervis\u00e9s:</p>"},{"location":"ml/#k-means-clustering","title":"K-means clustering","text":"<p>Le K-means clustering est une technique de partitionnement de donn\u00e9es qui permet de diviser un ensemble de donn\u00e9es en K groupes distincts (clusters). Chaque point de donn\u00e9es est affect\u00e9 \u00e0 un cluster en fonction de sa proximit\u00e9 avec le centre de ce cluster.</p> <p></p> <p>Voici un exemple de code en Python pour appliquer le K-means clustering :</p> <pre><code>from sklearn.cluster import KMeans\nimport numpy as np\n\n# G\u00e9n\u00e9rer des donn\u00e9es al\u00e9atoires\nX = np.random.rand(100, 2)\n\n# Instancier le mod\u00e8le de clustering\nkmeans = KMeans(n_clusters=3)\n\n# Fitter le mod\u00e8le aux donn\u00e9es\nkmeans.fit(X)\n\n# Pr\u00e9dire les clusters pour de nouvelles donn\u00e9es\nlabels = kmeans.predict(X)\n</code></pre>"},{"location":"ml/#analyse-en-composantes-principales-pca","title":"Analyse en composantes principales (PCA)","text":"<p>L'analyse en composantes principales est une m\u00e9thode de r\u00e9duction de dimension qui permet de projeter des donn\u00e9es \u00e0 haute dimension sur un espace de dimension inf\u00e9rieure tout en conservant autant que possible les informations contenues dans les donn\u00e9es originales.</p> <p></p> <p>Voici un exemple de code en Python pour appliquer l'analyse en composantes principales :</p> <pre><code>from sklearn.decomposition import PCA\nimport numpy as np\n\n# G\u00e9n\u00e9rer des donn\u00e9es al\u00e9atoires\nX = np.random.rand(100, 10)\n\n# Instancier le mod\u00e8le de PCA\npca = PCA(n_components=3)\n\n# Fitter le mod\u00e8le aux donn\u00e9es\npca.fit(X)\n\n# Transformer les donn\u00e9es pour obtenir les nouvelles dimensions\nX_pca = pca.transform(X)\n</code></pre>"},{"location":"ml/#reduction-de-dimension-avec-t-sne","title":"R\u00e9duction de dimension avec t-SNE","text":"<p>t-SNE est une m\u00e9thode de r\u00e9duction de dimension qui permet de projeter des donn\u00e9es \u00e0 haute dimension sur un espace de dimension inf\u00e9rieure en conservant autant que possible les relations de proximit\u00e9 entre les donn\u00e9es.</p> <p></p> <p>Voici un exemple de code en Python pour appliquer la r\u00e9duction de dimension avec t-SNE :</p> <pre><code>from sklearn.manifold import TSNE\nimport numpy as np\n\n# G\u00e9n\u00e9rer des donn\u00e9es al\u00e9atoires\nX = np.random.rand(100, 10)\n\n# Instancier le mod\u00e8le de t-SNE\ntsne = TSNE(n_components=2)\n\n# Fitter le mod\u00e8le aux donn\u00e9es\nX_tsne = tsne.fit_transform(X)\n</code></pre>"},{"location":"numpy/","title":"NumPy","text":"<p>NumPy est l'abr\u00e9viation de Numerical Python. C'est une biblioth\u00e8que/package Python utilis\u00e9e pour travailler avec des tableaux qui contiennent des classes, des fonctions, des variables, une grande biblioth\u00e8que de fonctions math\u00e9matiques, etc. pour travailler avec des calculs scientifiques. Il peut \u00eatre utilis\u00e9 pour cr\u00e9er un tableau \"n\" dimensionnel o\u00f9 \"n\" est un entier quelconque.</p> <p>Pourquoi NumPy ? En Python, nous avons des listes qui servent de tableaux, mais elles sont lentes. NumPy vise \u00e0 fournir un objet de tableau qui est jusqu'\u00e0 50 fois plus rapide qu'une liste Python traditionnelle.</p> <p></p> <p>L'objet de tableau dans NumPy s'appelle ndarray, il fournit de nombreuses fonctions de soutien qui rendent le travail avec ndarray tr\u00e8s facile. Les tableaux sont tr\u00e8s fr\u00e9quemment utilis\u00e9s en science des donn\u00e9es, o\u00f9 la vitesse et les ressources sont tr\u00e8s importantes.</p> <p></p> <p>Ce qui rend les tableaux NumPy plus rapides que les listes : les tableaux NumPy sont stock\u00e9s \u00e0 un endroit continu en m\u00e9moire contrairement aux listes, de sorte que les processus peuvent y acc\u00e9der et les manipuler tr\u00e8s efficacement. Ce comportement est appel\u00e9 la localit\u00e9 de r\u00e9f\u00e9rence. C'est la principale raison pour laquelle NumPy est plus rapide que les listes. Il est \u00e9galement optimis\u00e9 pour fonctionner avec les derni\u00e8res architectures de processeur.</p> <p>Installation de NumPy Pour installer NumPy, vous pouvez utiliser pip, l'installateur de paquets Python. Ouvrez votre terminal ou votre invite de commande et entrez la commande suivante :</p> <p>Copy code pip3 install numpy Importation de NumPy Il existe deux fa\u00e7ons d'importer NumPy. Exemple de code :</p> <p>python Copy code</p>"},{"location":"numpy/#cela-importera-lensemble-du-module-numpy","title":"cela importera l'ensemble du module NumPy.","text":"<p>import numpy as np</p>"},{"location":"numpy/#cela-importera-toutes-les-classes-les-objets-les-variables-etc-du-package-numpy","title":"cela importera toutes les classes, les objets, les variables, etc. du package NumPy","text":"<p>from numpy import* NumPy est g\u00e9n\u00e9ralement import\u00e9 sous l'alias np.</p> <p> alias : en Python, les alias sont un nom alternatif pour faire r\u00e9f\u00e9rence \u00e0 la m\u00eame chose.</p> <p> Cr\u00e9ation de tableaux NumPy L'objet de tableau dans NumPy s'appelle ndarray. Nous pouvons cr\u00e9er un objet ndarray NumPy en utilisant la fonction array(). Les tableaux NumPy peuvent \u00eatre cr\u00e9\u00e9s de plusieurs mani\u00e8res. Voici quelques-unes des m\u00e9thodes les plus courantes :</p> <p>Utilisation de la fonction numpy.array() pour cr\u00e9er un tableau \u00e0 partir d'une liste/d'un tuple : css Copy code a = np.array([1, 2, 3]) Utilisation de la fonction numpy.zeros() pour cr\u00e9er un tableau rempli de z\u00e9ros : bash Copy code b = np.zeros((2, 3)) Utilisation de la fonction numpy.ones() pour cr\u00e9er un tableau rempli de uns : bash Copy code c = np.ones((2, 3)) Utilisation de la fonction numpy.random.randint() : renvoie un tableau d'entiers al\u00e9atoires entre les deux nombres donn\u00e9s. lua Copy code d = np.random.randint(0, 10) Utilisation de la fonction numpy.random.rand() pour cr\u00e9er un tableau de valeurs al\u00e9atoires : lua Copy code e = np.random.rand(2, 3) Dimensions des tableaux NumPy</p>"},{"location":"pd/","title":"Pd","text":"<p>pd</p>"},{"location":"docker/docker_best_practice/","title":"Best Practices","text":""},{"location":"docker/docker_best_practice/#best-practices-for-design-and-optimize-containers","title":"Best Practices for design and optimize containers","text":""},{"location":"docker/docker_best_practice/#use-an-appropriate-base-image","title":"Use an appropriate base image","text":"<p>The base image you choose can greatly affect the size and security of your final image. Choose a minimal base image and only include what you need to minimize the attack surface and reduce the image size.</p> <p></p> <p>One popular base image is <code>Alpine</code> Linux. Alpine Linux is a lightweight Linux distribution that is designed to be small and efficient. It is commonly used for Docker images because of its small size, which makes it ideal for running containers with limited resources.</p> <p></p> <p>Another base image that is commonly used is the <code>slim</code> version of the official images provided by different software vendors. For example, the official Python image has a slim version, which is a smaller image with only the necessary dependencies required to run Python applications. This means that you can reduce the size of your Docker image by using the slim version instead of the full version.</p> <p></p> <p>However, it is important to keep in mind that using a base image that is too small can sometimes cause issues.</p>"},{"location":"docker/docker_best_practice/#avoid-running-as-root","title":"Avoid running as root","text":"<p>Running containers as the root user is considered bad practice because it poses a security risk. By default, the root user inside a container has the same privileges as the root user on the host machine. This means that if an attacker gains control of a container running as root, they could potentially escalate their privileges to the host machine.</p> <p></p> <p>To avoid running containers as root, you can specify a non-root user in your Dockerfile using the <code>USER</code> instruction. For example:</p> <pre><code>FROM python:3.9-slim\n\n# Create a non-root user\nRUN useradd --create-home myuser\nWORKDIR /home/myuser\n\n# Switch to the non-root user\nUSER myuser\n\n# Copy application files and install dependencies\nCOPY requirements.txt .\nRUN pip install -r requirements.txt\n\n# Copy the rest of the application code\nCOPY . .\n\n# Run the application\nCMD [\"python\", \"app.py\"]\n</code></pre> <p>In this example, we create a non-root user called myuser and switch to that user using the USER instruction. This user is then used to run the application inside the container.</p>"},{"location":"docker/docker_best_practice/#keep-layers-small","title":"Keep layers small","text":"<p>When building a Docker image, each line in the Dockerfile creates a new layer in the final image. Layers are stacked on top of each other to create the final image. Each layer only stores the changes made on top of the previous layer, which results in a more efficient use of disk space and a faster build time.</p> <p></p> <p>Keeping layers small is important because it can make it easier to update or modify specific parts of the image without rebuilding the entire image. This can be especially important when dealing with large applications that have many dependencies.</p> <p></p> <p></p> <p></p> <p>To keep layers small, it is best to group related commands together in a single line in the Dockerfile. For example, instead of installing several packages in separate RUN commands, it is better to install them all in a single RUN command. This will result in fewer layers and a smaller image size.</p> <p></p> <p>It is also important to clean up any temporary files created during the build process, as these files can add unnecessary weight to the image. The <code>RUN</code> command should be followed by a <code>CLEANUP</code> command to remove any unwanted files and dependencies.</p> <p></p> <p>Additionally, using the <code>--no-cache</code> flag when building an image can help to reduce the size of layers, as it prevents Docker from caching layers and forces it to rebuild each layer from scratch.</p>"},{"location":"docker/docker_best_practice/#use-multi-stage-builds","title":"Use multi-stage builds","text":"<p>Multi-stage builds are a way to optimize your Docker images and reduce their size. It allows you to use multiple FROM statements in your Dockerfile, each of which specifies a different base image.</p> <p></p> <p>Here's an example of how you might use multi-stage builds to build a Python application using Flask:</p> <pre><code># Use an official Python runtime as a parent image\nFROM python:3.8-slim-buster AS base\n\n# Set the working directory to /app\nWORKDIR /app\n\n# Copy the requirements file to the working directory\nCOPY requirements.txt .\n\n# Install any needed packages specified in requirements.txt\nRUN pip install --no-cache-dir --upgrade pip &amp;&amp; \\\n    pip install --no-cache-dir -r requirements.txt\n\n# Use a smaller image as the final base image\nFROM python:3.8-slim-buster\n\n# Set the working directory to /app\nWORKDIR /app\n\n# Copy the requirements file and installed packages from the previous stage\nCOPY --from=base /usr/local/lib/python3.8/site-packages /usr/local/lib/python3.8/site-packages\n\n# Copy the rest of the application code to the working directory\nCOPY . .\n\n# Start the Flask application\nCMD [\"python\", \"app.py\"]\n</code></pre> <p>In this example, the Dockerfile uses two stages. The first stage starts with the official Python 3.8 slim-buster image, sets the working directory to <code>/app</code>, and copies the <code>requirements.txt</code> file to the working directory. It then installs the required packages specified in the <code>requirements.txt</code> file and saves them to the image.</p> <p></p> <p>The second stage starts with the same <code>Python 3.8 slim-buster</code> image as the final base image. It sets the working directory to <code>/app</code>, copies the installed packages from the first stage to the image, copies the rest of the application code to the working directory, and starts the Flask application.</p> <p></p> <p>Using multi-stage builds can significantly reduce the size of your Docker images because you only include the necessary files and dependencies in the final image. In this example, the final image only includes the installed Python packages and the application code, which makes it much smaller than if it included the entire Python runtime.</p> <p></p> <p>Overall, using multi-stage builds is a best practice for optimizing your Docker images and reducing their size.</p>"},{"location":"docker/docker_best_practice/#use-caching-to-speed-up-builds","title":"Use caching to speed up builds","text":"<p>In Docker, every instruction in a Dockerfile creates a layer like we seen before. When a Dockerfile is built, Docker caches each layer, so that if the same instruction is used in a future build, Docker can use the cached layer instead of re-executing the instruction. This can greatly speed up the build process.</p> <p></p> <p>One way to take advantage of caching is to order the instructions in the Dockerfile such that the ones that change frequently are at the end, while the ones that change less frequently are at the beginning. For example, you might start with a base image, then copy in your application code, and finally install any dependencies.</p> <p></p> <p>It's also possible to explicitly tell Docker to use a cached layer with the --cache-from flag. This can be useful if you have multiple Dockerfiles that share some of the same layers. For example, if you have a base image that is used by multiple applications, you can build that image once and then use it as the cache for future builds of the applications.</p> <p></p> <p>Here's an example of how to use caching to speed up a Docker build:</p> <pre><code># Use an official Python runtime as a parent image\nFROM python:3.9-slim-buster\n\n# Set the working directory to /app\nWORKDIR /app\n\n# Copy the requirements file into the container\nCOPY requirements.txt .\n\n# Install any needed packages specified in requirements.txt\nRUN pip install --no-cache-dir -r requirements.txt\n\n# Copy the rest of the application code into the container\nCOPY . .\n\n# Expose port 80 for the web application\nEXPOSE 80\n\n# Start the web application\nCMD [\"python\", \"app.py\"]\n</code></pre> <p>In this example, the <code>COPY requirements.txt .</code> and <code>RUN pip install --no-cache-dir -r requirements.txt</code> instructions are near the beginning of the Dockerfile because they change less frequently than the application code. This means that Docker can cache those layers and reuse them in future builds, even if the application code has changed.</p>"},{"location":"docker/docker_best_practice/#clean-up-after-yourself","title":"Clean up after yourself","text":"<p>Cleaning up after yourself is an important best practice for Docker. This means removing any unused images, containers, volumes, and networks that are no longer needed. Not only does it save disk space, but it also ensures that the Docker environment is not cluttered with unnecessary artifacts that may cause conflicts or security issues.</p> <p></p> <p>Here are some tips for cleaning up after yourself in Docker:</p> <ol> <li>Remove unused containers: To remove unused containers, use the <code>docker container prune</code> command. This command removes all stopped containers. If you want to remove a specific container, use the <code>docker rm</code> command followed by the container ID.</li> <li>Remove unused images: To remove unused images, use the <code>docker image prune</code> command. This command removes all images that are not associated with any container. If you want to remove a specific image, use the <code>docker rmi</code> command followed by the image ID.</li> <li>Remove unused volumes: To remove unused volumes, use the <code>docker volume prune</code> command. This command removes all volumes that are not associated with any container. If you want to remove a specific volume, use the <code>docker volume rm</code> command followed by the volume name.</li> <li>Remove unused networks: To remove unused networks, use the <code>docker network prune</code> command. This command removes all networks that are not associated with any container. If you want to remove a specific network, use the <code>docker network rm</code> command followed by the network name.</li> <li>Use <code>--rm</code> option: When running containers, use the <code>--rm</code> option to automatically remove the container when it exits. This is especially useful for testing and development environments where you don't need to keep the container around.</li> </ol> <p>By following these best cleaning practices, you can keep your Docker environment clean and avoid cluttering it with unused artifacts.</p>"},{"location":"docker/docker_best_practice/#consider-security","title":"Consider security","text":"<p>Security is an important consideration when it comes to Docker containers. Here are some best practices to keep in mind:</p> <ol> <li>Use the latest version of the base image: It is important to use the latest version of the base image, as this will ensure that any security vulnerabilities in the base image have been patched.</li> <li>Avoid using root user: Running a container as root can be risky, as it can potentially allow an attacker to gain access to the host system. Instead, use a non-root user.</li> <li>Limit container capabilities: By default, containers have access to all capabilities of the host system. It is important to limit the capabilities of the container to only what it needs.</li> <li>Use a minimal base image: Using a minimal base image, such as Alpine, reduces the attack surface of the container by reducing the number of packages installed.</li> <li>Keep containers up to date: It is important to keep containers up to date with security patches and updates.</li> <li>Scan images for vulnerabilities: Use a vulnerability scanner to scan images for known vulnerabilities. This will help to identify any potential security issues.</li> <li>Consider network security: Secure network access to containers by using network segmentation, firewalls, and VPNs. A common practice is to run containers inside your cloud provider's VPC. </li> </ol>"},{"location":"docker/docker_best_practice/#quick-scan-a-container","title":"Quick scan a container","text":"<ol> <li> <p>First, install Trivy by following the installation instructions for your operating system from the official Trivy GitHub page: https://github.com/aquasecurity/trivy</p> </li> <li> <p>Then Pull a Docker image that you want to scan, for example, the official Python image:</p> </li> </ol> <pre><code>docker pull python:3.9-slim\n</code></pre> <ol> <li>Run Trivy against the image:</li> </ol> <pre><code>trivy image python:3.9-slim\n</code></pre> <p>This will scan the Python image and report any vulnerabilities found in the image's base image or any installed packages.</p> <p></p> <p>You can also scan a Dockerfile directly using the --file option:</p> <pre><code>trivy --file Dockerfile\n</code></pre> <p>This will scan the Dockerfile and report any vulnerabilities found in the base image or any installed packages.</p> <p></p> <p>Note that scanning Docker images is just one part of a comprehensive security strategy for containerized applications. It's also important to ensure that your containers are configured securely, that you use strong authentication and authorization mechanisms, and that you regularly apply security updates and patches to your container images.</p> <p></p> <p>By following these best practices, you can help to ensure that your Docker containers are secure and less vulnerable to attack.</p>"},{"location":"docker/docker_best_practice/#debugging-and-troubleshooting","title":"Debugging and Troubleshooting","text":"<ol> <li>Check container logs: Container logs can provide valuable information on what is happening inside the container. Use <code>docker logs &lt;container-id&gt;</code> to view container logs and troubleshoot issues.</li> <li>Use docker exec to troubleshoot running containers: <code>docker exec</code> allows you to run commands inside a running container, which can be useful for troubleshooting issues.</li> <li>Check container health: Use <code>docker ps</code> to check the status of running containers. If a container is not running, use <code>docker ps -a</code> to view all containers, including stopped ones.</li> <li>Check resource utilization: Docker containers can consume a lot of resources. Use <code>docker stats</code> to view resource utilization for running containers.</li> <li>Use the correct Docker command: Use the correct Docker command for the task at hand. For example, <code>docker stop</code> will gracefully stop a container, while <code>docker kill</code> will forcibly stop a container.</li> <li>Check networking: If your container is not communicating with other containers or services, check the networking configuration. Use docker network ls to view available networks and <code>docker network inspect</code> to view details of a specific network.</li> <li>Consider container security: Ensure that your container is running in a secure environment and follow security best practices for your application like we have seen before. </li> </ol> <p>By following best practices for Dockerfile design and container optimization and knowing how to troubleshoot common issues with Docker containers, you can ensure that your Docker containers are running smoothly and securely.</p>"},{"location":"docker/docker_commands/","title":"Docker CLI Commands","text":"<p>The Docker CLI (Command Line Interface) provides a set of commands for working with Docker images and containers. These commands are used to build, run, manage, and interact with Docker images and containers.</p> <p>Here are some of the most common Docker CLI commands:</p>"},{"location":"docker/docker_commands/#docker-build","title":"<code>docker build</code>","text":"<p>This command is used to build a Docker image from a Dockerfile. Example:</p> <pre><code>docker build -t myimage .\n</code></pre> <p>This command builds a Docker image from the Dockerfile in the current directory and tags it with the name <code>myimage</code>. The option <code>-t</code> or <code>--tag</code> : Sets the name and optionally a tag for the Docker image.</p>"},{"location":"docker/docker_commands/#docker-build-options","title":"docker build options","text":""},{"location":"docker/docker_commands/#tag-t","title":"Tag <code>-t</code>","text":"<p>Example:</p> <pre><code>docker build -t myimage:latest .\n</code></pre> <p>or </p> <pre><code>docker build -t myimage:01 .\n</code></pre> <p>This command builds a Docker image from the Dockerfile in the current directory, tags it with the name myimage and the <code>latest</code> or <code>01</code> tags.</p>"},{"location":"docker/docker_commands/#file-f","title":"File <code>-f</code>","text":"<p>The option <code>-f</code>, <code>--file</code> : Specifies the name and location of the Dockerfile to use. Example:</p> <pre><code>docker build -t myimage:latest -f path/to/Dockerfile.dev .\n</code></pre> <p>This command builds a Docker image from the Dockerfile located at <code>path/to/Dockerfile.dev</code>, tags it with the name <code>myimage</code> and the <code>latest</code> tag.</p>"},{"location":"docker/docker_commands/#cache-no-cache","title":"Cache <code>--no-cache</code>","text":"<p><code>--no-cache</code> : Disables caching during the build process. Example:</p> <pre><code>docker build --no-cache -t myimage:latest .\n</code></pre> <p>This command builds a Docker image from the Dockerfile in the current directory, without using any cached layers.</p>"},{"location":"docker/docker_commands/#docker-run","title":"<code>docker run</code>","text":"<p>This command is used to run a Docker container from a Docker image.</p> <p>Example:</p> <pre><code>docker run --name mycontainer myimage\n</code></pre> <p>This command runs a Docker container from the <code>myimage</code> Docker image and names the container <code>mycontainer</code> with the tag <code>--name</code>. </p>"},{"location":"docker/docker_commands/#docker-run-options","title":"docker run options","text":""},{"location":"docker/docker_commands/#tag-d","title":"Tag <code>-d</code>","text":"<p>The option <code>-d</code>, <code>--detach</code> : Runs the container in detached mode, in the background so you can use your terminal as you want is not stuck in the process. Example:</p> <pre><code>docker run -d myimage\n</code></pre> <p>This command runs the <code>myimage</code> Docker image in detached mode, in the background.</p>"},{"location":"docker/docker_commands/#tag-p","title":"Tag <code>-p</code>","text":"<p>The option <code>-p</code>, <code>--publish</code> : Publishes a container's port(s) to the host machine. Example:</p> <pre><code>docker run -p 80:80 myimage\n</code></pre> <p>This command runs the myimage Docker image and maps port <code>80</code> inside the container to port <code>80</code> on the host machine.</p>"},{"location":"docker/docker_commands/#tag-name","title":"Tag <code>--name</code>","text":"<p>The option <code>--name</code>: Assigns a name to the container. Example:</p> <pre><code>docker run --name mycontainer myimage\n</code></pre> <p>This command runs the <code>myimage</code> Docker image and assigns the name <code>mycontainer</code> to the resulting container.</p>"},{"location":"docker/docker_commands/#tag-e","title":"Tag <code>-e</code>","text":"<p>The option  <code>-e</code>, <code>--env</code> : Sets environment variables inside the container. Example:</p> <pre><code>docker run -e MYVAR=myvalue myimage\n</code></pre> <p>This command runs the <code>myimage</code> Docker image and sets the environment variable <code>MYVAR</code> to <code>myvalue</code> inside the container.</p>"},{"location":"docker/docker_commands/#tag-v","title":"Tag <code>-v</code>","text":"<p>The option <code>-v</code>, <code>--volume</code> : Mounts a volume from the host machine into the container. Example:</p> <pre><code>docker run -v /path/on/host:/path/in/container myimage\n</code></pre> <p>This command runs the <code>myimage</code> Docker image and mounts the directory <code>/path/on/host</code> on the host machine to the directory <code>/path/in/container</code> inside the container.</p>"},{"location":"docker/docker_commands/#tag-it","title":"Tag <code>-it</code>","text":"<p>The option <code>-it</code>, <code>--interactive</code> : Runs the container in interactive mode, allowing input from the user. Example:</p> <pre><code>docker run -it myimage /bin/bash\n</code></pre> <p>This command runs the <code>myimage</code> Docker image in interactive mode and starts a bash shell inside the container.</p> <p>You can of course use multiple tags like : </p> <pre><code>docker run -d --name mycontainer -p 80:80 myimage\n</code></pre> <p>This command runs a Docker container from the myimage Docker image in detached mode (<code>-d</code>), names the container mycontainer (<code>--name</code>), maps port <code>80</code> on the host machine to port <code>80</code> inside the container (<code>-p</code>), and uses the myimage Docker image as the container's base image.</p>"},{"location":"docker/docker_commands/#docker-ps","title":"<code>docker ps</code>","text":"<p>This command is used to list running Docker containers. Example:</p> <pre><code>docker ps\n</code></pre> <p>This command lists all running Docker containers. You can also list the exited container with the <code>-a</code> option , it is very usefull in case you want to debug a container.</p> <pre><code>docker ps -a\n</code></pre>"},{"location":"docker/docker_commands/#docker-stop","title":"<code>docker stop</code>","text":"<p>This command is used to stop a running Docker container. Example:</p> <pre><code>docker stop mycontainer\n</code></pre> <p>This command stops the mycontainer Docker container.</p>"},{"location":"docker/docker_commands/#docker-rm","title":"<code>docker rm</code>","text":"<p>This command is used to remove a stopped Docker container. Example:</p> <pre><code>docker rm mycontainer\n</code></pre> <p>This command removes the mycontainer Docker container.</p>"},{"location":"docker/docker_commands/#docker-images","title":"<code>docker images</code>","text":"<p>This command is used to list Docker images. Example:</p> <pre><code>docker images\n</code></pre> <p>This command lists all Docker images on the local machine.</p>"},{"location":"docker/docker_commands/#docker-rmi","title":"<code>docker rmi</code>","text":"<p>This command is used to remove a Docker image.</p> <p>Example:</p> <pre><code>docker rmi myimage\n</code></pre> <p>This command removes the myimage Docker image.</p>"},{"location":"docker/docker_commands/#docker-exec","title":"<code>docker exec</code>","text":"<p>This command is used to execute a command inside a running Docker container.</p> <p>Example:</p> <pre><code>docker exec mycontainer ls /app\n</code></pre> <p>This command executes the ls <code>/app</code> command inside the mycontainer Docker container.</p>"},{"location":"docker/docker_commands/#docker-logs","title":"<code>docker logs</code>","text":"<p>This command is used to view the logs for a Docker container.</p> <p>Example:</p> <pre><code>docker logs mycontainer\n</code></pre> <p>This command displays the logs for the mycontainer Docker container.</p>"},{"location":"docker/docker_commands/#docker-inspect","title":"<code>docker inspect</code>","text":"<p>This command is used to view detailed information about a Docker object, such as a container or image.</p> <p>Example:</p> <pre><code>docker inspect mycontainer\n</code></pre> <p>This command displays detailed information about the mycontainer Docker container.</p>"},{"location":"docker/docker_commands/#docker-pull","title":"<code>docker pull</code>","text":"<p>This command is used to pull a Docker image from a registry.</p> <p>Example:</p> <pre><code>docker pull nginx:latest\n</code></pre> <p>This command pulls the latest version of the nginx Docker image from the Docker Hub registry.</p>"},{"location":"docker/docker_commands/#docker-push","title":"<code>docker push</code>","text":"<p>This command is used to push a Docker image to a registry. Example:</p> <pre><code>docker push myregistry/myimage:latest\n</code></pre> <p>This command pushes the myimage Docker image with the latest tag to the myregistry Docker registry.</p>"},{"location":"docker/docker_commands/#wrap-up","title":"Wrap-up","text":"<p>These are just a few of the most common Docker CLI commands. There are many other commands available that can be used for more advanced use cases, such as networking, volumes, and swarm management. By mastering these basic Docker CLI commands, you can get started with Docker and start</p>"},{"location":"docker/docker_compose/","title":"Docker-compose","text":""},{"location":"docker/docker_compose/#what-is-docker-compose-and-why-use-it","title":"What is Docker Compose and Why Use It?","text":"<p>Docker Compose is a tool that allows you to define and run multi-container Docker applications. It makes it easy to start and stop multiple containers with a single command, and provides a way to configure the containers and their relationships to each other.</p> <p></p> <p>Docker Compose is particularly useful for running complex applications that are made up of multiple services, each with its own requirements and dependencies. By using Docker Compose, you can define the configuration for all of these services in a single file, making it easier to manage and deploy your application.</p>"},{"location":"docker/docker_compose/#yaml-syntax","title":"<code>YAML</code> syntax","text":"<p>YAML (short for \"YAML Ain't Markup Language\") is a human-readable data serialization language. It is often used for configuration files and data exchange between different programming languages. YAML is designed to be easily read by humans and can be used for complex or simple data structures.</p> <p></p> <p>Docker Compose uses YAML syntax for its configuration files because it is easy to read and write. Docker Compose configuration files define all the services that make up an application, as well as any associated networks, volumes, and environment variables. By using YAML syntax, it allows developers to easily define the relationships between the different parts of an application and deploy it consistently across different environments.</p> <p></p> <p>Few this to know about <code>yaml</code> syntax : </p> <ul> <li>YAML files use indentation to denote hierarchy, instead of curly braces like JSON or XML.</li> <li>The syntax is strict about indentation, so it's important to use consistent spacing (usually 2 or 4 spaces) for each level of hierarchy.</li> <li>Key-value pairs are written as key: value, with the key and value separated by a colon and a space.</li> <li>Lists are denoted by a dash (-) followed by a space, and can contain any type of value.</li> <li>Comments can be added using the # symbol.</li> </ul> <p>Here's an example YAML file that defines a simple docker-compose web service:</p> <pre><code>version: '3'\nservices:\n  web:\n    image: nginx:latest\n    ports:\n      - \"8080:80\"\n</code></pre> <p>In this file:</p> <ul> <li><code>version</code> specifies the Docker Compose file version.</li> <li><code>services</code> is a list of Docker services to be created and run.</li> <li><code>web</code> is the name of the first service.</li> <li><code>image</code> specifies the Docker image to be used for the service.</li> <li><code>ports</code> maps a port on the host machine to a port in the container.</li> <li><code>\"8080:80\"</code> maps port 8080 on the host (your local machine or virtual machine in case you are in a VM) to port 80 in the container.</li> </ul> <p>This is just a basic example, but hopefully it gives you an idea of how the YAML syntax works but it will be helpful for the next part.</p>"},{"location":"docker/docker_compose/#docker-compose-for-a-simple-python-app-and-redis-database","title":"Docker Compose for a simple Python App and Redis database","text":"<p>Let's create a two containers application with a <code>docker-compose.yml</code> file with a python app and a redis database in order to count how many times the page is reload.</p> <p></p> <p></p> <p></p> <p>First thing first, write our <code>app.py</code> script :</p> <pre><code>from flask import Flask\nfrom redis import Redis\n\napp = Flask(__name__)\nredis = Redis(host='redis-container', port=6379)\n\n@app.route('/')\ndef hello():\n    redis.incr('hits')\n    return ' - - - This basic web page has been viewed {} time(s) - - -'.format(redis.get('hits'))\n\n\nif __name__ == \"__main__\":\n    app.run(host=\"0.0.0.0\", debug=True)\n</code></pre> <p>and the <code>requirements.txt</code> file : </p> <pre><code>flask\nredis\n</code></pre> <p>This is a simple Python Flask web application that increments a counter each time the / route is accessed and displays the number of times it has been accessed. The application uses Redis as a datastore to store the hit counter.</p> <p></p> <p>Here is how our <code>app.py</code> script works:</p> <ol> <li>The Flask library is imported, which allows us to create a web application.</li> <li>The Redis library is imported, which allows us to connect to a Redis instance and manipulate data.</li> <li>The Flask application is created and the Redis client is initialized, connecting to the Redis container named \"redis-container\" at port 6379.</li> <li>A route for the / endpoint is defined. When this route is accessed, the hit counter in Redis is incremented and the current count is displayed on the page.</li> <li>Finally, the application is run, listening on all network interfaces (0.0.0.0) on port 5000 and with debugging enabled.</li> </ol> <p>Then, we must write a <code>Dockerfile</code> : </p> <pre><code>FROM python:3.6\nWORKDIR /app\nCOPY . .\nRUN pip install -r requirements.txt\nCMD python app.py\n</code></pre> <p>Like before this is a simple <code>Dockerfile</code> for a python application. </p>"},{"location":"docker/docker_compose/#write-the-docker-composeyml-of-our-app","title":"Write the <code>docker-compose.yml</code> of our app","text":"<pre><code>version: '3'\nservices:\n    web:\n        build: ./app\n        ports:\n            - \"5000:5000\"\n        volumes:\n            - ./app:/app\n        depends_on:\n            - redis-container\n\n    redis-container:\n        image: redis\n</code></pre> <p>This script is a Docker Compose file that describes two services that will be run in Docker containers: a web service and a Redis service.</p> <p></p> <p>The <code>web</code> service is defined by the <code>web</code> service block. It specifies that the <code>web</code> service should be built from the Dockerfile in the <code>./app</code> directory, and should expose port 5000 on the host machine. The volumes directive maps the <code>./app</code> directory on the host to the <code>/app</code> directory in the container, allowing changes to the code to be immediately reflected in the container. The depends_on directive specifies that the <code>web</code> service should not start until the Redis service is running.</p> <p></p> <p>The Redis service is defined by the <code>redis-container</code> block. It specifies that the Redis image should be used to create the service.</p> <p></p> <p>This is the architeture of our project : </p> <pre><code>.\n|_docker-compose.yml\n|_app\n  |_Dockerfile\n  |_requirements.txt\n  |_app.py\n</code></pre> <p>Together, these services can be started with the <code>docker-compose up</code> command, which will build and start the web and Redis containers, and connect them together on a default Docker network.</p> <p></p> <p> </p> <p></p> <p>You can also run your project in background with <code>-d</code> option then you should see your containers up and running with the command <code>docker ps</code></p>"},{"location":"docker/docker_compose/#docker-compose-for-a-python-app-and-postgresql","title":"Docker Compose for a Python App and PostgreSQL","text":"<p>Now that we understand how two containers works together let's code an application with a more efficient database : postgreSQL. </p>"},{"location":"docker/docker_compose/#what-is-postgresql","title":"What is PostgreSQL","text":"<p>PostgreSQL, also known as Postgres, is a powerful and open-source relational database management system. It uses and extends the SQL language and provides many features such as support for JSON and other NoSQL features, scalability, and extensibility. It can run on various platforms such as Windows, macOS, Linux, and Unix.</p> <p></p> <p>Many organizations use Postgres for their data storage needs due to its reliability, robustness, and community support.</p>"},{"location":"docker/docker_compose/#set-up-the-project","title":"Set up the project","text":"<p>To create a Docker Compose file for your Python app, you'll need to define the services that make up your application. Each service is defined in the Docker Compose file as a separate block of configuration. In this example we will take the <code>nortwhind</code> database here as base for our database service.</p> <p></p> <p>Download or <code>git clone</code> the <code>nortwhind</code> database here and open the <code>docker-compose.yml</code> file bellow who define two services, one for a monitoring application <code>pgadmin</code> and one for a PostgreSQL database <code>db</code> :</p> <pre><code>version: '3'\n\nservices:\n  db:\n    container_name: db\n    image: postgres:latest\n    environment:\n      POSTGRES_DB: northwind\n      POSTGRES_USER: postgres\n      POSTGRES_PASSWORD: postgres\n    volumes:\n      - postgresql_bin:/usr/lib/postgresql\n      - postgresql_data:/var/lib/postgresql/data\n      - ./northwind.sql:/docker-entrypoint-initdb.d/northwind.sql\n      - ./files:/files\n    ports:\n      - 55432:5432\n    networks:\n      - db\n\n  pgadmin:\n    container_name: pgadmin\n    image: dpage/pgadmin4\n    environment:\n      PGADMIN_DEFAULT_EMAIL: pgadmin4@pgadmin.org\n      PGADMIN_DEFAULT_PASSWORD: postgres\n      PGADMIN_LISTEN_PORT: 5050\n      PGADMIN_CONFIG_SERVER_MODE: 'False'\n    volumes:\n      - postgresql_bin:/usr/lib/postgresql\n      - pgadmin_root_prefs:/root/.pgadmin\n      - pgadmin_working_dir:/var/lib/pgadmin\n      - ./files:/files\n    ports:\n      - 5050:5050\n    networks:\n      - db\n\nnetworks:\n  db:\n    driver: bridge\n\nvolumes:\n  pgadmin_root_prefs:\n    driver: local\n  pgadmin_working_dir:\n    driver: local\n  postgresql_data:\n    driver: local\n  postgresql_bin:\n    driver: local\n</code></pre> <p>Let's break down this Docker Compose file:</p> <ul> <li>version: '3': This specifies the version of the Docker Compose file format that we're using.</li> <li>services: This is where we define the services that make up our application.<ul> <li><code>db</code>: The Postgres database service.<ul> <li><code>container_name</code>: Sets the name of the container to db.</li> <li><code>image</code>: postgres:latest: Specifies the image to use for the container.</li> <li><code>environment</code>: Sets environment variables for the container.<ul> <li><code>POSTGRES_DB</code>: northwind: Specifies the name of the database to create.</li> <li><code>POSTGRES_USER</code>: postgres: Specifies the username for the database.</li> <li><code>POSTGRES_PASSWORD</code>: postgres: Specifies the password for the database.</li> </ul> </li> <li><code>volumes</code>: Mounts volumes for the container.<ul> <li><code>postgresql_bin:/usr/lib/postgresql</code>: Mounts the PostgreSQL binaries.</li> <li><code>postgresql_data:/var/lib/postgresql/data</code>: Mounts the PostgreSQL data directory.</li> <li><code>./northwind.sql:/docker-entrypoint-initdb.d/northwind.sql</code>: Copies the northwind.sql script into the container for initializing the database.</li> <li><code>./files:/files</code>: Mounts the files directory into the container.</li> </ul> </li> <li><code>ports</code>: Maps ports between the container and the host.<ul> <li><code>55432:5432</code>: Maps port 5432 inside the container to port 55432 on the host.</li> </ul> </li> </ul> </li> <li><code>networks</code>: Specifies the networks to connect the container to.<ul> <li><code>db</code>: Connects the container to the db network.</li> </ul> </li> <li><code>pgadmin</code>: The pgAdmin web interface service in order to visualize our database <ul> <li><code>image : dpage/pgadmin4</code>: Specifies the image to use for the container.</li> <li><code>environment</code>: Sets environment variables for the container.<ul> <li><code>PGADMIN_DEFAULT_EMAIL</code>: pgadmin4@pgadmin.org: Specifies the default email for pgAdmin.</li> <li><code>PGADMIN_DEFAULT_PASSWORD</code>: postgres: Specifies the default password for pgAdmin.</li> <li><code>PGADMIN_LISTEN_PORT: 5050</code>: Specifies the port for pgAdmin to listen on.</li> <li><code>PGADMIN_CONFIG_SERVER_MODE</code>: 'False': Disables server mode for pgAdmin.</li> </ul> </li> <li><code>volumes</code>: Mounts volumes for the container.</li> <li><code>ports</code>: Maps ports between the container and the host.<ul> <li><code>5050:5050</code>: Maps port 5050 inside the container to port 5050 on the host.</li> </ul> </li> </ul> </li> </ul> </li> <li>networks: Specifies the networks to create.<ul> <li><code>db</code>: Creates the db network.</li> <li><code>driver: bridge</code>: Specifies the driver to use for the network, this is the standard driver \ud83e\udd13</li> </ul> </li> <li>volumes: Specifies the volumes to create, see volume part in the table of content for more detailed </li> </ul> <p>Once you've defined your Docker Compose file, you can use the <code>docker-compose up</code> command to start and stop your application. Here are some of the most common commands:</p> <ul> <li><code>docker-compose up</code>: This command starts your application and attaches your terminal to the logs of all running containers. You can use Ctrl+C to stop the containers and exit.</li> <li><code>docker-compose up -d</code>: This command starts your application in detached mode, which means that it runs in the background. You can use docker-compose logs to view the logs of your containers.</li> <li><code>docker-compose down</code>: This command stops and removes all containers, networks, and volumes that were created by docker-compose up.</li> <li><code>docker-compose ps</code>: This command lists all running containers in your Docker Compose application.</li> <li><code>docker-compose build</code>: This command builds the images for all of the services in your Docker Compose file.</li> </ul> <p>By using Docker Compose, you can easily start and stop multiple containers with a single command, and manage the configuration of all of your services in a single file. This makes it easier to manage and deploy complex applications that are made up of multiple services.</p>"},{"location":"docker/docker_compose/#pgadmin-interface","title":"PgAdmin interface","text":"<p>First let's confirm our containers are up and running by taping <code>docker ps</code> command. If you see the container running like :</p> <pre><code>a76abdcbf8da   dpage/pgadmin4             \"/entrypoint.sh\"         About an hour ago   Up About an hour        80/tcp, 443/tcp, 0.0.0.0:5050-&gt;5050/tcp, :::5050-&gt;5050/tcp\n</code></pre> <p>To see our database go to : (localhost:5050)[http://localhost:5050] and write a random password (like root) then register our database by running the following command : </p> <ol> <li>Add a new server in PgAdmin </li> <li>In the general Tab, write the paramater <code>Name = db</code></li> <li>In the Connection Tab write the following parameters : </li> </ol> <pre><code>Host name: db\nUsername: postgres\nPassword: postgres\n</code></pre> <ol> <li>Then, select database \"northwind\" and you can now see all the tables and metadata \ud83e\udd73</li> </ol>"},{"location":"docker/docker_compose/#add-a-python-app","title":"Add a Python app","text":"<pre><code>from fastapi import FastAPI\nfrom sqlalchemy import create_engine, text\nfrom sqlalchemy.orm import sessionmaker\n\napp = FastAPI()\nengine = create_engine('postgresql://postgres:postgres@db/northwind')\nSession = sessionmaker(bind=engine)\n\n@app.get('/')\ndef read_root():\n\n    session = Session()\n    result = session.execute(text('SELECT customer_id, company_name, contact_name FROM customers LIMIT 10'))\n    return {'Customers info': [dict(customerid=row[0], companyname=row[1], contactname=row[2]) for row in result]}\n</code></pre> <p>This application uses the FastAPI framework to define a simple endpoint that returns a JSON response with a greeting and a value from a PostgreSQL database.</p> <p></p> <p>To run this application using Docker Compose, you'll need to save this file as main.py in the same directory as your Dockerfile, and update your Docker Compose file to include the following environment variable for the app service and dependence :</p> <pre><code>environment:\n  DB_HOST: db\ndepends_on:\n      - db\n</code></pre> <p>This environment variable tells the application where to find the PostgreSQL database and tell the application to wait for the lunch of the <code>db</code> service.</p>"},{"location":"docker/docker_compose/#integrate-our-app-to-the-docker-composeyml-file","title":"Integrate our app to the <code>docker-compose.yml</code> file","text":"<pre><code>version: '3'\n\nservices:\n  db:\n    container_name: db\n    image: postgres:latest\n    environment:\n      POSTGRES_DB: northwind\n      POSTGRES_USER: postgres\n      POSTGRES_PASSWORD: postgres\n    volumes:\n      - postgresql_bin:/usr/lib/postgresql\n      - postgresql_data:/var/lib/postgresql/data\n      - ./northwind.sql:/docker-entrypoint-initdb.d/northwind.sql\n      - ./files:/files\n    ports:\n      - 55432:5432\n    networks:\n      - db\n\n  pgadmin:\n    container_name: pgadmin\n    image: dpage/pgadmin4\n    environment:\n      PGADMIN_DEFAULT_EMAIL: pgadmin4@pgadmin.org\n      PGADMIN_DEFAULT_PASSWORD: postgres\n      PGADMIN_LISTEN_PORT: 5050\n      PGADMIN_CONFIG_SERVER_MODE: 'False'\n    volumes:\n      - postgresql_bin:/usr/lib/postgresql\n      - pgadmin_root_prefs:/root/.pgadmin\n      - pgadmin_working_dir:/var/lib/pgadmin\n      - ./files:/files\n    ports:\n      - 5050:5050\n    networks:\n      - db\n\n  app:\n    build:\n      context: .\n      dockerfile: Dockerfile\n    environment:\n      DB_HOST: db\n    depends_on:\n      - db\n    ports:\n      - \"8000:8000\"\n    networks:\n      - db\n\nnetworks:\n  db:\n    driver: bridge\n\nvolumes:\n  pgadmin_root_prefs:\n    driver: local\n  pgadmin_working_dir:\n    driver: local\n  postgresql_data:\n    driver: local\n  postgresql_bin:\n    driver: local\n</code></pre> <p>The <code>app</code> service is a container that will host a Python application that uses the <code>northwind</code> database created by the <code>db</code> service. The app container will be built using the Dockerfile located in the same directory as the <code>docker-compose.yml</code> file. The <code>depends_on</code> property indicates that the app container must be started after the <code>db</code> container is running.</p> <p></p> <p>The environment property sets the <code>DB_HOST</code> environment variable, which is used in the application to connect to the <code>db</code> container. The ports property maps port <code>8000</code> of the <code>app</code> container to port <code>8000</code> of the host machine, allowing access to the FastAPI application from a web browser. The <code>networks</code> property specifies that the <code>app</code> container is connected to the <code>db</code> network, allowing communication between the application and the database.</p> <p></p> <p>Once you've made these changes, you can start your application using Docker Compose with the following command:</p> <pre><code>docker-compose up --build\n</code></pre> <p>This will start both the <code>db</code> and <code>app</code> services and rebuild it just in case, and you should be able to access the application by visiting http://localhost:8000 in your web browser.</p>"},{"location":"docker/docker_compose/#stop-docker-compose","title":"Stop docker-compose","text":"<p>Stop the server that was launched by docker compose up via <code>Ctrl-C</code> if you are in interactive mode, then remove the containers via:</p> <pre><code>docker-compose down\n</code></pre> <p>or just go to the root of your repository and run <code>docker-compose down</code></p>"},{"location":"docker/docker_https/","title":"Docker and HTTPS","text":""},{"location":"docker/docker_https/#what-is-https","title":"What is HTTPS","text":"<p>HTTPS stands for Hypertext Transfer Protocol Secure, which is an extension of the HTTP protocol used for secure communication over the internet. It is a way of encrypting the data that is transmitted between a web browser and a web server, making it more difficult for attackers to intercept and steal sensitive information, such as login credentials or credit card numbers.</p> <p></p> <p>To enable HTTPS on a website, you need to obtain an SSL (Secure Sockets Layer) certificate. An SSL certificate is a digital certificate that verifies the identity of a website and encrypts the data transmitted between the web server and the client's browser. SSL certificates are issued by trusted certificate authorities (CA), such as Let's Encrypt, Comodo, and Symantec.</p> <p></p> <p>There are several ways to get an SSL certificate, depending on your needs and budget. Here are some options:</p> <ul> <li>Let's Encrypt: Let's Encrypt is a free and open certificate authority that provides SSL certificates for websites. It is widely used and trusted, and can be easily integrated with many web servers, including Apache and Nginx.</li> <li>Paid SSL certificates: There are many companies that offer paid SSL certificates, including Comodo, Symantec, and DigiCert. These certificates usually provide a higher level of validation and come with more advanced features, such as extended validation and wildcard certificates.</li> <li>Cloud hosting providers: Many cloud hosting providers, such as AWS, Google Cloud, and Azure, offer SSL certificates as part of their hosting packages. These certificates are often managed by the hosting provider, making it easier to install and renew them.</li> </ul> <p>To obtain an SSL certificate, you typically need to generate a certificate signing request (CSR) on your web server, which contains information about your website and your public key. You then submit the CSR to a certificate authority, which will verify your identity and issue a certificate. Once you receive the certificate, you need to install it on your web server and configure your server to use HTTPS.</p> <p></p> <p>Keep in mind that SSL certificates have expiration dates and need to be renewed periodically, usually every one or two years. It's also important to ensure that your web server and applications are configured correctly to use HTTPS, and to keep your server and software up to date to address any security vulnerabilities.</p>"},{"location":"docker/docker_https/#add-https-to-our-pythonpostgres-app","title":"Add HTTPS to our Python/Postgres app","text":"<p>Let's take our project from the previous section and add an Nginx service \ud83e\udd13</p>"},{"location":"docker/docker_https/#nginx","title":"Nginx","text":"<p>Nginx is a popular open-source web server that can also function as a reverse proxy, load balancer, and HTTP cache. It is known for its high performance, stability, and ability to handle a large number of simultaneous connections.</p> <p></p> <p>Developers should be familiar with Nginx because it is commonly used as a frontend web server in production environments. In addition to its performance benefits, Nginx is also highly customizable and can be used to handle complex routing, authentication, and security configurations.</p> <p></p> <p>Nginx also integrates well with many popular web frameworks and technologies, making it a valuable tool for developers who are building web applications. By leveraging Nginx's features, developers can improve the performance, scalability, and security of their applications.</p>"},{"location":"docker/docker_https/#generate-a-free-ssl-certificate","title":"Generate a free ssl certificate","text":"<p>First go to the root of your project and create a new directory call <code>certs</code> and then run this command :</p> <pre><code>openssl req -x509 -newkey rsa:4096 -keyout certs/key.pem -out certs/cert.pem -days 365 -nodes\n</code></pre> <p>This will create a certs folder and generate a self-signed SSL certificate with a private key (<code>key.pem</code>) and a public certificate (<code>cert.pem</code>) that are valid for 365 days.</p> <p></p> <p>Then add execution right to the private key in order to be executed by our nginx service inside our <code>Dockerfile</code> with the following command : </p> <pre><code>chmod +x certs/key.pem\n</code></pre>"},{"location":"docker/docker_https/#create-an-nginxconf-file","title":"Create an <code>nginx.conf</code> file","text":"<p>Go to the root of your project and create a new file called <code>nginx.conf</code></p> <pre><code>events {}\n\nhttp {\n  upstream app {\n    server app:8000;\n  }\n\n  server {\n    listen 80;\n    listen [::]:80;\n    server_name yourdomain.com;\n    return 301 https://$host$request_uri;\n  }\n\n  server {\n    listen 443 ssl http2;\n    listen [::]:443 ssl http2;\n    server_name yourdomain.com;\n\n    ssl_certificate /etc/ssl/certs/cert.pem;\n    ssl_certificate_key /etc/ssl/certs/key.pem;\n\n    location / {\n      proxy_pass http://app;\n      proxy_set_header Host $host;\n      proxy_set_header X-Real-IP $remote_addr;\n      proxy_set_header X-Forwarded-Proto https;\n      proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n    }\n  }\n}\n</code></pre> <p>We will not dig in detail this script in this course section just make sure to replace <code>yourdomain.com</code> with your actual domain name, and update the SSL certificate file paths to match your file names and folder locations.</p>"},{"location":"docker/docker_https/#refactor-our-docker-composeyml-file","title":"Refactor our <code>docker-compose.yml</code> file","text":"<pre><code>version: '3'\n\nservices:\n  db:\n    container_name: db\n    image: postgres:latest\n    environment:\n      POSTGRES_DB: northwind\n      POSTGRES_USER: postgres\n      POSTGRES_PASSWORD: postgres\n    volumes:\n      - postgresql_bin:/usr/lib/postgresql\n      - postgresql_data:/var/lib/postgresql/data\n      - ./northwind.sql:/docker-entrypoint-initdb.d/northwind.sql\n      - ./files:/files\n    ports:\n      - 55432:5432\n    networks:\n      - db\n\n  pgadmin:\n    container_name: pgadmin\n    image: dpage/pgadmin4\n    environment:\n      PGADMIN_DEFAULT_EMAIL: pgadmin4@pgadmin.org\n      PGADMIN_DEFAULT_PASSWORD: postgres\n      PGADMIN_LISTEN_PORT: 5050\n      PGADMIN_CONFIG_SERVER_MODE: 'False'\n    volumes:\n      - postgresql_bin:/usr/lib/postgresql\n      - pgadmin_root_prefs:/root/.pgadmin\n      - pgadmin_working_dir:/var/lib/pgadmin\n      - ./files:/files\n    ports:\n      - 5050:5050\n    networks:\n      - db\n\n  app:\n    build:\n      context: .\n      dockerfile: Dockerfile\n    environment:\n      DB_HOST: db\n    depends_on:\n      - db\n    ports:\n      - \"8000:8000\"\n    networks:\n      - db\n      - mynetwork\n\n  nginx:\n    image: nginx:latest\n    ports:\n      - \"80:80\"\n      - \"443:443\"\n    volumes:\n      - ./nginx.conf:/etc/nginx/nginx.conf\n      - ./certs:/etc/ssl/certs\n    networks:\n      - mynetwork\n    depends_on:\n      - app\n    restart: always\n\nnetworks:\n  db:\n    driver: bridge\n  mynetwork:\n    driver: bridge\n\n\nvolumes:\n  pgadmin_root_prefs:\n    driver: local\n  pgadmin_working_dir:\n    driver: local\n  postgresql_data:\n    driver: local\n  postgresql_bin:\n    driver: local\n</code></pre> <p>Let's talk about the ppart of the docker-compose file defines a service named <code>nginx</code> that is based on the <code>nginx:latest</code> Docker image. Here is a detailed explanation of each section:</p> <ul> <li><code>image: nginx:latest</code>: This line specifies the Docker image to use for the nginx service, which is <code>nginx:latest</code>.</li> <li><code>ports</code>: This section maps the container ports to the host ports. It exposes the container ports <code>80</code> and <code>443</code> to the host machine.</li> <li><code>volumes</code>: This section maps the host directories or files to the container directories or files. Here, it mounts the <code>nginx.conf</code> file from the current directory into the container's <code>/etc/nginx/nginx.conf</code> path. It also mounts the certs directory from the current directory into the container's <code>/etc/ssl/certs</code> path.</li> <li><code>networks</code>: This section specifies the networks to which this service is attached. In this case, it is attached to the mynetwork network.</li> <li><code>depends_on</code>: This section specifies that the <code>nginx</code> service depends on the <code>app</code> service to start. This means that the <code>app</code> service will be started before the nginx service.</li> <li><code>restart</code>: This line specifies that the container should always be restarted if it stops for any reason.</li> </ul> <p>The <code>networks</code> section defines two networks: <code>db</code> and <code>mynetwork</code>. The networks are bridge driver type</p> <p></p> <p>Then you can run <code>docker-compose up -d</code> and you should see the nginx forwarding our app and all our container like this : </p> <pre><code>fe86842a56e1   nginx:latest               \"/docker-entrypoint.\u2026\"   19 seconds ago   Up 18 seconds           0.0.0.0:80-&gt;80/tcp, :::80-&gt;80/tcp, 0.0.0.0:443-&gt;443/tcp, :::443-&gt;443/tcp\nd05f1ca65c2f   northwind_psql_app         \"uvicorn app:app --h\u2026\"   19 seconds ago   Up 18 seconds           80/tcp, 0.0.0.0:8000-&gt;8000/tcp, :::8000-&gt;8000/tcp                                                                  northwind_psql_app_1\n51553cc3b247   postgres:latest            \"docker-entrypoint.s\u2026\"   9 hours ago      Up 19 seconds           0.0.0.0:55432-&gt;5432/tcp, :::55432-&gt;5432/tcp                                                                        db\na76abdcbf8da   dpage/pgadmin4             \"/entrypoint.sh\"         9 hours ago      Up 19 seconds           80/tcp, 443/tcp, 0.0.0.0:5050-&gt;5050/tcp, :::5050-&gt;5050/tcp                                                         pgadmin\n</code></pre> <p>Congrats our <code>app</code> service is now running in HTTPS \ud83e\udd73</p>"},{"location":"docker/docker_install/","title":"Setting up Docker","text":"<p>The process of installing Docker on your local machine will depend on the operating system you are using. Docker provides installation packages for Windows, macOS, and Linux.</p>"},{"location":"docker/docker_install/#installing-docker-on-macos","title":"Installing Docker on MacOS","text":"<ol> <li> <p>Go to the official docker website and download the appropriate installation package for your operating system. Be aware of your chipset for example if your Apple machine is new install the version apple chip not intel (you can see that chip information if you go on the <code>little \uf8ff on the top left of your screen</code> &gt; <code>about my Mac</code>)</p> </li> <li> <p>Follow the installation instructions </p> </li> <li>Once Docker is successfully installed, open a terminal or command prompt and run the following command to verify that Docker is running:</li> </ol> <pre><code>docker version\n</code></pre> <p>If Docker is running correctly, you should see information about the Docker version, API version, and other details like this : </p> <pre><code>Client:\n Cloud integration: 1.0.14\n Version:           20.10.6\n API version:       1.41\n Go version:        go1.16.3\n Git commit:        370c289\n Built:             Fri Apr  9 22:46:57 2021\n OS/Arch:           darwin/amd64\n Context:           default\n Experimental:      true\n\nServer: Docker Engine - Community\n Engine:\n  Version:          20.10.6\n  API version:      1.41 (minimum version 1.12)\n  Go version:       go1.13.15\n  Git commit:       8728dd2\n  Built:            Fri Apr  9 22:44:56 2021\n  OS/Arch:          linux/amd64\n  Experimental:     false\n containerd:\n  Version:          1.4.4\n  GitCommit:        05f951a3781f4f2c1911b05e61c160e9c30eaa8e\n runc:\n  Version:          1.0.0-rc93\n  GitCommit:        12644e614e25b05da6fd08a38ffa0cfe1903fdec\n docker-init:\n  Version:          0.19.0\n  GitCommit:        de40ad0\n</code></pre>"},{"location":"docker/docker_install/#technical-informations-about-docker-version","title":"Technical informations about docker version","text":"<p>Just in case if you wondering what the output means \ud83e\udd13</p> <ul> <li>Client: This section shows the version and details of the Docker client that is running on your local machine. The client is responsible for issuing commands to the Docker daemon, which manages containers and images.<ul> <li>Cloud integration: This shows the version of the Docker Cloud integration plugin that is installed on your machine. Docker Cloud is a service that provides tools for managing Docker containers in the cloud.</li> <li>Version: This shows the version of the Docker client that is installed on your machine.</li> <li>API version: This shows the version of the Docker API that is supported by the client.</li> <li>Go version: This shows the version of the Go programming language that was used to compile the Docker client.</li> <li>Git commit: This shows the Git commit hash that was used to build the Docker client.</li> <li>Built: This shows the date and time that the Docker client was built.</li> <li>OS/Arch: This shows the operating system and processor architecture that the Docker client is running on.</li> <li>Context: This shows the default Docker context that is currently in use.</li> <li>Experimental: This shows whether experimental features are enabled on the Docker client.</li> </ul> </li> <li>Server: This section shows the version and details of the Docker daemon that is running on your local machine. The daemon is responsible for managing containers and images.<ul> <li>Engine: This shows the version of the Docker engine that is running on your machine.</li> <li>API version: This shows the version of the Docker API that is supported by the engine.</li> <li>Go version: This shows the version of the Go programming language that was used to compile the Docker engine.</li> <li>Git commit: This shows the Git commit hash that was used to build the Docker engine.</li> <li>Built: This shows the date and time that the Docker engine was built.</li> <li>OS/Arch: This shows the operating system and processor architecture that the Docker engine is running on.</li> <li>Experimental: This shows whether experimental features are enabled on the Docker engine.</li> <li>containerd: This shows the version and Git commit of containerd, which is the container runtime used by Docker.</li> <li>runc: This shows the version and Git commit of runc, which is the command-line tool used to run containers.</li> <li>docker-init: This shows the version and Git commit of docker-init, which is the initialization script used by Docker to start containers.</li> </ul> </li> </ul>"},{"location":"docker/docker_install/#how-docker-works-on-our-machine","title":"How Docker works on our machine","text":"<p>As you can see the output of the <code>docker version</code> command is divided into two sections: Client and Server. In the context of Docker, the Docker client and server are two separate components that work together to manage containers and images.</p> <p></p> <p></p> <p>At the top, we have the client component, which runs on the host machine and interacts with the user. The client sends requests to the server component, which is hosted inside a Docker container.</p> <p></p> <p>The Docker container is built from an image, which contains the application code and its dependencies. The image is created using a Dockerfile, which specifies the steps to build the image. The image is then pushed to a Docker registry, where it can be accessed by other team members or deployed to production.</p> <p></p> <p>The Docker container runs on a Docker host, which is a machine that has Docker installed. The Docker host abstracts the underlying hardware and provides a consistent interface for running Docker containers.</p> <p></p> <p>The Docker container is isolated from other containers and the host machine, which provides a secure and predictable environment for running the application.</p> <p></p> <p>In this architecture, we can easily scale the server component by creating more Docker containers from the same image. We can also deploy the application to different environments, such as development, staging, and production, by using different Docker images and configurations.</p>"},{"location":"docker/docker_install/#docker-client","title":"Docker client","text":"<p>The Docker client is a command-line interface (CLI) tool that allows you to interact with the Docker daemon. The client sends commands to the daemon, which then executes those commands and manages the containers and images on your system. The Docker client can be used to build and run containers, manage images, and perform other Docker-related tasks.</p>"},{"location":"docker/docker_install/#docker-daemon","title":"Docker Daemon","text":"<p>The Docker server, also known as the Docker daemon, is a background process that manages the containers and images on your system. The daemon listens for commands from the Docker client, executes those commands, and manages the underlying infrastructure needed to run containers, such as networking and storage.</p> <p></p> <p>The Docker client and server communicate with each other using the Docker API, which is a RESTful API that provides a standardized way to interact with Docker. When you run a command using the Docker client, such as \"docker run\", the client sends a request to the Docker daemon over the Docker API. The daemon then processes the request and executes the command.</p> <p></p> <p>In summary, the Docker client is a tool for interacting with the Docker daemon, while the Docker daemon is a background process that manages the containers and images on your system. The client and daemon communicate with each other using the Docker API.</p>"},{"location":"docker/docker_intro/","title":"Introduction to Docker","text":"<p>Docker is an open-source platform for building, shipping, and running applications as containers. Docker solves the problem of \"it works on my machine but not in production\" by providing a consistent environment for running applications. </p> <p></p> <p>Traditionally, developers would build applications on their local machines, which could have different operating systems, libraries, and dependencies than the production environment. This could lead to compatibility issues and errors when the application was deployed to production.</p> <p></p> <p> </p> <p></p> <p>With Docker, developers can package their applications and dependencies into a container, which provides a consistent environment for running the application. This means that the container can be run on any machine that has Docker installed, without worrying about differences in the underlying operating system or environment.</p> <p></p> <p>By using Docker, developers can ensure that their applications will work the same way in development, testing, and production environments. This can help to reduce the risk of compatibility issues and errors when deploying applications to production.</p> <p></p> <p>Docker also makes it easier to manage and scale applications. Containers can be quickly and easily deployed, scaled up or down, and updated, which helps to reduce the time and effort required to manage applications. This can help to improve the reliability and performance of applications, while also reducing costs and complexity.</p> <p></p> <p>In summary, Docker provides a consistent and reliable way to package, deploy, and manage applications, which helps to solve the problem of \"it works on my machine but not in production\". By using Docker, developers can ensure that their applications will work the same way in all environments, which can help to improve the reliability and efficiency of application deployment.</p>"},{"location":"docker/docker_intro/#what-is-docker-and-why-use-it","title":"What is Docker and Why Use It?","text":"<p>Docker provides a number of benefits over traditional methods of deploying applications:</p> <ul> <li>Consistency : Docker provides a consistent environment for running your application, regardless of where it is being run. This means that you can build your application once, and then run it in any environment that has Docker installed, without worrying about differences in operating systems, libraries, or dependencies.</li> <li>Portability : Docker containers are lightweight and portable, which means that you can easily move them between machines, or even between different cloud providers. This makes it easy to deploy your application to different environments, such as development, staging, and production.</li> <li>Isolation : Docker containers provide a high degree of isolation between different applications, which reduces the risk of conflicts between different components of your application stack. This means that you can run multiple applications on the same machine, without worrying about interference between them.</li> <li>Resource Efficiency : Docker containers are lightweight and use fewer resources than traditional virtual machines, which means that you can run more containers on the same machine. This can result in significant cost savings for cloud-based applications.</li> </ul>"},{"location":"docker/docker_intro/#docker-vs-virtual-machines","title":"Docker VS Virtual Machines","text":"<p>Let's talk about the difference between a traditional virtual machine (VM) architecture and a containerized architecture for that let's take a look at this figure : </p> <p></p> <p></p> <p></p> <p>Starting with the VM architecture on the left, you can see that there is a physical server that hosts a hypervisor layer. The hypervisor layer creates multiple virtual machines, each of which has its own operating system (OS) and runs on top of the hypervisor layer. Each VM also has its own set of resources, such as CPU, memory, and storage, which are isolated from the other VMs.</p> <p></p> <p>In contrast, the containerized architecture on the right does not have a hypervisor layer. Instead, it has a host operating system that runs on top of the physical server. On top of the host operating system, there is a container runtime, which manages the creation and management of containers. Each container shares the host operating system with other containers, but each container has its own isolated file system, network, and process space.</p> <p></p> <p>Docker is a containerization technology that allows you to create, deploy, and manage containers. It provides a way to package and distribute software applications in a standardized and portable format, making it easy to move them from one environment to another. With Docker, you can create a Dockerfile that describes the dependencies and configuration of your application, and then use the Docker command-line interface to build, run, and manage containers based on that Dockerfile.</p> <p></p> <p>Overall, Docker provides a lightweight and flexible alternative to traditional VMs, making it easier to develop, deploy, and scale applications.</p>"},{"location":"docker/docker_intro/#what-is-a-containers","title":"What is a Containers","text":"<p>Docker's use of the term \"container\" is inspired by the shipping industry. In the shipping industry, containers are standardized, self-contained units that can be easily transported between ships, trains, and trucks. These containers can hold a variety of goods and products, and they are designed to be easy to load and unload from transport vehicles.</p> <p></p> <p>Similarly, in the context of software development, a container is a standardized, self-contained unit that can hold an application along with its dependencies and configurations. Like a shipping container, a software container can be easily transported between different environments, such as development, testing, and production.</p> <p></p> <p>By using the term \"container\", Docker is emphasizing the portability and standardization of its technology, which is similar to the shipping industry's use of containers to transport goods and products between different locations.</p>"},{"location":"docker/docker_intro/#advantages-of-containerization","title":"Advantages of Containerization","text":"<p>Containerization provides several advantages over traditional deployment methods:</p> <ul> <li>Portability : Containers are self-contained units of software that can be easily moved between different environments.</li> <li>Scalability : Containers can be quickly and easily scaled up or down, depending on demand.</li> <li>Consistency: Containers provide a consistent environment for running applications, which makes it easier to manage and troubleshoot applications.</li> <li>Resource Efficiency : Containers use fewer resources than traditional virtual machines, which means that you can run more containers on the same hardware.</li> <li>Security : Containers provide a high degree of isolation between different applications, which helps to reduce the risk of security breaches.</li> </ul> <p>In summary, Docker provides a flexible and efficient way to package and deploy applications as containers. By using Docker, you can create consistent, portable, and scalable environments for running your applications, which can help to reduce costs and improve reliability.</p>"},{"location":"docker/docker_intro/#5-reasons-why-developers-should-consider-using-docker","title":"5 reasons why developers should consider using Docker","text":"<ul> <li>Consistent Development Environments: With Docker, developers can create a consistent environment for developing and testing applications. Docker allows developers to package an application along with all its dependencies, libraries, and configurations into a container. This ensures that the application will run the same way on any machine, regardless of the underlying operating system or environment.</li> <li>Easy Collaboration: Docker containers can be easily shared between developers, which makes it easier to collaborate on projects. Containers can be used to create a development environment that is identical across all team members, which helps to reduce the risk of compatibility issues and errors.</li> <li>Faster Application Development and Deployment: Docker makes it easier to develop and deploy applications by automating the process of packaging and deploying applications. Developers can quickly create and test new versions of an application in a container, and then deploy it to production with minimal effort.</li> <li>Improved Testing: Docker makes it easier to test applications by allowing developers to create multiple containers with different configurations and environments. This makes it easier to test applications in different scenarios, such as different operating systems, libraries, or dependencies.</li> <li>Resource Efficiency: Docker containers are lightweight and use fewer resources than traditional virtual machines, which means that developers can run more containers on the same machine. This can result in significant cost savings for cloud-based applications.</li> </ul>"},{"location":"docker/docker_network/","title":"What is Docker Networking?","text":"<p>Docker Networking allows you to connect Docker containers together so that they can communicate with each other. This is useful for building complex applications that are made up of multiple containers, each with its own functionality.</p> <p></p> <p>Docker Networking also allows you to isolate containers from each other, providing an added layer of security. Additionally, Docker Networking makes it easy to connect containers to external networks, such as the internet, and to other Docker hosts.</p>"},{"location":"docker/docker_network/#docker-network-types","title":"Docker Network Types","text":"<p>Docker supports several types of network drivers that provide different ways to connect containers together. Here are some of the most common Docker network types:</p> <ul> <li>Bridge Network: The default network type in Docker, a bridge network is a private network that allows containers to communicate with each other using IP addresses. Containers on a bridge network can communicate with each other but are isolated from the host machine and external networks.</li> <li>Host Network: A host network allows containers to use the host machine's network stack, essentially giving them direct access to the host's network interfaces. This can provide better performance but may not be as secure as other network types.</li> <li>Overlay Network: An overlay network allows you to connect containers that are running on different Docker hosts. This is useful for building distributed applications that are made up of multiple Docker hosts.</li> <li>Macvlan Network: A macvlan network allows you to assign a MAC address to a container, essentially making it appear as though it is a physical machine on the network. This can be useful for running containers that require direct access to the physical network.</li> </ul>"},{"location":"docker/docker_network/#creating-a-docker-network","title":"Creating a Docker Network","text":"<p>Creating a Docker network is easy. You can use the docker network create command to create a new network:</p> <pre><code>docker network create mynetwork\n</code></pre> <p>This command creates a new Docker network with the name mynetwork.</p>"},{"location":"docker/docker_network/#attaching-containers-to-a-network","title":"Attaching Containers to a Network","text":"<p>To attach a container to a network, you can use the --network option when you start the container:</p> <pre><code>docker run --name mycontainer --network mynetwork alpine sleep 3000\n</code></pre> <p>This command creates a new container with the name mycontainer and attaches it to the mynetwork network.</p>"},{"location":"docker/docker_network/#connecting-to-external-networks","title":"Connecting to External Networks","text":"<p>To connect a container to an external network, such as the internet, you can use the --network option to specify the host network:</p> <pre><code>docker run --name mycontainer --network host alpine ping google.com\n</code></pre> <p>This command creates a new container with the name mycontainer and attaches it to the host network. The container then uses the host machine's network stack to ping google.com.</p>"},{"location":"docker/docker_network/#create-containers-and-attach-them-to-a-network","title":"Create containers and attach them to a network","text":""},{"location":"docker/docker_network/#step-1-create-a-docker-network","title":"Step 1: Create a Docker Network","text":"<p>The first step is to create a Docker network that both containers will be attached to. This can be done using the docker network create command:</p> <pre><code>docker network create mynetwork\n</code></pre>"},{"location":"docker/docker_network/#step-2-create-the-first-container","title":"Step 2: Create the First Container","text":"<p>Next, we'll create the first container and attach it to the mynetwork network. We'll use the docker run command to create the container:</p> <pre><code>docker run --name container1 --network mynetwork alpine sleep 3000\n</code></pre> <p>This command creates a new container with the name container1, attaches it to the mynetwork network, and starts the sleep command to keep the container running for 3000 seconds.</p>"},{"location":"docker/docker_network/#step-3-create-the-second-container","title":"Step 3: Create the Second Container","text":"<p>Next, we'll create the second container and attach it to the mynetwork network. We'll use the docker run command again:</p> <pre><code>docker run --name container2 --network mynetwork alpine sleep 3000\n</code></pre> <p>Same thing, this command creates a new container with the name <code>container2</code>, attaches it to the mynetwork network, and starts the sleep command to keep the container running for 3000 seconds.</p>"},{"location":"docker/docker_network/#step-4-create-the-third-container","title":"Step 4: Create the Third Container","text":"<p>Now, let's create a third container that is not attached to the mynetwork network. We'll use the docker run command to create the container:</p> <pre><code>docker run --name container3 alpine sleep 3000\n</code></pre> <p>This command creates a new container with the name <code>container3</code> and starts the sleep command to keep the container running for 3000 seconds. Since we did not specify a network for this container, it will be attached to the default bridge network.</p>"},{"location":"docker/docker_network/#step-5-ping-one-container-from-the-other","title":"Step 5: Ping One Container from the Other","text":""},{"location":"docker/docker_network/#what-is-ping","title":"What is <code>ping</code>","text":"<p>The <code>ping</code> command is commonly used to test the availability and responsiveness of network devices, such as servers or routers. It can help diagnose network connectivity issues, such as packet loss or latency.</p> <p></p> <p>When you run the <code>ping</code> command, it will send packets of data to the specified destination, and display the results in the terminal. The output will typically include statistics about the packet transmission, such as the number of packets sent and received, the round-trip time (RTT) for each packet, and any errors or packet loss that occurred during the transmission.</p> <p></p> <p>Here's an example of running the ping command:</p> <pre><code>ping google.com\n</code></pre> <p>This command sends packets of data to the Google.com domain name, and displays the results in the terminal. The output will show the RTT for each packet, as well as other statistics about the packet transmission.</p>"},{"location":"docker/docker_network/#ping-container1-from-container2","title":"Ping  <code>container1</code> from <code>container2</code>","text":"<p>Now that both containers are running and attached to the same network, we can confirm that they can communicate with each other. We'll do this by pinging <code>container1</code> from <code>container2</code>:</p> <pre><code>docker exec container2 ping container1\n</code></pre> <p>This command uses the docker exec command to run the ping container1 command inside container2. If the two containers are able to communicate with each other, you should see output similar to the following:</p> <pre><code>PING container1 (172.19.0.2): 56 data bytes\n64 bytes from 172.19.0.2: seq=0 ttl=64 time=0.091 ms\n64 bytes from 172.19.0.2: seq=1 ttl=64 time=0.111 ms\n</code></pre> <p>If you see this output, it means that the two containers are able to communicate with each other over the <code>mynetwork</code> network.</p> <p></p> <p>Now, let's try to ping <code>container1</code> from <code>container3</code>, which is not attached to the <code>mynetwork</code> network:</p> <pre><code>docker exec container3 ping container1\n</code></pre> <p>This command uses the docker exec command to run the ping container1 command inside <code>container3</code>. Since <code>container3</code> is not attached to the mynetwork network, it should not be able to communicate with container1. You should see output similar to the following:</p> <pre><code>ping: bad address 'container1'\n</code></pre> <p>This output confirms that <code>container3</code> is not able to communicate with <code>container1</code>.</p>"},{"location":"docker/docker_network/#wrap-up","title":"Wrap-up","text":"<p>Docker Networking is a powerful feature that allows you to connect Docker containers together so that they can communicate with each other. By mastering Docker Networking, you can build complex applications that are made up of multiple containers, each with its own functionality. You can also isolate containers from each other, connect them to external networks, and build distributed applications that are made up of multiple Docker hosts.</p>"},{"location":"docker/docker_python_app/","title":"Building a Docker Image for your Python App","text":"<p>Docker provides a convenient way to package your Python applications and dependencies into a self-contained image that can be run on any machine. In this tutorial, we will walk you through the process of building a Docker image for a standard Python app.</p>"},{"location":"docker/docker_python_app/#common-problems-if-you-choose-to-not-use-docker","title":"Common problems if you choose to NOT use Docker","text":"<p>Here are three common problems you might encounter if you choose not to use Docker for your Python script deployment:</p> <ul> <li>Dependency Conflicts: One of the biggest challenges with Python application deployment is managing dependencies. Without Docker, it can be difficult to ensure that your Python application and its dependencies will work correctly on different machines and environments. This can result in dependency conflicts, broken code, and lost productivity.</li> <li>Inconsistency: Another issue with deploying Python applications without Docker is inconsistency. Different machines and environments can have different versions of Python, different system libraries, and different configurations. This can make it difficult to reproduce and debug issues, and can result in code that works on some machines but not on others.</li> <li>Limited Portability: Without Docker, it can be difficult to move your Python application between different machines and environments. This can limit your ability to scale and deploy your application effectively, and can result in lost opportunities and increased costs.</li> </ul> <p>Overall, while it is possible to deploy Python applications without Docker, doing so can lead to dependency conflicts, inconsistency, and limited portability. By using Docker to package your Python application and its dependencies into a self-contained container, you can ensure that your application runs consistently and reliably across different machines and environments.</p>"},{"location":"docker/docker_python_app/#why-we-use-docker-to-run-python-scripts-in-containers","title":"Why we use Docker to run Python scripts in containers:","text":"<ul> <li>Isolation: Running a Python script in a Docker container provides a degree of isolation between the script and the host machine, which helps to minimize conflicts and dependencies with other applications or processes.</li> <li>Consistency: By running a Python script in a Docker container, you can ensure that the environment in which the script runs is consistent across different machines and environments. This helps to avoid the \"it works on my machine\" problem and makes it easier to reproduce and debug issues.</li> <li>Portability: Docker containers are self-contained units that can be easily moved between different machines and environments. This makes it easy to deploy and scale Python scripts in a variety of settings, from local development to production servers.</li> <li>Efficiency: Docker containers are lightweight and efficient, which means that they can be deployed quickly and consume minimal resources. This makes them an ideal choice for running Python scripts that need to be deployed quickly or scaled up or down rapidly.</li> </ul>"},{"location":"docker/docker_python_app/#creating-a-dockerfile-for-our-python-app","title":"Creating a Dockerfile for our python app","text":"<p>The first step in building a Docker image for your Python app is to create a Dockerfile. The Dockerfile is a text file that contains a set of instructions for building the Docker image. Here's an example Dockerfile for a Python app:</p> <pre><code># Use an official Python runtime as a parent image\nFROM python:3.9\n\n# Set the working directory to /app\nWORKDIR /app\n\n# Copy the current directory contents into the container at /app\nCOPY . /app\n\n# Install any needed packages specified in requirements.txt\nRUN pip install --no-cache-dir -r requirements.txt\n\n# Make port 80 available to the world outside this container\nEXPOSE 80\n\n# Define environment variable\nENV NAME World\n\n# Run app.py when the container launches\nCMD [\"python\", \"app.py\"]\n</code></pre>"},{"location":"docker/docker_python_app/#lets-see-how-this-file-works-line-by-line","title":"Let's see how this file works line by line","text":""},{"location":"docker/docker_python_app/#defining-the-base-image-and-environment","title":"Defining the base image and environment","text":"<p>The first line in the Dockerfile specifies the base image to use for the container. In this case, we are using the official <code>Python 3.9</code> image.</p> <pre><code>FROM python:3.9\n</code></pre> <p>Next, we set the working directory to \"/app\" inside the container.</p> <pre><code>WORKDIR /app\n</code></pre> <p>This is the directory where we will copy our application code and dependencies.</p>"},{"location":"docker/docker_python_app/#installing-dependencies-and-copying-source-code","title":"Installing dependencies and copying source code","text":"<p>Next, we copy our application code and dependencies into the container. This is done using the <code>COPY</code> command.</p> <pre><code>COPY . /app\n</code></pre> <p>This command copies the contents of the current directory into the \"/app\" directory inside the container.</p> <p>We then install any dependencies that are needed for our application. This is done using the \"RUN\" command.</p> <pre><code>RUN pip install --no-cache-dir -r requirements.txt\n</code></pre> <p>This command reads the requirements.txt file and installs any dependencies listed in the file.</p>"},{"location":"docker/docker_python_app/#configuring-the-app-and-exposing-ports","title":"Configuring the app and exposing ports","text":"<p>Next, we configure our application by setting any environment variables and exposing any necessary ports.</p> <pre><code>EXPOSE 80\nENV NAME World\n</code></pre> <p>In this example, we are exposing port 80 and setting an environment variable named \"NAME\" to \"World\".</p> <p>Finally, we specify the command to run when the container is launched.</p> <pre><code>CMD [\"python\", \"app.py\"]\n</code></pre> <p>This command specifies that the \"app.py\" file should be executed when the container is launched.</p>"},{"location":"docker/docker_python_app/#building-the-docker-image","title":"Building the Docker image","text":"<p>Now that we have created our Dockerfile, we can build our Docker image.  To do this, we use the <code>docker build</code> command like this : </p> <pre><code>docker build -t my-python-app .\n</code></pre> <p>This command tells Docker to build an image with the name <code>my-python-app</code> using the Dockerfile in the current directory (.) </p>"},{"location":"docker/docker_python_app/#running-the-docker-container","title":"Running the Docker container","text":"<p>Once we have built our Docker image, we can run it using the <code>docker run</code> command : </p> <pre><code>docker run -p 4000:80 my-python-app\n</code></pre> <p>This command tells Docker to run the <code>my-python-app</code> image and map port <code>4000</code> on the host machine to port <code>80</code> inside the container.</p>"},{"location":"docker/docker_python_app/#summary-of-the-most-common-dockerfile-commands","title":"Summary of the most common Dockerfile commands","text":"<p>These commands can be combined in various ways to create a Dockerfile for your specific application. By using Dockerfile commands, you can define the steps needed to build a Docker image and run a Docker container for your application.</p> <p>Most common Dockerfile commands: </p> <ul> <li><code>FROM</code>: Specifies the base image for the Docker image.</li> <li><code>RUN</code>: Executes a command during the build process, such as installing dependencies or running tests.</li> <li><code>COPY</code> or <code>ADD</code>: Copies files or directories from the host machine into the Docker image.</li> <li><code>WORKDIR</code>: Sets the working directory inside the Docker image.</li> <li><code>EXPOSE</code>: Exposes a port for the Docker container.</li> <li><code>ENV</code>: Sets an environment variable inside the Docker image.</li> <li><code>CMD</code> or <code>ENTRYPOINT</code>: Specifies the command to run when the Docker container starts.</li> </ul> <p></p> <p> </p> <p></p> <p>These commands can be combined in various ways to create a Dockerfile for your specific application. By using Dockerfile commands, you can define the steps needed to build a Docker image and run a Docker container for your application.</p>"},{"location":"docker/docker_python_app/#run-a-fastapi-hello-world-python-app-into-a-container","title":"Run a FastAPI \"Hello World\" Python app into a container","text":"<p>Create a new Python file named <code>main.py</code> with the following code : </p> <pre><code>from fastapi import FastAPI\n\napp = FastAPI()\n\n@app.get(\"/\")\nasync def root():\n    return {\"message\": \"Hello World!\"}\n</code></pre> <p>Create a new file named <code>Dockerfile</code> in the same directory with the following contents:</p> <pre><code>FROM tiangolo/uvicorn-gunicorn-fastapi:python3.8-slim\n\nCOPY ./app /app\n\nEXPOSE 80\n\nCMD [\"uvicorn\", \"main:app\", \"--host\", \"0.0.0.0\", \"--port\", \"80\"]\n</code></pre> <p>This Dockerfile uses the <code>tiangolo/uvicorn-gunicorn-fastapi</code> base image, copies the app directory (which contains main.py) into the container, exposes port <code>80</code>, and sets the <code>CMD</code> to run the uvicorn server with the <code>main:app</code> parameter.</p> <p></p> <p>Build the Docker image using the following command:</p> <pre><code>docker build -t fastapi-demo .\n</code></pre> <p>This command builds the Docker image and tags it with the name fastapi-demo.</p> <p></p> <p>Run the Docker container using the following command:</p> <pre><code>docker run -p 80:80 fastapi-demo\n</code></pre> <p>This command starts the Docker container and maps port 80 on the host machine to port 80 inside the container.</p> <p></p> <p>Make sure the container is up and the API is running with the command : </p> <pre><code>docker ps \n</code></pre> <p>If you see the container UP and running, then you can open your web browser and navigate to http://localhost:80/. You should see the message \"Hello World!\" displayed in your browser \ud83e\udd73</p>"},{"location":"docker/docker_python_app/#why-0000-and-not-localhost","title":"Why <code>0.0.0.0</code> and not <code>localhost</code>","text":"<p>When setting up a Docker container, it's common to bind the container's internal port to a port on the host machine so that the container's services can be accessed from the outside. When specifying the IP address for the --host parameter in the uvicorn command, you have a choice between using <code>localhost</code> and <code>0.0.0.0</code>.</p> <p></p> <p>Using localhost as the IP address for the --host parameter means that the server will only accept requests coming from within the container itself. This can be useful if you want to restrict access to the server to only the container itself.</p> <p></p> <p>However, if you want to allow external access to the server (i.e., from the host machine or other machines on the same network), you should use <code>0.0.0.0</code> as the IP address for the --host parameter. This tells the server to accept requests from any IP address.</p> <p></p> <p>So, in a FastAPI application context for a Docker container, using <code>0.0.0.0</code> as the IP address for the --host parameter allows the container's services to be accessed from the host machine or other machines on the same network, while using localhost would restrict access to only the container itself.</p>"},{"location":"docker/docker_python_app/#wrap-up","title":"Wrap-up","text":"<p>In summary, building a Docker image for your Python app involves creating a Dockerfile, defining the base image and environment, installing dependencies and copying source code, configuring the app and exposing ports, and finally building and running the Docker image. </p>"},{"location":"docker/docker_volume/","title":"Docker Volumes","text":""},{"location":"docker/docker_volume/#what-are-docker-volumes","title":"What are Docker Volumes?","text":"<p>Docker volumes are a way to persist data outside of a container's file system. When you create a Docker volume, you create a new volume object that can be attached to one or more containers. Data can be written to or read from the volume, and the data will persist even if the container is removed or recreated.</p>"},{"location":"docker/docker_volume/#using-a-docker-volume-for-a-hello-world-fastapi-app","title":"Using a Docker Volume for a Hello World FastAPI App","text":"<p>Let's say you have a simple Hello World FastAPI app that you want to run in a Docker container. Here's an example of what the Dockerfile might look like:</p> <pre><code>FROM tiangolo/uvicorn-gunicorn-fastapi:python3.8\n\nWORKDIR /app\n\nCOPY ./app /app\n\nRUN pip install --no-cache-dir -r requirements.txt\n\nCMD [\"uvicorn\", \"app.main:app\", \"--host\", \"0.0.0.0\", \"--port\", \"80\"]\n</code></pre> <p>This Dockerfile uses the <code>tiangolo/uvicorn-gunicorn-fastapi</code> base image and copies the app directory into the <code>/app</code> directory in the container.</p> <p></p> <p>Next, it runs the pip command to install the packages listed in the requirements.txt file. The <code>--no-cache-dir</code> flag is used to ensure that the packages are installed from scratch, rather than using any cached packages.</p> <p></p> <p>Finally, it sets the command to start the app using the Uvicorn server on port <code>80</code>.</p> <p></p> <p>Here's the code for the <code>app.py</code> file:</p> <pre><code>from fastapi import FastAPI\n\napp = FastAPI()\n\n@app.get(\"/\")\ndef read_root():\n    return {\"Hello\": \"World\"}\n</code></pre> <p>and the <code>requirements.txt</code> file : </p> <pre><code>fastapi==0.68.1\nuvicorn==0.15.0\n</code></pre>"},{"location":"docker/docker_volume/#why-using-volume","title":"Why using volume","text":"<p>When you create a Docker volume and attach it to a container, it's like putting a bookmark from the container to a local folder on your host machine.</p> <p></p> <p></p> <p></p> <p>Just like a bookmark in a web browser, a volume allows you to quickly access a specific location in the container's file system, without having to navigate through all of the directories manually.</p> <p></p> <p>With a volume, you can also persist data outside of the container's file system. This can be useful if you need to share data between multiple containers, or if you need to keep data separate from the container image itself.</p> <p></p> <p>Overall, volumes are a powerful tool in Docker that allow you to manage and persist data in a flexible and efficient way.</p>"},{"location":"docker/docker_volume/#add-volume-to-docker-run","title":"Add volume to <code>docker run</code>","text":"<p>With this Dockerfile, you can build and run the container using the following commands:</p> <pre><code>docker build -t myimage .\n\ndocker run -d --name mycontainer -p 8000:80 -v $(pwd):/app myimage\n</code></pre> <p>When you run this app in a Docker container, you can use a Docker volume to mount the <code>app.py</code> file into the container at runtime, rather than copying it into the container at build time. This has a few advantages:</p> <ul> <li>You can make changes to the app.py file without having to rebuild the entire Docker image.</li> <li>You can keep the app code and the container image separate, which can make it easier to manage and update the app over time.</li> </ul>"},{"location":"sql/02_db_kesako/","title":"What is a Database ?","text":"<p>A database is an organized collection of data that is designed to be easy to access, manage, and update. Databases are used in a wide range of applications, from social media platforms to scientific research to financial systems. They are essential for storing and managing large amounts of data in a way that makes it easy to find, update, and retrieve the information you need quickly.</p>"},{"location":"sql/02_db_kesako/#some-examples","title":"Some examples","text":"<p>One of the simplest examples of a database is an address book. Think about the contacts list on your phone. You have a list of people you know, along with their phone numbers, email addresses, and other details. This list is essentially a simple database, with each contact representing a record in the database. You can easily search for a contact by name, update their information, or delete a contact when you no longer need it.</p> <p></p> <p>Another example of a database is an online store. When you shop online, you browse through a catalog of products, add items to your cart, and then complete your purchase. Behind the scenes, the online store is using a database to store information about the products, customers, and orders. When you search for a product, the database is used to find all the relevant information about that product, including the price, description, and availability. When you complete your purchase, the database is updated with information about the order, including the items you bought, the shipping address, and the payment method.</p>"},{"location":"sql/02_db_kesako/#types-of-databases","title":"Types of Databases","text":"<p>There are many different types of databases, each with its own strengths and weaknesses. Some of the most common types of databases include:</p> <ul> <li>Relational databases: These databases organize data into tables with columns and rows, similar to a spreadsheet. They are the most common type of database and are used in many different applications.</li> <li>NoSQL databases: These databases are designed to handle large amounts of unstructured or semi-structured data. They are commonly used in big data applications, such as social media analytics and scientific research.</li> <li>Object-oriented databases: These databases store data as objects, which can be manipulated using object-oriented programming techniques. They are commonly used in software development and data modeling.</li> </ul>"},{"location":"sql/02_db_kesako/#examples-of-day-to-day-use-cases-for-each-type-of-database","title":"Examples of day-to-day use cases for each type of database","text":""},{"location":"sql/02_db_kesako/#relational-databases","title":"Relational databases","text":"<ul> <li>Customer database example : A business might use a relational database to keep track of customer information, such as their name, contact details, and purchase history. They could then use this information to target customers with personalized marketing campaigns based on their previous purchases.</li> <li>Inventory management example : A store might use a relational database to manage their inventory, with one table for products and another table for suppliers. They could then use SQL queries to quickly retrieve information on which products are in stock, which products are selling quickly, and which suppliers they need to contact to restock their inventory.</li> <li>Employee scheduling example : A company might use a relational database to manage employee schedules, with one table for employees and another table for shifts. They could then use SQL queries to quickly retrieve information on which employees are available to work on a particular day or time, and which shifts still need to be filled.</li> </ul>"},{"location":"sql/02_db_kesako/#nosql-databases","title":"NoSQL databases","text":"<ul> <li>Social media analytics: Social media platforms like Facebook and Twitter use NoSQL databases to store and analyze massive amounts of user data, such as likes, comments, and shares. This allows them to quickly retrieve and analyze user data to provide better ad targeting and personalized content.</li> <li>Internet of Things (IoT) devices: IoT devices like smart thermostats and security cameras generate a huge amount of data, which can be stored and analyzed in NoSQL databases. This allows manufacturers to track device usage patterns, identify and fix bugs, and improve device performance over time.</li> <li>Gaming: Many video games use NoSQL databases to store player data, such as character stats and in-game achievements. This allows players to continue their game progress across different devices, and enables game developers to quickly retrieve and analyze player data to identify areas for improvement.</li> </ul>"},{"location":"sql/02_db_kesako/#object-oriented-databases","title":"Object-oriented databases","text":"<ul> <li>Geolocation data: Companies that rely on geolocation data, such as mapping and navigation services, often use object-oriented databases to store and retrieve this data. This allows them to quickly retrieve and analyze large amounts of geolocation data in real-time.</li> <li>E-commerce: An e-commerce website might use an object-oriented database to store and manage product information, such as product images and descriptions. This allows them to easily update and manage product information across multiple platforms, such as their website, mobile app, and social media.</li> <li>Medical records: Hospitals and healthcare providers often use object-oriented databases to manage patient medical records, which can include a wide range of data types, such as images, test results, and diagnoses. This allows healthcare providers to easily access and update patient information, and can help improve patient care and outcomes.</li> </ul> <p>In this part we will focus only on relational databases. </p>"},{"location":"sql/02_db_kesako/#vocabulary","title":"Vocabulary","text":"<ul> <li>MySQL client is a command-line tool that allows you to interact with the MySQL server, execute SQL queries, and manage databases.</li> <li>MySQL server is the software that stores and manages databases, and allows multiple clients to connect to it and perform operations on the databases.</li> <li>SQL (Structured Query Language) is the language used to interact with relational databases like MySQL, and it provides a standardized syntax for creating, modifying, and querying databases.</li> </ul>"},{"location":"sql/03_table/","title":"Tables &amp; Keys","text":"<p>In a database, a table is a collection of related data that is organized into rows and columns. Tables are the primary way to store data in a relational database management system (RDBMS). In order to organize data effectively, tables are structured with columns that define the data that can be stored in each row.</p>"},{"location":"sql/03_table/#keys","title":"Keys","text":"<p>Keys are an important concept in database design. They are used to ensure data integrity and to establish relationships between tables. There are several types of keys in a database:</p> <ul> <li>Primary Key: A primary key is a column or set of columns that uniquely identifies each row in a table. The primary key is used to enforce data integrity and to ensure that there are no duplicate rows in the table.</li> <li>Foreign Key: A foreign key is a column or set of columns that refers to the primary key of another table. It is used to establish a relationship between two tables.</li> <li>Composite Key: A composite key is a combination of two or more columns that together uniquely identify each row in a table.</li> </ul>"},{"location":"sql/03_table/#examples-of-social-security-number","title":"Examples of social security number","text":"<ul> <li>Primary Key: A primary key is a unique identifier for a record in a table. It is used to ensure that each record in the table is unique and can be easily identified. For example, a person's social security number (SSN) can be used as a primary key in a table of customer data to ensure that each customer is unique and can be easily searched for.</li> <li>Foreign Key: A foreign key is used to link two tables together in a relational database. It is a field in one table that refers to the primary key in another table. For example, a customer's order history can be linked to their customer record using a foreign key. The foreign key in the order history table would refer to the primary key in the customer table, allowing for easy retrieval of all orders associated with a particular customer.</li> <li>Composite Key: A composite key is a key that consists of more than one field. It is used to ensure that a combination of fields in a record is unique. For example, in a table of product inventory, a combination of the product name and the manufacturer's part number could be used as a composite key to ensure that each product is unique and can be easily searched for.</li> </ul>"},{"location":"sql/03_table/#examples-of-social-media-database","title":"Examples of social media database","text":"<ul> <li>Primary Key: In a social media website's database, each user's unique username or email address can be used as a primary key to identify and manage their account. This ensures that each user has a unique identifier, making it easy for the website to maintain user data, track user activity, and provide personalized content.</li> <li>Foreign Key: In a hospital's database, a patient's medical record can be linked to their lab results using a foreign key. The foreign key would refer to the primary key in a table of lab test results, allowing doctors to easily access each patient's test results and track their medical history.</li> <li>Composite Key: In a hotel's database, a room reservation can be linked to a specific guest's booking using a composite key consisting of the guest's name and reservation number. This ensures that each guest has a unique reservation and allows the hotel to easily track each guest's room preference and check-in/check-out dates.</li> </ul>"},{"location":"sql/03_table/#creating-tables","title":"Creating Tables","text":"<p>Creating a table is the first step in building a database. The syntax for creating a table varies depending on the specific database management system being used. Here's an example of how to create a simple table with a primary key:</p> <pre><code>CREATE TABLE employees (\n  id INT PRIMARY KEY,\n  first_name VARCHAR(50),\n  last_name VARCHAR(50),\n  age INT\n);\n</code></pre> <p>In this example, we have created a table called employees with four columns: <code>id</code>, <code>first_name</code>, <code>last_name</code>, and <code>age</code>. The id column is designated as the primary key for the table.</p> <p></p> <p>To create a table with a foreign key, we first need to create the primary key in the table it will reference, and then add the foreign key to the table we're creating. Here's an example:</p> <pre><code>CREATE TABLE departments (\n  id INT PRIMARY KEY,\n  name VARCHAR(50)\n);\n\nCREATE TABLE employees (\n  id INT PRIMARY KEY,\n  first_name VARCHAR(50),\n  last_name VARCHAR(50),\n  age INT,\n  department_id INT,\n  FOREIGN KEY (department_id) REFERENCES departments(id)\n);\n\n</code></pre> <p>In this example, we have created two tables - <code>employees</code> and <code>departments</code>. The <code>departments</code> table has two columns - <code>id</code> and <code>name</code>, with <code>id</code> designated as the primary key. The <code>employees</code> table has five columns - <code>id</code>, <code>first_name</code>, <code>last_name</code>, <code>age</code>, and <code>department_id</code>. The <code>id</code> column is the primary key, and the <code>department_id</code> column is a foreign key that references the <code>id</code> column in the <code>departments</code> table.</p> <p></p> <p>By using tables and keys, we can organize data effectively and establish relationships between tables. This allows us to build powerful and flexible databases that can store and manipulate large amounts of data.</p> <p></p> <p>Don't worry about understunding the syntaxe at this point we will explain more later \ud83e\udd13</p>"},{"location":"sql/04_basics/","title":"SQL Basics understunding","text":""},{"location":"sql/04_basics/#formal-introduction","title":"Formal introduction","text":"<p>Structured Query Language (SQL) is a programming language used to manage and manipulate relational databases. It is a standard language used by most databases to store, retrieve, and manipulate data. SQL is an essential skill for any developer working with databases.</p>"},{"location":"sql/04_basics/#sql-commands","title":"SQL commands","text":"<p>SQL commands are used to interact with a database, such as inserting, updating, deleting, and selecting data.</p> <p></p> <p>The basic SQL commands include SELECT, INSERT, UPDATE, DELETE, and CREATE. The SELECT command is used to retrieve data from a database, while the INSERT, UPDATE, and DELETE commands are used to modify data in a database. The CREATE command is used to create tables and other database objects.</p> <p></p> <p>SQL commands are typically entered into a command line interface or a graphical user interface, such as MySQL Workbench or pgAdmin. These interfaces allow developers to visually design and manipulate databases, as well as enter SQL commands to manage data.</p> <p></p> <p>SQL is widely used in web development, data analysis, and many other fields. It allows developers to easily store and retrieve data, as well as perform complex data manipulations and analysis. Understanding SQL and its commands is essential for developers working with relational databases, and is a valuable skill in today's tech industry.</p> <p></p> <p>In the following sections, we will delve deeper into the world of SQL and explore each of the major SQL commands in more detail. By the end of this course, you will have a solid understanding of SQL, its uses, and how to use it to manage and manipulate data. With this knowledge, you will be equipped to tackle a variety of database-related challenges and create powerful data-driven applications. </p> <p></p> <p>So let's continue with SQL installations \ud83d\ude80</p>"},{"location":"sql/05_MacOS_install/","title":"Install MySQL on Mac OS","text":""},{"location":"sql/05_MacOS_install/#spec","title":"Spec","text":"<p>Version OS : Catalina 10.15.7 or higher Version MAMP : 5.5 </p>"},{"location":"sql/05_MacOS_install/#what-is-mamp","title":"What is MAMP?","text":"<p>MAMP is a free, open-source software that allows you to easily install and run Apache, PHP, and MySQL on your local machine. MAMP is a popular solution for web developers who want to develop and test websites locally before uploading them to a live server. In this section, we'll focus on how to use MAMP to set up and use MySQL on MacOS. </p>"},{"location":"sql/05_MacOS_install/#step-1-download-and-install-mamp","title":"Step 1: Download and Install MAMP","text":"<p>The first step is to download and install MAMP on your MacOS machine. You can download the latest version of MAMP from the official website</p> <p></p> <p>Once the download is complete, double-click on the downloaded file to begin the installation process. Follow the on-screen instructions to install MAMP on your machine.</p>"},{"location":"sql/05_MacOS_install/#step-2-start-mamp-server","title":"Step 2: Start MAMP Server","text":"<p>After installing MAMP, you can start the server by double-clicking on the MAMP icon in the Applications folder. This will launch the MAMP control panel.</p> <p></p> <p>Click on the Start Servers button to start the Apache and MySQL servers. You can check the status of the servers by looking at the indicators in the MAMP control panel. The Apache server is running if the status indicator is green, and the MySQL server is running if the status indicator is also green.</p> <p></p> <p></p> <p></p>"},{"location":"sql/05_MacOS_install/#step-3-create-a-test-database-with-graphic-interface-in-mamp","title":"Step 3: Create a test Database with graphic interface in MAMP","text":"<p>Once the servers are running, you can create a database. To do this, click on the Open WebStart page button in the MAMP control panel. This will launch the MAMP homepage in your default browser.</p> <p></p> <p></p> <p></p> <p>Click on the phpMyAdmin link on the left-hand side of the MAMP homepage to launch the phpMyAdmin interface. phpMyAdmin is a web-based interface that allows you to manage your MySQL databases.</p> <p></p> <p></p> <p></p> <p>In the phpMyAdmin interface, click on the Databases tab</p> <p></p> <p></p> <p></p> <p>and then enter a name for your new database in the Create Database field for our case <code>test</code>.</p> <p></p> <p></p> <p></p> <p>Click on the Create button to create the database and add a table name <code>departments</code> who look like this in SQL command line : </p> <pre><code>CREATE TABLE departments (\n  id INT PRIMARY KEY,\n  name VARCHAR(50)\n);\n</code></pre> <p></p> <p></p> <p></p> <p>after validating the table creation we have to specify two field like above :</p> <p></p> <p></p> <p></p> <p>and then you can see your new database :</p> <p></p> <p></p>"},{"location":"sql/05_MacOS_install/#why-mysql-workbench","title":"Why MySQL Workbench","text":"<p>MySQL Workbench and MAMP are two different software tools that can be used to work with MySQL databases, but they have different features and use cases.</p> <p></p> <p>MySQL Workbench is a graphical user interface (or GUI) tool that is designed for database administrators and developers who need to manage and develop MySQL databases. It provides a wide range of features for working with databases, including:</p> <ul> <li>Creating and managing database schemas</li> <li>Designing and executing SQL queries</li> <li>Visualizing database structures with ER diagrams</li> <li>Managing user accounts and permissions</li> <li>Managing database backups and restores</li> </ul> <p>MySQL Workbench is a powerful tool for working with MySQL databases, but it can be complex and may have a steep learning curve for beginners and we thinks it's more easy to handle and query database.</p> <p></p> <p>MAMP, on the other hand, is a lightweight web development environment that is designed to make it easy to set up a local web server on your computer. It includes a range of tools that are useful for web developers, including:</p> <ul> <li>Apache web server</li> <li>MySQL database server</li> <li>PHP scripting language</li> </ul> <p>MAMP is designed to be easy to use and configure, and is a good choice for beginners who want to set up a local web development environment quickly and easily.</p>"},{"location":"sql/05_MacOS_install/#difference-between-mysql-and-mamp","title":"Difference between MySQL and MAMP","text":"<p>In summary, MySQL Workbench is a powerful tool for working with MySQL databases, while MAMP is a lightweight web development environment that includes a MySQL database server as one of its components. Which one you choose to use depends on your specific needs and level of expertise.</p>"},{"location":"sql/05_MacOS_install/#install-mysql-workbench","title":"Install MySQL Workbench","text":"<p>Go to the official download link</p> <p></p> <p>Download the appropriate version of the software for your OS and lunch MAMP SQL server then open the software and click on the button <code>MySQL Connection</code> &gt; <code>Local Instance</code> like the screen below :</p> <p></p> <p></p> <p></p> <p>If you don't have change anything you have the following ids : </p> <ul> <li>user : root </li> <li>password : root </li> </ul> <p>Good you are now connected to MAMP SQL Server \ud83e\udd73</p>"},{"location":"sql/05_MacOS_install/#wrap-up","title":"Wrap up","text":"<p>In this tutorial, we have seen how to install MAMP on MacOS and use it to create and manage MySQL databases. Here some important notions about what you have learned through the MAMP installation and MySQL server and client:</p> <ul> <li>MAMP is a software package that allows you to easily install a local web server on your computer, which includes Apache, MySQL, and PHP.</li> <li>With MAMP, you can easily set up a MySQL server and manage databases and data with the MySQL client.</li> <li>To install MAMP on Windows, you can download the MAMP software package and follow the installation instructions. Once installed, you can access the MySQL server and client through the MAMP control panel.</li> <li>MySQL client is a command-line tool that allows you to interact with the MySQL server, execute SQL queries, and manage databases.</li> <li>MySQL server is the software that stores and manages databases, and allows multiple clients to connect to it and perform operations on the databases.</li> <li>SQL (Structured Query Language) is the language used to interact with relational databases like MySQL, and it provides a standardized syntax for creating, modifying, and querying databases.</li> <li>With the MySQL client, you can create and manage databases, create tables, and insert, update, and delete data with SQL queries.</li> <li>By practicing with MAMP and the MySQL Workbench, you have learned the basics of how to install and set up a MySQL server and interact with it.</li> </ul> <p>In short, SQL is the language used to communicate with databases, while the MySQL server is the software that manages the databases and listens for connections from clients like the MySQL client. The MySQL client is the tool used to connect to the MySQL server and execute SQL queries. </p>"},{"location":"sql/06_b_docker_install/","title":"Install MySQL server with docker","text":"<p>Before we get started, it's important to note that Docker is a containerization platform that allows you to run software applications in isolated environments called containers. This means that you can interact with MySQL server without installing it from scrach and run multiple instances of the same application without any interference between them.</p> <p></p> <p>Now let's dive into the tutorial:</p>"},{"location":"sql/06_b_docker_install/#step-1-install-docker","title":"Step 1: Install Docker","text":"<p>If you don't have Docker installed on your system, you'll need to download and install it first. You can download Docker from the official website</p>"},{"location":"sql/06_b_docker_install/#step-2-pull-the-mysql-docker-image","title":"Step 2: Pull the MySQL Docker image","text":"<p>In Docker, images are used to create containers, which are isolated environments that run applications. Images can be thought of as a template for containers, as they contain all the necessary files, libraries, and dependencies required for an application to run.</p> <p></p> <p>The <code>docker pull</code> command is used to download an image from a remote registry, such as Docker Hub. When you run this command, Docker will search for the specified image in the remote registry and download it to your local machine.</p> <p></p> <p>Once Docker is installed, open a terminal and run the following command to pull the MySQL Docker image:</p> <pre><code>docker pull mysql\n</code></pre> <p>This command will download the MySQL image to your local machine, which you can then use to create a container.</p> <p></p> <p>It's important to note that you must have Docker installed on your local machine to use the <code>docker pull</code> command, as it is a Docker CLI command. Additionally, the image you're trying to pull must be available in the remote registry you're trying to access.</p>"},{"location":"sql/06_b_docker_install/#step-3-start-a-mysql-container","title":"Step 3: Start a MySQL container","text":"<p>After you have pulled the MySQL Docker image, you can start a container using the following command:</p> <pre><code>docker run --name mysql-container -e MYSQL_ROOT_PASSWORD=my-secret-pw -d mysql\n</code></pre> <p>This is the command used to start a new MySQL container with the following options : </p> <ul> <li>--name mysql-container: This option is used to give a name to the new container. In this case, the container is named \"mysql-container\".</li> <li>-e MYSQL_ROOT_PASSWORD=my-secret-pw: This option sets an environment variable for the container, in this case, the MySQL - root password. This means that the password \"my-secret-pw\" will be used as the MySQL root password.</li> <li>-d: This option runs the container in detached mode, which means that it will run in the background and not attach to the terminal session. This is useful for long-running containers, such as database servers.</li> <li>mysql: This is the name of the Docker image that the container is based on. In this case, it is the official MySQL Docker image.</li> </ul> <p>So when you run this command, Docker will start a new container based on the MySQL image with the name \"mysql-container\", set the MySQL root password to \"my-secret-pw\", and run the container in the background it just send you the id of the container like <code>8c4f5828f04b</code> it means it started fine. </p> <p></p> <p>It's important to note that the MySQL root password should be changed to a more secure password before using the container in a production environment. Also, the name of the container and the password used can be changed to suit your specific needs.</p> <p></p> <p>This command will start a new container named \"mysql-container\" with the root password <code>my-secret-pw</code>.</p> <p></p> <p>You can verify if the container is running with the command in your terminal : </p> <pre><code>docker ps\n</code></pre> <p>You should see this in your terminal : </p> <p></p> <p></p> <p></p>"},{"location":"sql/06_b_docker_install/#step-4-access-the-mysql-container-with-the-command-line","title":"Step 4: Access the MySQL container with the command line","text":"<p>To access the MySQL container, you can use the following command:</p> <pre><code>docker exec -it mysql-container mysql -p\n</code></pre> <p>This command will start a MySQL shell session inside the container and prompt you to enter the password you set in the previous step.</p>"},{"location":"sql/06_b_docker_install/#step-5-create-a-test-database-and-a-table","title":"Step 5: Create a test database and a table","text":"<p>Now that you have access to the MySQL container, you can create a database and a table using the following commands:</p> <pre><code>CREATE DATABASE testdb;\nUSE testdb;\nCREATE TABLE users (\nid INT NOT NULL AUTO_INCREMENT,\nname VARCHAR(50) NOT NULL,\nemail VARCHAR(50) NOT NULL,\nPRIMARY KEY (id)\n);\n</code></pre> <p>These commands will create a new database named \"testdb\" and a new table named \"users\" with three columns: \"id\", \"name\", and \"email\".</p>"},{"location":"sql/06_b_docker_install/#step-6-insert-values-into-the-table","title":"Step 6: Insert values into the table","text":"<p>You can insert values into the table using the following command:</p> <pre><code>INSERT INTO users (name, email) VALUES ('John Doe', 'johndoe@example.com');\n</code></pre> <p>This command will insert a new row into the \"users\" table with the name \"John Doe\" and the email \"johndoe@example.com\".</p>"},{"location":"sql/06_b_docker_install/#step-7-test-a-query","title":"Step 7: Test a query","text":"<p>Finally, you can test a query to retrieve the data you just inserted using the following command:</p> <pre><code>SELECT * FROM users;\n</code></pre> <p>This command will retrieve all the data from the \"users\" table.</p> <p>And that's it! You've successfully installed MySQL with Docker and created a table, inserted values, and executed a test query \ud83e\udd73</p>"},{"location":"sql/07_creating_tables/","title":"Creating Tables","text":"<p>We said before, in SQL a table is a collection of data stored in rows and columns. To create a table, you need to define the table schema which includes the table name, column names, data types, and any constraints on the data. The CREATE TABLE statement is used to create a new table in a database.</p>"},{"location":"sql/07_creating_tables/#in-depth-look-at-how-to-create-tables","title":"In-depth look at how to create tables","text":"<p>To create a new table in SQL, you use the <code>CREATE TABLE</code> command followed by the table name and a list of column definitions. Each column definition specifies the column name, data type, and any constraints on the data.</p> <p></p> <p>Here is an example of creating a simple table with two columns:</p> <pre><code>CREATE TABLE users (\n  id INT PRIMARY KEY,\n  name VARCHAR(50) NOT NULL\n);\n</code></pre> <p>This creates a table named <code>users</code> with two columns: <code>id</code> and <code>name</code>. The <code>id</code> column is defined as an integer and is marked as the primary key for the table. The <code>name</code> column is defined as a variable-length string with a maximum length of 50 characters and is marked as required <code>(NOT NULL)</code>.</p>"},{"location":"sql/07_creating_tables/#overview-of-different-data-types-and-how-to-use-them","title":"Overview of different data types and how to use them","text":"<p>SQL provides a wide range of data types that can be used to define columns in a table. These data types include integers, floating-point numbers, strings, dates, and more. Here are some common data types:</p> <ul> <li>INT: used for integer values</li> <li>VARCHAR(n): used for variable-length character strings with a maximum length of n</li> <li>DATE: used for date values</li> <li>FLOAT: used for floating-point numbers</li> <li>BOOLEAN: used for boolean values</li> </ul> <p>Here is an example of creating a table with columns of different data types:</p> <pre><code>CREATE TABLE products (\n  id INT PRIMARY KEY,\n  name VARCHAR(50) NOT NULL,\n  price FLOAT,\n  in_stock BOOLEAN,\n  created_at DATE\n);\n</code></pre>"},{"location":"sql/07_creating_tables/#add-primary-and-foreign-keys-and-link-an-other-table","title":"Add primary and foreign keys and link an other table","text":"<p>In a relational database, a primary key is a unique identifier for each row in a table. It is used to ensure that each row can be uniquely identified and is commonly used to link to other tables in the database.</p> <p></p> <p>A foreign key is a column in one table that refers to the primary key of another table. This is used to create relationships between tables and enforce referential integrity.</p> <p></p> <p>Here is an example of creating a table with a primary key and a foreign key:</p> <pre><code>CREATE TABLE orders (\n  id INT PRIMARY KEY,\n  product_id INT,\n  quantity INT,\n  FOREIGN KEY (product_id) REFERENCES products(id)\n);\n</code></pre> <p>This creates a table named orders with three columns: <code>id</code>, <code>product_id</code>, and <code>quantity</code>. The <code>id</code> column is defined as the primary key for the table. The <code>product_id</code> column is defined as a foreign key that references the id column in the <code>products</code> table, which creates a relationship between the two tables. Here, the <code>quantity</code> column is defined as an integer.</p>"},{"location":"sql/08_insert/","title":"Inserting Data","text":"<p>Once you have created a table, you can start inserting data into it. The process of inserting data involves specifying the table name, the columns to insert data into, and the values to be inserted.</p>"},{"location":"sql/08_insert/#overview-of-different-insert-commands-and-syntax","title":"Overview of Different Insert Commands and Syntax","text":"<p>There are a few different ways to insert data into a table in SQL, depending on how much information you have about the data you are inserting. Here are some common insert commands and their syntax:</p>"},{"location":"sql/08_insert/#inserting-values-into-specific-columns","title":"Inserting Values into Specific Columns","text":"<p>You can use the <code>INSERT INTO</code> command to insert values into specific columns in a table. Here is the syntax for inserting a single row of data into a table:</p> <pre><code>INSERT INTO table_name (column1, column2, column3, ...)\nVALUES (value1, value2, value3, ...);\n</code></pre> <p>For example, to insert a new row into a <code>users</code> table with the values \"John Doe\" for the <code>name</code> column, \"johndoe@example.com\" for the <code>email</code> column, and 25 for the <code>age</code> column, you would use the following command:</p> <pre><code>INSERT INTO users (name, email, age)\nVALUES ('John Doe', 'johndoe@example.com', 25);\n</code></pre>"},{"location":"sql/08_insert/#inserting-values-into-all-columns","title":"Inserting Values into All Columns","text":"<p>If you have data to insert for every column in a table, you can omit the column names from the INSERT INTO command. Here is the syntax for inserting a single row of data into a table without specifying column names:</p> <pre><code>INSERT INTO table_name\nVALUES (value1, value2, value3, ...);\n</code></pre> <p>For example, to insert a new row into the <code>users</code> table with the values \"Jane Smith\" for the <code>name</code> column, \"janesmith@example.com\" for the <code>email</code> column, 30 for the <code>age</code> column, and \"female\" for the <code>gender</code> column, you would use the following command:</p> <pre><code>INSERT INTO users\nVALUES ('Jane Smith', 'janesmith@example.com', 30, 'female');\n\n</code></pre>"},{"location":"sql/08_insert/#inserting-multiple-rows-at-once","title":"Inserting Multiple Rows at Once","text":"<p>You can also use the <code>INSERT INTO</code> command to insert multiple rows of data at once. Here is the syntax for inserting multiple rows of data into a table:</p> <pre><code>INSERT INTO table_name (column1, column2, column3, ...)\nVALUES\n  (value1, value2, value3, ...),\n  (value1, value2, value3, ...),\n  (value1, value2, value3, ...),\n  ...;\n</code></pre> <p>For example, to insert three new rows into the <code>users</code> table, you would use the following command:</p> <pre><code>INSERT INTO users (name, email, age)\nVALUES\n  ('Alice Johnson', 'alicejohnson@example.com', 35),\n  ('Bob Williams', 'bobwilliams@example.com', 40),\n  ('Charlie Brown', 'charliebrown@example.com', 45);\n</code></pre> <p>By using these different insert commands and syntax, you can efficiently add data to your SQL database tables.</p>"},{"location":"sql/09_constraints/","title":"Constraints","text":"<p>Constraints are rules that you can apply to a table in a database to enforce data integrity. They play a vital role in ensuring that the data within the database remains consistent and accurate. There are various types of constraints that can be applied to a table, each serving a specific purpose.</p>"},{"location":"sql/09_constraints/#types-of-constraints","title":"Types of constraints","text":"<p>One type of constraint is the primary key constraint, which enforces the uniqueness of a column or a group of columns within a table. Another type of constraint is the foreign key constraint, which establishes a relationship between two tables based on the values of their respective columns.</p> <p></p> <p>Other types of constraints include the NOT NULL constraint, which ensures that a column cannot have a NULL value, and the UNIQUE constraint, which ensures that the values in a column are unique.</p>"},{"location":"sql/09_constraints/#examples-of-customers-table-one-without-constraints-and-the-other-with-constraints","title":"Examples of customers table one without constraints and the other with constraints","text":""},{"location":"sql/09_constraints/#without-constraints","title":"Without Constraints","text":"<pre><code>CREATE TABLE customers (\n    id INT,\n    first_name VARCHAR(50),\n    last_name VARCHAR(50),\n    email VARCHAR(100)\n);\n\nINSERT INTO customers (id, first_name, last_name, email)\nVALUES\n    (1, 'John', 'Doe', 'john.doe@example.com'),\n    (2, 'Jane', 'Doe', 'jane.doe@example.com'),\n    (3, 'Bob', 'Smith', 'bob.smith@example.com'),\n    (4, 'Alice', 'Johnson', 'alice.johnson@example.com');\n\n</code></pre> <p>In this example, we create a table named <code>customers</code> with four columns - <code>id</code>, <code>first_name</code>, <code>last_name</code>, and <code>email</code>. We then insert some sample data into the table. However, there are no constraints set on the table to enforce any rules about the data being inserted. For example, we can insert multiple rows with the same <code>id</code> value, which can lead to inconsistencies in the data.</p>"},{"location":"sql/09_constraints/#with-constraints","title":"With Constraints","text":"<pre><code>CREATE TABLE customers (\n    id INT PRIMARY KEY,\n    first_name VARCHAR(50) NOT NULL,\n    last_name VARCHAR(50) NOT NULL,\n    email VARCHAR(100) UNIQUE\n);\n\nINSERT INTO customers (id, first_name, last_name, email)\nVALUES\n    (1, 'John', 'Doe', 'john.doe@example.com'),\n    (2, 'Jane', 'Doe', 'jane.doe@example.com'),\n    (3, 'Bob', 'Smith', 'bob.smith@example.com'),\n    (4, 'Alice', 'Johnson', 'alice.johnson@example.com');\n\nINSERT INTO customers (id, first_name, last_name, email)\nVALUES\n    (1, 'Mark', 'Smith', 'mark.smith@example.com'); -- This will fail due to duplicate primary key constraint\n\nINSERT INTO customers (id, first_name, last_name, email)\nVALUES\n    (5, 'Sam', 'Jones', 'bob.smith@example.com'); -- This will fail due to unique constraint on email column\n\n</code></pre> <p>In this example, we create the same customers table, but with additional constraints. We set the id column as the primary key, which means that it must be unique for each row. We also set the first_name and last_name columns as NOT NULL, which means that they cannot be empty. Finally, we set the email column as UNIQUE, which means that each email must be unique in the table.</p> <p></p> <p>When we try to insert data into the table, the constraints are enforced. The first INSERT statement will work fine because it does not violate any constraints. However, the second INSERT statement will fail because it tries to insert a row with a duplicate id value, which violates the primary key constraint. Similarly, the third INSERT statement will fail because it tries to insert a row with a duplicate email value, which violates the unique constraint on the email column.</p>"},{"location":"sql/10_update_delete/","title":"Update &amp; Delete","text":"<p>In addition to inserting data into tables, you may also need to modify or delete existing data. The SQL language provides several commands for updating and deleting data within tables.</p>"},{"location":"sql/10_update_delete/#updating-data","title":"Updating Data","text":"<p>To update data within a table, you can use the <code>UPDATE</code> command followed by the name of the table and the <code>SET</code> keyword. The <code>SET</code> keyword is followed by the column name you want to update, an equals sign, and the new value you want to set.</p> <p></p> <p>Here's the basic syntax for updating data in a table:</p> <pre><code>UPDATE table_name\nSET column_name = new_value\nWHERE condition;\n</code></pre> <p>In this syntax, the <code>WHERE</code> clause specifies which rows to update. Without a <code>WHERE</code> clause, all rows in the table would be updated.</p> <p></p> <p>Here's an example that updates the price of a product in a table called <code>products</code>:</p> <pre><code>UPDATE products\nSET price = 19.99\nWHERE product_id = 1234;\n</code></pre> <p>This statement updates the price column for the row where the product_id is equal to 1234.</p>"},{"location":"sql/10_update_delete/#deleting-data","title":"Deleting Data","text":"<p>To delete data from a table, you can use the <code>DELETE</code> command followed by the name of the table. If you want to delete only certain rows, you can use a <code>WHERE</code> clause to specify which rows to delete.</p> <p></p> <p>Here's the basic syntax for deleting data from a table:</p> <pre><code>DELETE FROM table_name\nWHERE condition;\n</code></pre> <p>Here's an example that deletes a row from a table called <code>orders</code>:</p> <pre><code>DELETE FROM orders\nWHERE order_id = 5678;\n</code></pre> <p>This statement deletes only the row where the <code>order_id</code> is equal to 5678.</p>"},{"location":"sql/10_update_delete/#summarize-creating-inserting-updating-and-deleting","title":"Summarize : creating, inserting, updating and deleting","text":"<p>Let's summarize the previous notions with an SQL example code to create a table, insert values into it, and update a field : </p> <pre><code>-- Creating a table for products\nCREATE TABLE products (\n  id INT PRIMARY KEY,\n  name VARCHAR(50),\n  category VARCHAR(50),\n  price DECIMAL(8, 2)\n);\n\n-- Inserting data into the table\nINSERT INTO products (id, name, category, price)\nVALUES (1, 'Product A', 'Category 1', 10.99),\n       (2, 'Product B', 'Category 2', 19.99),\n       (3, 'Product C', 'Category 1', 5.99);\n\n-- Updating the price of Product A\nUPDATE products\nSET price = 12.99\nWHERE id = 1;\n\n-- Deleting a record from the 'products' table\nDELETE FROM products\nWHERE product_id = 2;\n</code></pre> <p>In this example, we first create a table named <code>products</code> with four columns: <code>id</code>, <code>name</code>, <code>category</code>, and <code>price</code>. We define the <code>id</code> column as the primary key, meaning it uniquely identifies each row in the table.</p> <p></p> <p>Next, we insert three rows of data into the table using the <code>INSERT INTO</code> command. Each row represents a different product, with values for the <code>id</code>, <code>name</code>, <code>category</code>, and <code>price</code> columns.</p> <p></p> <p>Finally, we update the price of <code>Product A</code> using the <code>UPDATE</code> command. We specify the table we want to update (<code>products</code>), the field we want to update (<code>price</code>), and the new value we want to set <code>(12.99)</code>. We use the <code>WHERE</code> clause to specify which row(s) we want to update; in this case, we only want to update the row with an <code>id</code> of <code>1</code>, which corresponds to <code>Product A</code>.</p> <p></p> <p>Then, the <code>DELETE</code> command is used to remove the record from the <code>products</code> table where the value of the <code>product_id</code> field is equal to <code>2</code>. This will delete the second product from the table, which in this case is <code>Product B</code>.</p>"},{"location":"sql/10_update_delete/#deleting-a-single-field-in-a-row","title":"Deleting a single field in a row","text":"<p>Here's an example of deleting a single field in a row of the products table:</p> <pre><code>-- Delete the description of the product with id 3\nUPDATE products\nSET description = NULL\nWHERE id = 3;\n</code></pre> <p>In this example, we use the <code>UPDATE</code> command to modify the description field of the row with <code>id</code> equal to <code>3</code>. The <code>SET</code> keyword is used to specify the new value of the description field, which we set to <code>NULL</code> to delete the existing value.</p> <p></p> <p>The <code>WHERE</code> clause is used to specify which row(s) to update. In this case, we're only updating the row with <code>id</code> equal to <code>3</code>. By setting the description field to <code>NULL</code>, we effectively delete the value of that field for that particular row.</p>"},{"location":"sql/11_queries/","title":"Basic Queries","text":"<p>In the world of database management, tables and queries go hand in hand. Queries are a fundamental component of any database, as they allow you to retrieve and manipulate data in meaningful ways. </p> <p></p> <p>In this chapter, we will explore the basics of SQL queries and how they are used to extract data from tables. To demonstrate this, we will use two example tables, the <code>orders</code> and <code>customers</code> tables. </p> <p></p> <p>These tables will be linked together using a foreign key to show how queries can retrieve data from multiple tables at once. Understanding queries and the relationship between tables is essential for effective database management, as it enables developers to extract valuable insights and make informed decisions based on data.</p> <p></p> <p>This is the example table called <code>customers</code>:</p> <pre><code>CREATE TABLE customers (\n  id INT PRIMARY KEY,\n  first_name VARCHAR(50),\n  last_name VARCHAR(50),\n  email VARCHAR(100),\n  address VARCHAR(100),\n  city VARCHAR(50),\n  state VARCHAR(50),\n  zip_code VARCHAR(20)\n);\n</code></pre> <p>This table has columns for a customer's ID, first name, last name, email address, street address, city, state, and zip code. The <code>id</code> column is the primary key for the table, which means that each row in the table is uniquely identified by its value in the <code>id</code> column.</p> <p></p> <p>This is the example of an <code>orders</code> table:</p> <pre><code>CREATE TABLE orders (\n  order_id INT PRIMARY KEY,\n  customer_id INT,\n  order_date DATE,\n  total_price DECIMAL(10,2)\n);\n</code></pre> <p>This table has four columns: <code>order_id</code>, <code>customer_id</code>, <code>order_date</code>, and <code>total_price</code>. The <code>order_id</code> column is the primary key of the table, which means that each row has a unique value in that column.</p> <p></p> <p>The <code>customer_id</code> column is a foreign key that references the <code>customer_id</code> column in the <code>customers</code> table. </p> <p></p> <p>This establishes a relationship between the two tables. The orders table contains information about each order placed by a customer. The <code>customer_id</code> column is used to link each order to a specific customer in the <code>customers</code> table. </p> <p></p> <p>The <code>order_date</code> column contains the date that the order was placed, and the <code>total_price</code> column contains the total price of the order. By joining the <code>orders</code> table with the <code>customers</code> table on the <code>customer_id</code> column, we can retrieve information about both the customer and their order in a single query.</p>"},{"location":"sql/11_queries/#overview-of-different-select-commands-and-syntax","title":"Overview of Different SELECT Commands and Syntax","text":"<p>The <code>SELECT</code> statement has a variety of options for retrieving and manipulating data. Here are some examples:</p> <ul> <li>The <code>WHERE</code> clause is used to filter data based on a specified condition:</li> </ul> <pre><code>SELECT * FROM customers WHERE city = 'London';\n</code></pre> <p>This statement retrieves all columns and rows from the <code>customers</code> table where the city is <code>London</code>.</p> <ul> <li>The <code>ORDER BY</code> clause is used to sort data by one or more columns:</li> </ul> <pre><code>SELECT * FROM customers ORDER BY last_name;\n</code></pre> <p>This statement retrieves all columns and rows from the <code>customers</code> table, sorted by the <code>last_name</code> column.</p> <ul> <li>The <code>GROUP BY</code> clause is used to group data by one or more columns:</li> </ul> <pre><code>SELECT city, COUNT(*) FROM customers GROUP BY city;\n</code></pre> <p>This statement retrieves the <code>city</code> column and a count of how many times each <code>city</code> appears in the <code>customers</code> table.</p> <ul> <li>The <code>JOIN</code> command is used to combine data from two or more tables:</li> </ul> <pre><code>SELECT * FROM customers JOIN orders ON customers.customer_id = orders.customer_id;\n</code></pre> <p>This statement retrieves all columns and rows from both the <code>customers</code> and <code>orders</code> tables where the <code>customer_id</code> column matches in both tables.</p>"},{"location":"sql/12_company_db_1/","title":"Company Database Introduction","text":"<p>In the modern era of technology, most businesses depend on software to manage and track various aspects of their operations. One of the most important types of software that businesses rely on is the database management system (DBMS). A DBMS allows companies to store, manage, and retrieve information in a structured and organized way. A company database is a type of DBMS that is specifically designed to help organizations store and manage information about their employees, customers, products, and services.</p> <p></p> <p>A company database can be used for a wide range of purposes, such as tracking inventory, processing transactions, generating reports, and analyzing data. By keeping all the relevant information in a centralized location, a company database provides a more efficient and accurate way to manage and analyze data. This, in turn, enables businesses to make informed decisions based on reliable and up-to-date information.</p> <p></p> <p>Having a well-designed and properly maintained company database is vital to the success of any business. A good company database can help to improve operational efficiency, streamline processes, and enhance customer satisfaction. It can also help organizations to identify trends, analyze performance, and make strategic decisions based on real data.</p> <p></p> <p>In this chapter, we will explore the various components of a company database, including tables, fields, and relationships. We will also learn how to design and build a company database from scratch, as well as how to use SQL to retrieve, analyze, and manipulate data. By the end of this tutorial, you should have a good understanding how to build a database from scratch for your own business or project.</p>"},{"location":"sql/12_company_db_1/#summary-of-the-project","title":"Summary of the project","text":"<p>This project will focus on building a company database that includes seven tables: * employees * departments * projects * department_projects * employee_projects * jobs * location</p> <p>These tables will be linked together using foreign keys and relationships, allowing organizations to easily access and manage information. The project will also include the creation of primary keys, indexes, and constraints to ensure the integrity and consistency of the data. This database will provide a robust platform for companies to store, organize, and access data in a way that enhances their ability to make data-driven decisions.</p>"},{"location":"sql/12_company_db_1/#set-up-the-project","title":"Set up the project","text":"<p>Start by opening your MySQL client and connecting to your server. In our case just start MAMP like in the installation section. </p>"},{"location":"sql/12_company_db_1/#database-creation","title":"Database creation","text":"<p>Create a new database call <code>company</code> with the graphic interface like in the installation section or with the SQL command line : </p> <pre><code>CREATE DATABASE company;\n</code></pre> <p>if you used the command line option run also this command :</p> <pre><code>USE company;\n</code></pre> <p>like you've guess it just tell to MySQL to use our database for the futur queries.</p>"},{"location":"sql/12_company_db_1/#tables-creation","title":"Tables creation","text":"<p>This is the SQL script that creates the necessary tables : </p> <pre><code>-- Create Employees table\nCREATE TABLE Employees (\n    EmployeeID INT AUTO_INCREMENT PRIMARY KEY,\n    FirstName VARCHAR(50),\n    LastName VARCHAR(50),\n    Email VARCHAR(50),\n    Phone VARCHAR(20),\n    HireDate DATE,\n    Salary DECIMAL(10,2),\n    CommissionPct DECIMAL(4,2),\n    ManagerID INT,\n    DepartmentID INT,\n    JobID INT,\n    LocationID INT,\n    CONSTRAINT fk_manager FOREIGN KEY (ManagerID) REFERENCES Employees(EmployeeID),\n    CONSTRAINT fk_department FOREIGN KEY (DepartmentID) REFERENCES Departments(DepartmentID),\n    CONSTRAINT fk_job FOREIGN KEY (JobID) REFERENCES Jobs(JobID),\n    CONSTRAINT fk_location FOREIGN KEY (LocationID) REFERENCES Locations(LocationID)\n);\n\n-- Create Departments table\nCREATE TABLE Departments (\n    DepartmentID INT AUTO_INCREMENT PRIMARY KEY,\n    DepartmentName VARCHAR(50),\n    ManagerID INT,\n    LocationID INT,\n    CONSTRAINT fk_department_manager FOREIGN KEY (ManagerID) REFERENCES Employees(EmployeeID),\n    CONSTRAINT fk_department_location FOREIGN KEY (LocationID) REFERENCES Locations(LocationID)\n);\n\n-- Create Projects table\nCREATE TABLE Projects (\n    ProjectID INT AUTO_INCREMENT PRIMARY KEY,\n    ProjectName VARCHAR(50),\n    StartDate DATE,\n    EndDate DATE,\n    Budget DECIMAL(15,2)\n);\n\n-- Create Department_Projects table\nCREATE TABLE Department_Projects (\n    DepartmentID INT,\n    ProjectID INT,\n    CONSTRAINT fk_department_project_department FOREIGN KEY (DepartmentID) REFERENCES Departments(DepartmentID),\n    CONSTRAINT fk_department_project_project FOREIGN KEY (ProjectID) REFERENCES Projects(ProjectID)\n);\n\n-- Create Employee_Projects table\nCREATE TABLE Employee_Projects (\n    EmployeeID INT,\n    ProjectID INT,\n    HoursWorked DECIMAL(8,2),\n    CONSTRAINT fk_employee_project_employee FOREIGN KEY (EmployeeID) REFERENCES Employees(EmployeeID),\n    CONSTRAINT fk_employee_project_project FOREIGN KEY (ProjectID) REFERENCES Projects(ProjectID)\n);\n\n-- Create Jobs table\nCREATE TABLE Jobs (\n    JobID INT AUTO_INCREMENT PRIMARY KEY,\n    JobTitle VARCHAR(50),\n    MinSalary DECIMAL(10,2),\n    MaxSalary DECIMAL(10,2)\n);\n\n-- Create Locations table\nCREATE TABLE Locations (\n    LocationID INT AUTO_INCREMENT PRIMARY KEY,\n    Address VARCHAR(50),\n    City VARCHAR(50),\n    StateProvince VARCHAR(50),\n    Country VARCHAR(50),\n    PostalCode VARCHAR(50)\n);\n\n</code></pre> <p>Note that the foreign keys are created using the <code>CONSTRAINT</code> keyword and the <code>REFERENCES</code> keyword to specify the table and column to which the key refers. The <code>AUTO_INCREMENT</code> keyword is used to specify that the primary key column should automatically increment for each new row.</p>"},{"location":"sql/12_company_db_1/#insert-data","title":"Insert data","text":"<p>Then populate the tables with this script : </p> <pre><code>-- Insert 10 employees\nINSERT INTO employees (first_name, last_name, email, phone, hire_date, job_id, salary, manager_id, department_id)\nVALUES\n  ('John', 'Doe', 'johndoe@example.com', '555-555-1234', '2022-01-01', 1, 50000, NULL, 1),\n  ('Jane', 'Doe', 'janedoe@example.com', '555-555-5678', '2022-01-01', 2, 60000, 1, 1),\n  ('Bob', 'Smith', 'bobsmith@example.com', '555-555-9012', '2022-02-01', 3, 75000, 2, 2),\n  ('Alice', 'Johnson', 'alicejohnson@example.com', '555-555-3456', '2022-02-01', 4, 85000, 2, 2),\n  ('Mark', 'Lee', 'marklee@example.com', '555-555-7890', '2022-03-01', 5, 95000, 2, 3),\n  ('Emily', 'Chen', 'emilychen@example.com', '555-555-2345', '2022-03-01', 5, 80000, 2, 3),\n  ('Sara', 'Kim', 'sarakim@example.com', '555-555-6789', '2022-04-01', 6, 70000, 3, 4),\n  ('Michael', 'Wu', 'michaelwu@example.com', '555-555-0123', '2022-04-01', 7, 65000, 3, 4),\n  ('David', 'Nguyen', 'davidnguyen@example.com', '555-555-4567', '2022-05-01', 8, 55000, 4, 5),\n  ('Jennifer', 'Garcia', 'jennifergarcia@example.com', '555-555-8901', '2022-05-01', 9, 60000, 4, 5);\n\n-- Insert 3 departments\nINSERT INTO departments (name, manager_id, location_id)\nVALUES\n  ('Engineering', 1, 1),\n  ('Marketing', 2, 2),\n  ('Sales', 3, 3);\n\n-- Insert 4 projects\nINSERT INTO projects (name, start_date, end_date)\nVALUES\n  ('Project A', '2022-01-01', '2022-03-01'),\n  ('Project B', '2022-02-01', '2022-05-01'),\n  ('Project C', '2022-03-01', '2022-06-01'),\n  ('Project D', '2022-04-01', '2022-07-01');\n\n-- Insert 4 department_projects relationships\nINSERT INTO department_projects (department_id, project_id)\nVALUES\n  (1, 1),\n  (1, 2),\n  (2, 3),\n  (3, 4);\n\n-- insert 10 rows into department_projects table\nINSERT INTO department_projects (department_id, project_id) VALUES\n  (1, 1),\n  (1, 2),\n  (2, 1),\n  (2, 3),\n  (3, 2),\n  (3, 3),\n  (4, 1),\n  (4, 2),\n  (5, 1),\n  (5, 3);\n\n-- insert 10 rows into jobs table\nINSERT INTO jobs (title, min_salary, max_salary) VALUES\n  ('Manager', 70000, 120000),\n  ('Salesperson', 20000, 40000),\n  ('Developer', 50000, 100000),\n  ('Accountant', 35000, 60000),\n  ('HR Manager', 45000, 80000),\n  ('Marketing Specialist', 40000, 75000),\n  ('Administrative Assistant', 25000, 35000),\n  ('Designer', 45000, 80000),\n  ('Writer', 30000, 50000),\n  ('Engineer', 55000, 90000);\n\n-- insert 10 rows into location table\nINSERT INTO location (city, state, country) VALUES\n  ('New York', 'NY', 'USA'),\n  ('Los Angeles', 'CA', 'USA'),\n  ('San Francisco', 'CA', 'USA'),\n  ('Chicago', 'IL', 'USA'),\n  ('Houston', 'TX', 'USA'),\n  ('London', NULL, 'England'),\n  ('Paris', NULL, 'France'),\n  ('Berlin', NULL, 'Germany'),\n  ('Sydney', NULL, 'Australia'),\n  ('Tokyo', NULL, 'Japan');\n\n-- Insert 10 rows into the employee_projects table\nINSERT INTO employee_projects (employee_id, project_id, start_date, end_date)\nVALUES (1, 1, '2021-01-01', '2021-06-30'),\n       (1, 2, '2021-07-01', '2021-12-31'),\n       (2, 1, '2021-01-01', '2021-06-30'),\n       (2, 3, '2021-07-01', '2021-12-31'),\n       (3, 2, '2021-01-01', '2021-06-30'),\n       (3, 3, '2021-07-01', '2021-12-31'),\n       (4, 2, '2021-01-01', '2021-06-30'),\n       (4, 1, '2021-07-01', '2021-12-31'),\n       (5, 3, '2021-01-01', '2021-06-30'),\n       (5, 1, '2021-07-01', '2021-12-31');\n\n</code></pre>"},{"location":"sql/12_company_db_1/#more-informations-about-constraint-and-references","title":"More informations about <code>CONSTRAINT</code> and <code>REFERENCES</code>","text":"<p>The CONSTRAINT and REFERENCES keywords are used to create foreign key constraints in SQL. A foreign key constraint is a rule that ensures the values in a column or set of columns in one table are matched by values in another table.</p> <p></p> <p>In the example code I provided earlier, we used the CONSTRAINT keyword to create foreign key constraints between the employee_projects and employees tables, as well as between the department_projects and departments tables.</p> <p></p> <p>Here is an example of the foreign key constraint between the employee_projects and employees tables:</p> <pre><code>CREATE TABLE employee_projects (\n    id INT AUTO_INCREMENT PRIMARY KEY,\n    employee_id INT,\n    project_id INT,\n    hours_worked DECIMAL(5,2),\n    CONSTRAINT fk_employee_project_employee\n        FOREIGN KEY (employee_id)\n        REFERENCES employees (id)\n);\n</code></pre> <p>In this example, we first create the employee_projects table with the id, employee_id, project_id, and hours_worked columns. Then we use the CONSTRAINT keyword to create a foreign key constraint named fk_employee_project_employee. The FOREIGN KEY clause specifies the employee_id column as the foreign key column, and the REFERENCES clause specifies the employees table and the id column as the referenced column.</p> <p></p> <p>This foreign key constraint ensures that every value in the employee_id column in the employee_projects table must exist in the id column of the employees table.</p> <p></p> <p>The CONSTRAINT and REFERENCES keywords are powerful tools that allow you to establish relationships between tables in a database. They can help ensure data integrity and improve the accuracy and reliability of your queries.</p>"},{"location":"sql/12_company_db_1/#tests-some-queries-for-verification-to-test","title":"Tests some queries for verification --&gt; TO TEST","text":"<p>Let's take a look to ten example queries to verify the data in the seven tables:</p> <ul> <li>Retrieve all employees who work in the \"Sales\" department:</li> </ul> <pre><code>SELECT e.first_name, e.last_name, d.department_name\nFROM employees e\nJOIN departments d ON e.department_id = d.department_id\nWHERE d.department_name = 'Sales';\n</code></pre> <ul> <li>Retrieve all projects that are assigned to the \"Marketing\" department:</li> </ul> <pre><code>SELECT p.project_name, d.department_name\nFROM projects p\nJOIN department_projects dp ON p.project_id = dp.project_id\nJOIN departments d ON dp.department_id = d.department_id\nWHERE d.department_name = 'Marketing';\n</code></pre> <ul> <li>Retrieve all projects that have an estimated cost greater than $100,000:</li> </ul> <pre><code>SELECT project_name, estimated_cost\nFROM projects\nWHERE estimated_cost &gt; 100000;\n</code></pre> <ul> <li>Retrieve all employees who are working on the \"Big Project\":</li> </ul> <pre><code>SELECT e.first_name, e.last_name, p.project_name\nFROM employees e\nJOIN employee_projects ep ON e.employee_id = ep.employee_id\nJOIN projects p ON ep.project_id = p.project_id\nWHERE p.project_name = 'Big Project';\n</code></pre> <ul> <li>Retrieve all job titles and the number of employees who hold each job title:</li> </ul> <pre><code>SELECT j.job_title, COUNT(*) AS num_employees\nFROM employees e\nJOIN jobs j ON e.job_id = j.job_id\nGROUP BY j.job_title;\n</code></pre> <ul> <li>List all employees and their department:</li> </ul> <pre><code>SELECT e.employee_id, e.first_name, e.last_name, d.department_name \nFROM employees e \nINNER JOIN departments d ON e.department_id = d.department_id;\n</code></pre> <ul> <li>List all departments and their location:</li> </ul> <pre><code>SELECT d.department_name, l.city, l.state \nFROM departments d \nINNER JOIN location l ON d.location_id = l.location_id;\n</code></pre> <ul> <li>List all projects and their department:</li> </ul> <pre><code>SELECT p.project_id, p.project_name, d.department_name \nFROM projects p \nINNER JOIN department_projects dp ON p.project_id = dp.project_id \nINNER JOIN departments d ON dp.department_id = d.department_id;\n</code></pre> <ul> <li>List all employees and the projects they are working on:</li> </ul> <pre><code>SELECT e.first_name, e.last_name, p.project_name \nFROM employees e \nINNER JOIN employee_projects ep ON e.employee_id = ep.employee_id \nINNER JOIN projects p ON ep.project_id = p.project_id;\n</code></pre> <ul> <li>List all employees, their job title, and salary:</li> </ul> <pre><code>SELECT e.first_name, e.last_name, j.job_title, j.salary \nFROM employees e \nINNER JOIN jobs j ON e.job_id = j.job_id;\n</code></pre>"},{"location":"sql/12_company_db_1/#the-importance-of-schema-and-organization","title":"The importance of schema and organization","text":"<p>Creating a schema and diagrams for a database is critical, especially when dealing with large databases with many tables and relationships. Without proper organization and documentation, it can be challenging to understand the structure and relationships between different tables. </p> <p></p> <p>This is particularly true when many people are working on the database or when there is a lot of data being added and updated regularly. Having a clear schema and diagrams can help developers and users understand the structure and relationships of the data, leading to more efficient and effective use of the database. Additionally, it can help to identify and prevent errors in the data or in the database design itself. Overall, investing time in creating a clear schema and diagrams can save time and resources in the long run and make the database easier to manage and use.</p>"},{"location":"sql/12_company_db_1/#wrap-up","title":"Wrap-up","text":"<ul> <li>In this project, we learned how to create a company database using MySQL.</li> <li>We created 7 tables: employees, departments, projects, department_projects, employee_projects, jobs, and location.</li> <li>We added primary keys to all tables with auto-increment options for unique identification and added foreign keys to establish relationships between tables.</li> <li>We inserted data into each table and test some queries.</li> <li>We also learned about the importance of schema and diagrams for databases, especially as the number of tables and relationships grows, and the significance of foreign keys in ensuring data integrity and consistency.</li> </ul>"},{"location":"sql/13_queries_db/","title":"More queries","text":"<p>In this chapter we will be working on the MySQL Sample Database. The MySQL Sample Database provides a sample database called \"employees\" that you can use to practice SQL queries. You can download the database and load it into your MySQL server. Link to the database</p>"},{"location":"sql/13_queries_db/#download-the-database-and-load-it-into-mysqlworkbench","title":"Download the database and load it into MySQLWorkbench","text":"<p>\ud83d\udea7 You need to run MySQL server (with MAMP for example) before lunching MySQLWorkbench \ud83d\udea7</p>"},{"location":"sql/13_queries_db/#dowload-the-mysql-sample-database","title":"Dowload the MySQL Sample Database","text":"<p>You can follow the documentation above or just go to : link and download the repo as zip. </p>"},{"location":"sql/13_queries_db/#load-mysql-sample-database-into-mysqlworkbench","title":"Load MySQL Sample Database into MySQLWorkbench","text":"<p>When you have downloaded the git repo as zip go to your Download files and unzip the folder and  open MySQLWorkbench then go to &gt; <code>File</code> &gt; <code>Run SQL Scripts</code> and load the file <code>employees.sql</code></p>"},{"location":"sql/13_queries_db/#run-a-test-query","title":"Run a test query","text":"<p>We will running a test query for testing our database, we must open a new file for writing our query for that you can click on the file icon button like in the screen below or go to <code>File</code> &gt; <code>New Query Tab</code></p> <pre><code>use employees;\n\nSELECT d.dept_name, AVG(s.salary) AS avg_salary\nFROM departments d\nINNER JOIN dept_emp de ON d.dept_no = de.dept_no\nINNER JOIN salaries s ON de.emp_no = s.emp_no\nGROUP BY d.dept_name;\n</code></pre> <p>Notice that, the first line <code>use employees;</code> is here to tell to our software to use the employees database then you can see the result of our test query in the window bellow :</p> <p></p> <p></p> <p></p> <p>We will study in detail this query later don't worry. </p>"},{"location":"sql/13_queries_db/#in-depth-look-at-more-basic-queries-in-sql","title":"In-depth look at more basic queries in SQL","text":"<p>We encourage you to pratice the queries into MySQLWorkbench, let's review some basics !</p>"},{"location":"sql/13_queries_db/#select-statement","title":"SELECT statement:","text":"<p>The <code>SELECT</code> statement is used to retrieve data from a table in a database. It can take multiple arguments, which are separated by commas. </p> <p></p> <p>The <code>*</code> character can be used as a shorthand to select all columns in a table. We often use the <code>AS</code> keyword is used to assign a name to a column in the output.</p> <pre><code>SELECT first_name, last_name, salary AS \"Annual Salary\"\nFROM employees;\n</code></pre> <p>In this example, the AS keyword is used to assign a new name to the \"salary\" column in the output. The new name is \"Annual Salary\".</p> <p></p> <p>This query selects the first name, last name, and salary of all the employees in the \"employees\" table, but it renames the \"salary\" column as \"Annual Salary\" in the output.</p> <p></p> <p>Note that the AS keyword is optional, and you can also use a space or equals sign to assign a name to a column. For example, the following query is equivalent to the one above:</p> <pre><code>SELECT first_name, last_name, salary \"Annual Salary\"\nFROM employees;\n</code></pre> <p>In both cases, the output column is named \"Annual Salary\".</p>"},{"location":"sql/13_queries_db/#where-clause","title":"WHERE clause:","text":"<p>The WHERE clause is used to filter the results returned by a SELECT statement. It contains a logical expression that evaluates to true or false for each row in the table.</p> <pre><code>SELECT *\nFROM orders\nWHERE order_date &gt;= '2022-01-01';\n</code></pre> <p>This query selects all the columns from the \"orders\" table where the order date is on or after January 1, 2022.</p> <p></p> <p>This is an other example : </p> <pre><code>SELECT first_name, last_name, salary * 12 AS \"Annual Salary\"\nFROM employees\nWHERE hire_date &gt;= '2005-01-01';\n</code></pre> <p>In this example, the WHERE clause is used to filter the results to include only employees hired on or after January 1, 2005. The AS keyword is used to assign a new name to the \"salary * 12\" expression in the output. The new name is \"Annual Salary\".</p> <p></p> <p>This query selects the first name, last name, and annual salary of all the employees in the \"employees\" table who were hired on or after January 1, 2005. The annual salary is calculated by multiplying the monthly salary by 12.</p> <p></p> <p>Note that the order of the SQL clauses matters. The WHERE clause is used to filter the results before the AS keyword is used to assign a new name to the output column.</p>"},{"location":"sql/13_queries_db/#join-clause","title":"JOIN clause","text":"<p>The <code>JOIN</code> clause is used to combine rows from two or more tables based on a related column between them. Here's an example:</p> <pre><code>SELECT customers.first_name, customers.last_name, orders.order_date\nFROM customers\nINNER JOIN orders\nON customers.customer_id = orders.customer_id;\n</code></pre> <p>This query selects the first name, last name, and order date of all customers who have placed an order. The results are obtained by joining the \"customers\" and \"orders\" tables on the customer_id column.</p> <p></p> <p>We will discuss nore about <code>JOIN</code> later don't worry. </p>"},{"location":"sql/13_queries_db/#order-by-clause","title":"ORDER BY clause","text":"<p>The ORDER BY clause is used to sort the results returned by a SELECT statement based on one or more columns. Here's an example:</p> <pre><code>SELECT product_name, unit_price\nFROM products\nORDER BY unit_price DESC;\n</code></pre> <p>This query selects the product name and unit price of all the products in the \"products\" table and sorts the results in descending order based on the unit price.</p>"},{"location":"sql/13_queries_db/#group-by-clause","title":"GROUP BY clause","text":"<p>The GROUP BY clause is used to group the rows returned by a SELECT statement based on one or more columns. The columns listed in the SELECT statement must be either in the GROUP BY clause or have an aggregate function applied to them. Aggregate functions like COUNT, SUM, AVG, MAX, and MIN can be used to perform calculations on the grouped data.</p> <pre><code>SELECT category_id, COUNT(*) AS num_products\nFROM products\nGROUP BY category_id;\n</code></pre> <p>This query groups the products in the \"products\" table by their category and counts the number of products in each category. The COUNT(*) function is used to count the number of rows in each group, and the AS keyword is used to assign the name \"num_products\" to the output column.</p> <p></p> <p>Here an other example : </p> <pre><code>SELECT department, AVG(salary) AS \"Average Salary\"\nFROM employees\nGROUP BY department\nORDER BY \"Average Salary\" DESC;\n</code></pre> <p>In this example, the GROUP BY clause is used to group the employees by department, and the AVG() function is used to calculate the average salary for each department. The AS keyword is used to assign a new name to the \"AVG(salary)\" expression in the output. The new name is \"Average Salary\".</p> <p></p> <p>The ORDER BY keyword is used to sort the results in descending order based on the \"Average Salary\" column. Note that we need to enclose the output column name in double quotes because it contains a space.</p> <p></p> <p>This query selects the department and average salary of all the employees in the \"employees\" table, grouped by department, and sorted in descending order by average salary.</p> <p></p> <p>Note that when using the GROUP BY clause, the SELECT statement can only include the columns that are specified in the GROUP BY clause or have an aggregate function applied to them. Any other columns will result in an error, unless they are included in an aggregate function. In this example, we only select the department and average salary columns because the department column is included in the GROUP BY clause.</p>"},{"location":"sql/13_queries_db/#wrap-up","title":"Wrap up","text":"<p>These are just a few examples of basic SQL queries, but they provide a good foundation for building more complex queries. By combining these statements with other SQL clauses, you can perform powerful data analysis and extract valuable insights from your data.</p> <p></p> <p>Let's summarize what we've learn in this section : </p> <ul> <li>The SELECT statement is used to retrieve data from a table in a database. It can take multiple arguments, which are separated by commas. The * character can be used as a shorthand to select all columns in a table. The AS keyword is used to assign a name to a column in the output.</li> <li>The WHERE clause is used to filter the results returned by a SELECT statement. It contains a logical expression that evaluates to true or false for each row in the table.</li> <li>The JOIN clause is used to combine rows from two or more tables based on a related column between them. It can be used to join tables on a primary key/foreign key relationship or on a common column.</li> <li>The GROUP BY clause is used to group the rows returned by a SELECT statement based on one or more columns. The columns listed in the SELECT statement must be either in the GROUP BY clause or have an aggregate function applied to them.</li> <li>Aggregate functions like COUNT, SUM, AVG, MAX, and MIN can be used to perform calculations on the grouped data.</li> <li>The ORDER BY clause is used to sort the results returned by a SELECT statement based on one or more columns. It can be used to sort in ascending (ASC) or descending (DESC) order.</li> <li>The AS keyword is used to assign a new name to a column or an expression in the output.</li> <li>SQL keywords are not case-sensitive, but it is a best practice to use them in uppercase to make the code more readable.</li> <li>The order of the SQL clauses matters, and it can affect the output of the query.</li> </ul>"},{"location":"sql/14_functions/","title":"SQL Functions","text":""},{"location":"sql/14_functions/#introduction-to-functions-in-sql","title":"Introduction to Functions in SQL","text":"<p>SQL functions are built-in functions that are used to perform operations on data in a database. They take one or more arguments as input, perform a specific operation, and return a result. Functions can be used in SELECT, WHERE, HAVING, and ORDER BY clauses of a SQL query.</p> <p></p> <p>There are many different types of functions in SQL, including aggregate functions, scalar functions, date and time functions, and string functions. Each type of function performs a specific operation on data and returns a result.</p> <p></p> <p>Overall, SQL functions are essential for data analysis because they allow you to perform complex calculations, filter data based on specific criteria, clean up messy data, aggregate data to provide insights into trends and patterns, and transform data from one format to another. By mastering SQL functions, you can become a more effective data analyst and make more informed decisions based on your data.</p>"},{"location":"sql/14_functions/#overview-of-different-types-of-functions-and-examples","title":"Overview of Different Types of Functions and Examples","text":""},{"location":"sql/14_functions/#aggregate-functions","title":"Aggregate Functions","text":"<p>Aggregate functions are used to perform calculations on groups of rows and return a single value. Some common aggregate functions are:</p> <ul> <li><code>COUNT()</code>: returns the number of rows in a table or the number of non-null values in a column.</li> </ul> <pre><code>SELECT COUNT(*) as num_employees\nFROM employees;\n</code></pre> <p>This query counts the number of rows in the \"employees\" table and assigns the name \"num_employees\" to the output column.</p> <ul> <li><code>SUM()</code>: returns the sum of values in a column.</li> </ul> <pre><code>SELECT SUM(salary) as total_salary\nFROM salaries;\n</code></pre> <p>This query calculates the total salary of all employees in the \"salaries\" table and assigns the name \"total_salary\" to the output column.</p> <ul> <li><code>AVG()</code>: returns the average value of a column.</li> </ul> <pre><code>SELECT AVG(salary) as avg_salary\nFROM salaries;\n</code></pre> <p>This query calculates the average salary of all employees in the \"salaries\" table and assigns the name \"avg_salary\" to the output column.</p> <ul> <li><code>MAX()</code>: returns the maximum value in a column.</li> </ul> <pre><code>SELECT MAX(salary) as max_salary\nFROM salaries;\n</code></pre> <p>This query finds the highest salary in the \"salaries\" table and assigns the name \"max_salary\" to the output column. - <code>MIN()</code>: returns the minimum value in a column.</p> <pre><code>SELECT MIN(salary) as min_salary\nFROM salaries;\n</code></pre> <p>This query finds the lowest salary in the \"salaries\" table and assigns the name \"min_salary\" to the output column.</p>"},{"location":"sql/14_functions/#scalar-functions","title":"Scalar Functions","text":"<p>Scalar functions are used to perform operations on individual values and return a single value. Some common scalar functions are:</p> <ul> <li><code>UPPER()</code>: converts a string to uppercase.</li> </ul> <pre><code>SELECT UPPER(first_name) as upper_first_name\nFROM employees;\n</code></pre> <p>This query converts the first name of all employees in the \"employees\" table to uppercase and assigns the name \"upper_first_name\" to the output column. - <code>LOWER()</code>: converts a string to lowercase.</p> <pre><code>SELECT LOWER(last_name) as lower_last_name\nFROM employees;\n</code></pre> <p>This query converts the last name of all employees in the \"employees\" table to lowercase and assigns the name \"lower_last_name\" to the output column.</p> <ul> <li><code>LENGTH()</code>: returns the length of a string.</li> </ul> <pre><code>SELECT first_name, LENGTH(first_name) as name_length\nFROM employees;\n</code></pre> <p>This query returns the first name of all employees in the \"employees\" table, and calculates the length of each name and assigns the name \"name_length\" to the output column.</p>"},{"location":"sql/14_functions/#date-and-time-functions","title":"Date and Time Functions","text":"<p>Date and time functions are used to perform operations on date and time values. Some common date and time functions are:</p> <ul> <li><code>DATE()</code>: extracts the date part from a datetime value.</li> </ul> <pre><code>SELECT hire_date, DATE(hire_date) as hire_date_only\nFROM employees;\n</code></pre> <p>This query extracts the date part from the \"hire_date\" column of the \"employees\" table and assigns the name \"hire_date_only\" to the output column.</p> <ul> <li><code>YEAR()</code>: returns the year from a date value.</li> </ul> <pre><code>SELECT hire_date, YEAR(hire_date) as hire_year\nFROM employees;\n</code></pre> <p>This query returns the \"hire_date\" column of the \"employees\" table and calculates the year each employee was hired. The name \"hire_year\" is assigned to the output column.</p> <p></p> <p>Same <code>MONTH()</code> function :</p> <pre><code>SELECT hire_date, MONTH(hire_date) as hire_month\nFROM employees;\n</code></pre> <p>This query returns the \"hire_date\" column of the \"employees\" table and calculates the month each employee was hired. The name \"hire_month\" is assigned to the output column.</p>"},{"location":"sql/14_functions/#string-functions","title":"String Functions","text":"<p>String functions are used to perform operations on string values. Some common string functions are:</p> <ul> <li>CONCAT(): concatenates two or more strings together.</li> </ul> <pre><code>SELECT CONCAT(first_name, ' ', last_name) as full_name\nFROM employees;\n</code></pre> <p>This query combines the first name and last name columns of the \"employees\" table and assigns the name \"full_name\" to the output column. - LEFT(): returns the leftmost characters of a string.</p> <pre><code>SELECT first_name, LEFT(first_name, 3) as initial\nFROM employees;\n</code></pre> <p>This query returns the first name of all employees in the \"employees\" table and extracts the first three characters of each name. The name \"initial\" is assigned to the output column. - REPLACE(): replaces a substring in a string with another substring.</p> <pre><code>SELECT REPLACE(email, 'gmail', 'yahoo') as new_email\nFROM employees;\n</code></pre> <p>This query returns the email column of the \"employees\" table and replaces the substring 'gmail' with 'yahoo' in each email address. The name \"new_email\" is assigned to the output column.</p>"},{"location":"sql/14_functions/#mix-up","title":"Mix up","text":"<p>Let's take a look at three examples of SQL queries that use a mix of functions on the \"employees\" database again. </p>"},{"location":"sql/14_functions/#find-the-average-salary-of-employees-by-department-and-round-the-results-to-two-decimal-places","title":"Find the average salary of employees by department, and round the results to two decimal places:","text":"<pre><code>SELECT department, ROUND(AVG(salary), 2) as avg_salary\nFROM employees\nJOIN dept_emp ON employees.emp_no = dept_emp.emp_no\nJOIN departments ON dept_emp.dept_no = departments.dept_no\nGROUP BY department;\n</code></pre> <p>This query joins the \"employees\", \"dept_emp\", and \"departments\" tables, and uses the AVG() function to calculate the average salary of employees in each department. The ROUND() function is used to round the results to two decimal places. The output includes the department name and the average salary for each department.</p> <p></p> <p>Don't worry about the <code>JOIN</code> clause we will get to it in detail later. </p>"},{"location":"sql/14_functions/#find-the-top-10-most-common-first-names-among-employees-and-show-the-number-of-employees-with-each-name","title":"Find the top 10 most common first names among employees, and show the number of employees with each name:","text":"<pre><code>SELECT first_name, COUNT(*) as num_employees\nFROM employees\nGROUP BY first_name\nORDER BY num_employees DESC\nLIMIT 10;\n</code></pre> <p>This query uses the COUNT() function to count the number of employees with each first name, and the GROUP BY clause to group the results by first name. The ORDER BY clause is used to sort the results in descending order by the number of employees, and the LIMIT clause is used to show only the top 10 results.</p>"},{"location":"sql/14_functions/#find-the-number-of-employees-hired-in-each-year-and-show-the-results-as-a-percentage-of-the-total-number-of-employees","title":"Find the number of employees hired in each year, and show the results as a percentage of the total number of employees:","text":"<pre><code>SELECT YEAR(hire_date) as hire_year, COUNT(*) / (SELECT COUNT(*) FROM employees) * 100 as percentage\nFROM employees\nGROUP BY hire_year;\n</code></pre> <p>This query uses the YEAR() function to extract the year from the hire date of each employee, and the COUNT() function to count the number of employees hired in each year. The subquery (SELECT COUNT(*) FROM employees) is used to calculate the total number of employees in the \"employees\" table. The percentage of employees hired in each year is calculated by dividing the count by the total number of employees and multiplying by 100. The output includes the hire year and the percentage of employees hired in that year.</p>"},{"location":"sql/14_functions/#find-the-number-of-employees-born-in-each-month-and-sort-the-results-by-month","title":"Find the number of employees born in each month, and sort the results by month:","text":"<pre><code>SELECT MONTH(birth_date) as birth_month, COUNT(*) as num_employees\nFROM employees\nGROUP BY birth_month\nORDER BY birth_month;\n</code></pre> <p>This query uses the MONTH() function to extract the month from the birth date of each employee, and the COUNT() function to count the number of employees born in each month. The GROUP BY clause is used to group the results by birth month, and the ORDER BY clause is used to sort the results by month.</p>"},{"location":"sql/14_functions/#find-the-number-of-employees-who-were-hired-in-each-year-and-show-the-results-as-a-bar-chart","title":"Find the number of employees who were hired in each year, and show the results as a bar chart:","text":"<pre><code>SELECT YEAR(hire_date) as hire_year, COUNT(*) as num_employees\nFROM employees\nGROUP BY hire_year;\n</code></pre> <p>This query uses the YEAR() function to extract the year from the hire date of each employee, and the COUNT() function to count the number of employees hired in each year. The GROUP BY clause is used to group the results by hire year. You can visualize the results as a bar chart in a data visualization tool, such as Tableau or Power BI, to see the distribution of hires over time.</p>"},{"location":"sql/14_functions/#conclusion","title":"Conclusion","text":"<p>SQL functions are powerful tools that allow you to perform operations on data and return meaningful results. They can be used to calculate aggregate values, manipulate strings, and work with date and time values. By understanding the different types of functions available in SQL and how to use them in queries, you can perform complex data analysis and retrieve valuable insights from your data.</p>"},{"location":"sql/15_Wildcards/","title":"Wildcards &amp; Unions","text":""},{"location":"sql/15_Wildcards/#wildcaards","title":"Wildcaards","text":"<p>Wildcards are special characters that are used in SQL to represent one or more characters in a string. They are used in conjunction with the LIKE operator to perform pattern matching on text values. Wildcards allow you to search for strings that match a specific pattern, even if you don't know the exact value of the string.</p> <p></p> <p>Wildcards are particularly useful when searching for records that have similar but not identical values in a column. For example, you can use a wildcard to find all employees with a first name that starts with the letter \"J\", or all employees with a last name that ends in \"son\".</p>"},{"location":"sql/15_Wildcards/#overview-of-different-wildcard-characters-and-their-uses","title":"Overview of Different Wildcard Characters and Their Uses","text":"<p>There are three main wildcard characters in SQL: the percent sign (%), the underscore (_), and the square brackets ([]). Each wildcard character serves a different purpose and can be used in different ways.</p>"},{"location":"sql/15_Wildcards/#the-percent-sign","title":"The Percent Sign (%)","text":"<p>The percent sign is used to represent zero or more characters in a string. It can be used at the beginning, end, or in the middle of a search pattern.</p> <p></p> <p>For example, to find all employees with a first name that starts with the letter \"J\", you can use the following SQL query:</p> <pre><code>SELECT * FROM employees\nWHERE first_name LIKE 'J%';\n</code></pre> <p>This query returns all employees whose first name starts with the letter \"J\". The % wildcard character is used to match any number of characters that come after the letter \"J\".</p> <p></p> <p>Similarly, to find all employees with a last name that ends in \"son\", you can use the following SQL query:</p> <pre><code>SELECT * FROM employees\nWHERE last_name LIKE '%son';\n</code></pre> <p>This query returns all employees whose last name ends in the letters \"son\". The % wildcard character is used to match any number of characters that come before the letters \"son\".</p>"},{"location":"sql/15_Wildcards/#the-underscore-_","title":"The Underscore (_)","text":"<p>The underscore is used to represent a single character in a string. It can be used at the beginning, end, or in the middle of a search pattern.</p> <p></p> <p>For example, to find all employees with a first name that starts with the letter \"J\" and has a second letter that is an \"o\", you can use the following SQL query:</p> <pre><code>SELECT * FROM employees\nWHERE first_name LIKE 'J_o%';\n</code></pre> <p>This query returns all employees whose first name starts with the letter \"J\", has a second letter that is an \"o\", and has any number of characters that come after the second letter.</p>"},{"location":"sql/15_Wildcards/#the-square-brackets","title":"The Square Brackets ([])","text":"<p>The square brackets are used to represent a single character that can be any one of the characters specified within the brackets. For example, to find all employees with a first name that starts with the letters \"J\" or \"P\", you can use the following SQL query:</p> <pre><code>SELECT * FROM employees\nWHERE first_name LIKE '[JP]%';\n</code></pre> <p>This query returns all employees whose first name starts with the letters \"J\" or \"P\". The square brackets are used to specify that the first letter can be either \"J\" or \"P\".</p> <p></p> <p>You can also use the square brackets to search for ranges of characters. For example, to find all employees with a last name that starts with the letters \"M\" to \"Z\", you can use the following SQL query:</p> <pre><code>SELECT * FROM employees\nWHERE last_name LIKE '[M-Z]%';\n</code></pre> <p>This query returns all employees whose last name starts with any letter from \"M\" to \"Z\". The square brackets and the \"-\" symbol are used to specify the range of letters.</p>"},{"location":"sql/15_Wildcards/#union","title":"Union","text":"<p>Union is a set operation in SQL that is used to combine the results of two or more <code>SELECT</code> statements into a single result set. Union returns a distinct set of rows that are present in either of the two or more <code>SELECT</code> statements. Union can be used to combine data from multiple tables, or to combine data from a single table that is split across multiple columns.</p> <p></p> <p>Union can be useful when you need to combine data from multiple sources or when you want to merge two or more tables with similar structure. Union can help simplify data analysis by providing a consolidated view of data that is spread across multiple sources.</p>"},{"location":"sql/15_Wildcards/#overview-of-how-to-use-union-to-combine-data","title":"Overview of How to Use Union to Combine Data","text":"<p>The syntax for using Union in SQL is as follows:</p> <pre><code>SELECT column1, column2, ... FROM table1\nUNION\nSELECT column1, column2, ... FROM table2;\n</code></pre> <p>In this syntax, the first <code>SELECT</code> statement selects data from table1 and the second <code>SELECT</code> statement selects data from <code>table2</code>. The column names and data types of the columns in each <code>SELECT</code> statement must match.</p> <p>Union combines the results of the two <code>SELECT</code> statements and removes any duplicate rows. The columns in the result set are determined by the columns in the first <code>SELECT</code> statement.</p> <p>Here are a few examples of how to use Union to combine data:</p>"},{"location":"sql/15_Wildcards/#example-1-combine-data-from-two-tables","title":"Example 1: Combine Data from Two Tables","text":"<p>Suppose you have two tables in the \"employees\" database: \"sales\" and \"marketing\". Both tables have the same structure and contain sales data for different regions. You can use Union to combine the sales data from both tables into a single result set:</p> <pre><code>SELECT region, sales_amount, year FROM sales\nUNION\nSELECT region, sales_amount, year FROM marketing;\n</code></pre> <p>This query combines the sales data from the \"sales\" and \"marketing\" tables and returns a result set that includes the region, sales amount, and year for each sale. Union removes any duplicate rows from the result set.</p>"},{"location":"sql/15_Wildcards/#example-2-combine-data-from-multiple-columns","title":"Example 2: Combine Data from Multiple Columns","text":"<p>Suppose you have a table in the \"employees\" database that stores the names of employees in two columns: \"first_name\" and \"last_name\". You can use Union to combine the data from both columns into a single column:</p> <pre><code>SELECT first_name as name FROM employees\nUNION\nSELECT last_name as name FROM employees;\n</code></pre> <p>This query combines the data from the \"first_name\" and \"last_name\" columns into a single column called \"name\". Union removes any duplicate names from the result set.</p>"},{"location":"sql/15_Wildcards/#example-3-use-union-all-to-include-duplicate-rows","title":"Example 3: Use Union All to Include Duplicate Rows","text":"<p>By default, Union removes duplicate rows from the result set. If you want to include all rows from both <code>SELECT</code> statements, including duplicates, you can use Union All instead:</p> <pre><code>SELECT region, sales_amount, year FROM sales\nUNION ALL\nSELECT region, sales_amount, year FROM marketing;\n</code></pre> <p>This query combines the sales data from the \"sales\" and \"marketing\" tables and returns a result set that includes all rows, including duplicates.</p>"},{"location":"sql/17_joins/","title":"Joins","text":""},{"location":"sql/17_joins/#explanation-of-joins-in-sql","title":"Explanation of Joins in SQL","text":"<p>Joins in SQL are used to combine data from two or more tables in a relational database. Joins allow you to retrieve data that is spread across multiple tables by linking related data together.</p> <p></p> <p>A join creates a new virtual table that contains data from the tables being joined. The data in the virtual table is a combination of data from the original tables that match a specific condition. The condition for joining tables is typically based on the values of a common column or set of columns in each table.</p> <p></p> <p>Joins are an essential tool for retrieving complex data from a database. By linking related data together, joins allow you to retrieve data that is spread across multiple tables in a single query.</p>"},{"location":"sql/17_joins/#overview-of-different-types-of-joins-and-how-to-use-them","title":"Overview of Different Types of Joins and How to Use Them","text":"<p>There are several types of joins in SQL, including <code>inner join</code>, <code>left join</code>, <code>right join</code>, and <code>full outer join</code>. Each type of join is used to combine data from two or more tables in a different way.</p> <p></p> <p>Here a summary schema for each type of join : </p> <p></p> <p></p> <ul> <li>Inner Join: This join returns only the rows that have matching values in both tables. In the image, the result of an inner join between tables A and B is shown. Only the rows that have matching values in both tables are included in the result set.</li> <li>Left Join: This join returns all the rows from the left table and the matching rows from the right table. If there is no match in the right table, the result will contain NULL values for those columns. In the image, the result of a left join between tables A and B is shown. All the rows from table A are included in the result set, and the matching rows from table B are included. Rows in table A that have no matching rows in table B are included, with NULL values for the columns in table B.</li> <li>Right Join: This join returns all the rows from the right table and the matching rows from the left table. If there is no match in the left table, the result will contain NULL values for those columns. In the image, the result of a right join between tables A and B is shown. All the rows from table B are included in the result set, and the matching rows from table A are included. Rows in table B that have no matching rows in table A are included, with NULL values for the columns in table A.</li> <li>Full Outer Join: This join returns all the rows from both tables, with NULL values in the columns where there is no match. In the image, the result of a full outer join between tables A and B is shown. All the rows from both tables are included in the result set, with NULL values in the columns where there is no match.</li> <li>Left Outer Join or Left Excluding Join: This join returns all the rows from the left table that do not have a matching row in the right table. In the image, the result of a left outer join (or left excluding join) between tables A and B is shown. Only the rows from table A that do not have a matching row in table B are included in the result set.</li> <li>Right Outer Join or Right Excluding Join: This join returns all the rows from the right table that do not have a matching row in the left table. In the image, the result of a right outer join (or right excluding join) between tables A and B is shown. Only the rows from table B that do not have a matching row in table A are included in the result set.</li> </ul>"},{"location":"sql/17_joins/#some-examples-on-mysql-employees-database","title":"Some examples on MySQL Employees Database","text":""},{"location":"sql/17_joins/#inner-join","title":"Inner Join","text":"<p>An inner join returns only the rows that have matching values in both tables being joined. The syntax for an inner join is as follows:</p> <pre><code>SELECT column1, column2, ... FROM table1\nINNER JOIN table2\nON table1.column = table2.column;\n</code></pre> <p>In this syntax, the <code>INNER JOIN</code> keyword specifies that an inner join is being performed. The <code>ON</code> keyword specifies the condition for joining the tables. The columns being joined must have the same data type and contain similar data.</p> <p></p> <p>Here's an example of an inner join that combines data from the \"employees\" and \"departments\" tables:</p> <pre><code>SELECT employees.emp_no, employees.first_name, employees.last_name, departments.dept_name\nFROM employees\nINNER JOIN departments\nON employees.dept_no = departments.dept_no;\n</code></pre> <p>This query returns a result set that includes the employee number, first name, last name, and department name for each employee. The INNER JOIN operator links the \"employees\" and \"departments\" tables on the \"dept_no\" column, and returns only the rows where there is a match between the two tables.</p>"},{"location":"sql/17_joins/#left-join","title":"Left Join","text":"<p>A left join returns all the rows from the left table and the matching rows from the right table. If there are no matching rows in the right table, the result set will contain NULL values for the columns in the right table. The syntax for a left join is as follows:</p> <pre><code>SELECT column1, column2, ... FROM table1\nLEFT JOIN table2\nON table1.column = table2.column;\n</code></pre> <p>In this syntax, the <code>LEFT JOIN</code> keyword specifies that a left join is being performed. The ON keyword specifies the condition for joining the tables.</p> <p></p> <p>Here's an example of a left join that combines data from the <code>employees</code> and <code>departments</code> tables:</p> <pre><code>SELECT employees.emp_no, employees.first_name, employees.last_name, departments.dept_name\nFROM employees\nLEFT JOIN departments\nON employees.dept_no = departments.dept_no;\n</code></pre> <p>This query returns a result set that includes the employee number, first name, last name, and department name for each employee. The <code>LEFT JOIN</code> operator links the <code>employees</code> and <code>departments</code> tables on the <code>dept_no</code> column, and returns all the rows from the <code>employees</code> table, and the matching rows from the <code>departments</code> table.</p>"},{"location":"sql/17_joins/#right-join","title":"Right Join","text":"<p>A right join returns all the rows from the right table and the matching rows from the left table. If there are no matching rows in the left table, the result set will contain <code>NULL</code> values for the columns in the left table. </p> <p></p> <p>Here's an example of a right join that combines data from the <code>employees</code> and <code>departments</code> tables:</p> <pre><code>SELECT employees.emp_no, employees.first_name, employees.last_name, departments.dept_name\nFROM employees\nRIGHT JOIN departments\nON employees.dept_no = departments.dept_no;\n</code></pre> <p>This query returns a result set that includes the employee number, first name, last name, and department name for each employee. The <code>RIGHT JOIN</code> operator links the <code>employees</code> and <code>departments</code> tables on the <code>dept_no</code> column, and returns all the rows from the <code>departments</code> table, and the matching rows from the <code>employees</code> table.</p>"},{"location":"sql/17_joins/#full-outer-join","title":"Full Outer Join","text":"<p>A full outer join returns all the rows from both tables being joined, and <code>NULL</code> values for the columns that do not have matching values in the other table. The syntax for a full outer join varies depending on the database management system being used. In MySQL, a full outer join can be simulated using a combination of left join and union operators:</p> <pre><code>SELECT employees.emp_no, employees.first_name, employees.last_name, departments.dept_name\nFROM employees\nLEFT JOIN departments\nON employees.dept_no = departments.dept_no\nUNION\nSELECT employees.emp_no, employees.first_name, employees.last_name, departments.dept_name\nFROM employees\nRIGHT JOIN departments\nON employees.dept_no = departments.dept_no\nWHERE employees.dept_no IS NULL;\n</code></pre> <p>This query combines the results of a <code>left join</code> and a <code>right join</code> to simulate a full outer join. The first <code>SELECT</code> statement performs a <code>left join</code> and returns all the rows from the <code>employees</code> table and the matching rows from the <code>departments</code> table. The second <code>SELECT</code> statement performs a right join and returns all the rows from the <code>departments</code> table and the matching rows from the <code>employees</code> table where there is no match in the <code>employees</code> table. The <code>UNION</code> operator combines the results of the two <code>SELECT</code> statements.</p> <p></p> <p>This is the same version with the <code>full outer join</code> keyword : </p> <pre><code>SELECT employees.emp_no, employees.first_name, employees.last_name, departments.dept_name\nFROM employees\nFULL OUTER JOIN departments\nON employees.dept_no = departments.dept_no\nWHERE employees.dept_no IS NULL OR departments.dept_no IS NULL;\n</code></pre> <p>In this query, the <code>FULL OUTER JOIN</code> returns all the rows from both tables, including those that do not have a match in the other table. The <code>WHERE</code> clause filters the result set to include only the rows where either the <code>employees.dept_no</code> or <code>departments.dept_no</code> is <code>NULL</code>, which indicates that there is no match in the other table.</p>"},{"location":"sql/17_joins/#more-examples-of-left-join-inner-join-and-right-join","title":"More examples of <code>left join</code>, <code>inner join</code> and <code>right join</code>","text":""},{"location":"sql/17_joins/#inner-join-example-1","title":"Inner Join Example 1","text":"<p>Suppose you want to retrieve data that shows the salary of each employee along with the department name for the department they work in. You can use an inner join to link the <code>employees</code> and <code>dept_emp</code> tables on the <code>emp_no</code> column and the <code>departments</code> and <code>dept_emp</code> tables on the <code>dept_no</code> column:</p> <pre><code>SELECT e.emp_no, e.first_name, e.last_name, d.dept_name, s.salary\nFROM employees e\nINNER JOIN dept_emp de ON e.emp_no = de.emp_no\nINNER JOIN departments d ON de.dept_no = d.dept_no\nINNER JOIN salaries s ON e.emp_no = s.emp_no;\n</code></pre> <p>This query returns a result set that includes the employee number, first name, last name, department name, and salary for each employee. The <code>INNER JOIN</code> operator links the <code>employees</code> and <code>dept_emp</code> tables on the <code>emp_no</code> column, and links the <code>departments</code> and <code>dept_emp</code> tables on the <code>dept_no</code> column, and links the <code>salaries</code> table on the <code>emp_no</code> column.</p>"},{"location":"sql/17_joins/#inner-join-example-2","title":"Inner Join Example 2","text":"<p>Suppose you want to retrieve data that shows the department name and manager's name for each department in the company. You can use an inner join to link the <code>departments</code> and <code>dept_manager</code> tables on the <code>dept_no</code> column, and link the <code>employees</code> table on the <code>emp_no</code> column to get the name of the manager:</p> <pre><code>SELECT d.dept_name, e.first_name, e.last_name\nFROM departments d\nINNER JOIN dept_manager dm ON d.dept_no = dm.dept_no\nINNER JOIN employees e ON dm.emp_no = e.emp_no;\n</code></pre> <p>This query returns a result set that includes the department name and the first and last name of the manager for each department. The INNER JOIN operator links the \"departments\" and \"dept_manager\" tables on the \"dept_no\" column, and links the \"employees\" table on the \"emp_no\" column to get the name of the manager.</p>"},{"location":"sql/17_joins/#left-join-example-1","title":"Left Join Example 1","text":"<p>Suppose you want to retrieve data that shows the name and department of each employee, even if they are not currently assigned to a department. You can use a left join to link the \"employees\" and \"dept_emp\" tables on the \"emp_no\" column, and link the \"departments\" table on the \"dept_no\" column:</p> <pre><code>SELECT e.first_name, e.last_name, d.dept_name\nFROM employees e\nLEFT JOIN dept_emp de ON e.emp_no = de.emp_no\nLEFT JOIN departments d ON de.dept_no = d.dept_no;\n</code></pre> <p>This query returns a result set that includes the first name, last name, and department name for each employee. The LEFT JOIN operator links the \"employees\" and \"dept_emp\" tables on the \"emp_no\" column, and links the \"departments\" table on the \"dept_no\" column. Even if an employee is not currently assigned to a department, their name will still appear in the result set with a NULL value for the \"dept_name\" column.</p>"},{"location":"sql/17_joins/#left-join-example-2","title":"Left Join Example 2","text":"<p>Suppose you want to retrieve data that shows the total number of sales made by each employee, even if they have not made any sales. You can use a left join to link the \"employees\" and \"sales\" tables on the \"emp_no\" column:</p> <pre><code>SELECT e.emp_no, e.first_name, e.last_name, COUNT(s.sales_amount) as total_sales\nFROM employees e\nLEFT JOIN sales s ON e.emp_no = s.emp_no\nGROUP BY e.emp_no;\n</code></pre>"},{"location":"sql/17_joins/#right-join-example-1","title":"Right Join Example 1","text":"<p>Retrieving data that shows the name and department of each employee, even if the department has no employees assigned to it.</p> <pre><code>SELECT e.first_name, e.last_name, d.dept_name\nFROM dept_emp de\nRIGHT JOIN employees e ON de.emp_no = e.emp_no\nRIGHT JOIN departments d ON de.dept_no = d.dept_no;\n</code></pre>"},{"location":"sql/17_joins/#right-join-example-2","title":"Right Join Example 2","text":"<p>Retrieving data that shows the total number of sales made by each employee, even if they have not made any sales.</p> <pre><code>SELECT e.emp_no, e.first_name, e.last_name, COUNT(s.sales_amount) as total_sales\nFROM sales s\nRIGHT JOIN employees e ON s.emp_no = e.emp_no\nGROUP BY e.emp_no;\n</code></pre>"},{"location":"sql/18_Nested_Queries/","title":"Nested Queries","text":""},{"location":"sql/18_Nested_Queries/#introduction-to-nested-queries","title":"Introduction to Nested Queries","text":"<p>A nested query, also known as a subquery, is a query that is nested inside another query. A subquery can be used to retrieve data that will be used in the main query, allowing for complex queries that would be difficult to write using a single query. Subqueries can be used with various clauses in SQL, such as <code>SELECT</code>, <code>WHERE</code>, and <code>HAVING</code>.</p>"},{"location":"sql/18_Nested_Queries/#overview-of-how-to-use-subqueries","title":"Overview of How to Use Subqueries","text":"<p>A subquery is typically enclosed in parentheses and used in conjunction with an operator such as <code>IN</code>, <code>EXISTS</code>, or <code>=.</code> The subquery can be used in various parts of a query, depending on the desired result.</p> <p></p> <p>Here's an example of a subquery used in a <code>SELECT</code> statement:</p> <pre><code>SELECT first_name, last_name, birth_date\nFROM employees\nWHERE birth_date &gt; (SELECT birth_date FROM employees WHERE emp_no = 10001);\n</code></pre> <p>This query returns a result set that includes the first name, last name, and birth date for each employee whose birth date is later than that of the employee with <code>emp_no = 10001</code>. The subquery is used in the <code>WHERE</code> clause to retrieve the birth date of the employee with <code>emp_no = 10001</code>.</p> <p></p> <p>Here's an example of a subquery used in a <code>HAVING</code> clause:</p> <pre><code>SELECT departments.dept_name, AVG(salaries.salary) AS avg_salary\nFROM employees\nINNER JOIN dept_emp ON employees.emp_no = dept_emp.emp_no\nINNER JOIN departments ON dept_emp.dept_no = departments.dept_no\nINNER JOIN salaries ON employees.emp_no = salaries.emp_no\nGROUP BY departments.dept_name\nHAVING AVG(salaries.salary) &gt; (SELECT AVG(salary) FROM salaries);\n</code></pre> <p>This query joins the employees, salaries, dept_emp, and departments tables together based on the employee number, department number, and salary information. It then groups the results by department name using the <code>GROUP BY</code> clause and calculates the average salary for each department using the <code>AVG</code> function.</p> <p></p> <p>The <code>HAVING</code> clause is used to filter the results based on the condition that the average salary for a department is greater than the overall average salary of all employees, which is calculated using a subquery that selects the average salary from the salaries table.</p>"},{"location":"sql/18_Nested_Queries/#some-examples-with-mysql-employees-database","title":"Some examples with MySQL Employees database","text":""},{"location":"sql/18_Nested_Queries/#example-1-retrieving-data-for-employees-who-are-currently-managers","title":"Example 1: Retrieving data for employees who are currently managers","text":"<pre><code>SELECT first_name, last_name, hire_date\nFROM employees\nWHERE emp_no IN (\n    SELECT emp_no\n    FROM dept_manager\n);\n</code></pre> <p>This query returns a result set that includes the first name, last name, and hire date for each employee who is currently a manager. The subquery is used in the WHERE clause to retrieve the employee numbers of all employees who are currently department managers.</p>"},{"location":"sql/18_Nested_Queries/#example-2-retrieving-data-for-employees-who-were-hired-in-the-same-year-as-a-specific-employee","title":"Example 2: Retrieving data for employees who were hired in the same year as a specific employee","text":"<pre><code>SELECT first_name, last_name, hire_date\nFROM employees\nWHERE YEAR(hire_date) = (\n    SELECT YEAR(hire_date)\n    FROM employees\n    WHERE emp_no = 10001\n);\n</code></pre> <p>This query returns a result set that includes the first name, last name, and hire date for each employee who was hired in the same year as the employee with emp_no = 10001. The subquery is used in the WHERE clause to retrieve the year in which the employee with emp_no = 10001 was hired.</p>"},{"location":"sql/18_Nested_Queries/#example-3-find-the-10th-employee-with-the-highest-salary-along-with-their-job-title","title":"Example 3: Find the 10th employee with the highest salary, along with their job title","text":"<pre><code>SELECT employees.emp_no, employees.first_name, employees.last_name, MAX(salaries.salary) AS max_salary, MAX(titles.title) AS title\nFROM employees\nJOIN salaries ON employees.emp_no = salaries.emp_no\nJOIN titles ON employees.emp_no = titles.emp_no\nGROUP BY employees.emp_no\nORDER BY max_salary DESC\nLIMIT 10; \n</code></pre> <p>The query starts by selecting specific columns from the employees table, including the employee number, first name, and last name. It then joins the salaries and titles tables to the employees table based on the employee number, using the <code>JOIN</code> clause. The <code>MAX</code> function is used to find the maximum salary and job title for each employee.</p> <p></p> <p>The <code>GROUP BY</code> clause is used to group the results by employee number. This ensures that the maximum salary and job title returned for each employee correspond to the same person. The <code>ORDER BY</code> clause is used to sort the results in descending order based on the maximum salary, so that the employee with the highest salary is at the top.</p> <p></p> <p>Finally, the <code>LIMIT</code> clause is used to limit the results to only the top row, which corresponds to the employee with the highest salary.</p>"},{"location":"sql/19_delete/","title":"On delete","text":""},{"location":"sql/19_delete/#introduction-to-on-delete","title":"Introduction to ON DELETE","text":"<p><code>ON DELETE</code> is a referential action that can be applied to foreign key constraints in SQL. It specifies what should happen to data in the child table when a row is deleted from the parent table. The different options available for <code>ON DELETE</code> include <code>CASCADE</code>, <code>SET NULL</code>, <code>RESTRICT</code>, and <code>NO ACTION</code>. Using <code>ON DELETE</code> is important for maintaining data integrity in a database.</p>"},{"location":"sql/19_delete/#overview-of-how-to-use-on-delete","title":"Overview of How to Use ON DELETE","text":"<p>Here's an example of creating a foreign key with <code>ON DELETE CASCADE</code> in SQL:</p> <pre><code>ALTER TABLE employees\nADD CONSTRAINT emp_dept_fk\nFOREIGN KEY (dept_no)\nREFERENCES departments (dept_no)\nON DELETE CASCADE;\n</code></pre> <p>In this example, a foreign key constraint named \"emp_dept_fk\" is added to the \"employees\" table. The foreign key references the \"dept_no\" column in the \"departments\" table, and specifies \"ON DELETE CASCADE.\" This means that when a row is deleted from the \"departments\" table, any corresponding rows in the \"employees\" table will also be deleted.</p> <p></p> <p>Here's an example of creating a foreign key with \"ON DELETE SET NULL\" in SQL:</p> <pre><code>ALTER TABLE employees\nADD CONSTRAINT emp_manager_fk\nFOREIGN KEY (emp_no)\nREFERENCES employees (emp_no)\nON DELETE SET NULL;\n</code></pre> <p>In this example, a foreign key constraint named \"emp_manager_fk\" is added to the \"employees\" table. The foreign key references the \"emp_no\" column in the \"employees\" table, and specifies \"ON DELETE SET NULL.\" This means that when a row is deleted from the \"employees\" table, any corresponding rows in other tables will have the foreign key column value set to NULL.</p> <p></p> <p>Here's an example of creating a foreign key with \"ON DELETE RESTRICT\" in SQL:</p> <pre><code>ALTER TABLE departments\nADD CONSTRAINT dept_manager_fk\nFOREIGN KEY (emp_no)\nREFERENCES employees (emp_no)\nON DELETE RESTRICT;\n</code></pre> <p>In this example, a foreign key constraint named \"dept_manager_fk\" is added to the \"departments\" table. The foreign key references the \"emp_no\" column in the \"employees\" table, and specifies \"ON DELETE RESTRICT.\" This means that when a row is deleted from the \"employees\" table, any corresponding rows in the \"departments\" table cannot be deleted.</p> <p></p> <p>Here's an example of creating a foreign key with \"ON DELETE NO ACTION\" in SQL:</p> <pre><code>ALTER TABLE dept_emp\nADD CONSTRAINT dept_emp_fk\nFOREIGN KEY (emp_no)\nREFERENCES employees (emp_no)\nON DELETE NO ACTION;\n</code></pre> <p>In this example, a foreign key constraint named \"dept_emp_fk\" is added to the \"dept_emp\" table. The foreign key references the \"emp_no\" column in the \"employees\" table, and specifies \"ON DELETE NO ACTION.\" This means that when a row is deleted from the \"employees\" table, any corresponding rows in the \"dept_emp\" table will cause an error and the delete operation will be rejected.</p>"},{"location":"sql/19_delete/#conclusion","title":"Conclusion","text":"<p>Using \"ON DELETE\" in SQL is important for maintaining data integrity in a database. The different options available for \"ON DELETE\" include \"CASCADE,\" \"SET NULL,\" \"RESTRICT,\" and \"NO ACTION.\" By understanding how to use \"ON DELETE\" in SQL, you can ensure that your database remains consistent and accurate over time.</p>"},{"location":"sql/20_triggers/","title":"Triggers","text":""},{"location":"sql/20_triggers/#introduction-to-triggers-in-sql","title":"Introduction to Triggers in SQL","text":"<p>In SQL, a trigger is a special kind of stored program that is automatically executed in response to specific events or actions that occur within a database. Triggers can be used to automate tasks, maintain data integrity, and enforce business rules. They are often used in conjunction with other SQL features, such as constraints and indexes, to ensure that a database remains consistent and accurate over time.</p>"},{"location":"sql/20_triggers/#overview-of-how-to-use-triggers-to-automate-tasks","title":"Overview of How to Use Triggers to Automate Tasks","text":"<p>Here's an example of creating a trigger in SQL that automatically sets the \"to_date\" field of a row in the \"dept_emp\" table to the current date whenever a new row is inserted:</p> <pre><code>CREATE TRIGGER update_dept_emp_to_date\nBEFORE INSERT ON dept_emp\nFOR EACH ROW\nSET NEW.to_date = NOW();\n</code></pre> <p>In this example, a trigger named \"update_dept_emp_to_date\" is created using the CREATE TRIGGER statement. The trigger is defined to execute \"BEFORE INSERT\" on the \"dept_emp\" table, and is set to execute \"FOR EACH ROW\" that is inserted. The body of the trigger consists of a single statement that sets the value of the \"to_date\" field for the newly inserted row to the current date and time, using the NOW() function.</p> <p></p> <p>Here's an example of creating a trigger in SQL that prevents the deletion of a row in the \"employees\" table if that row is currently assigned to a department:</p> <pre><code>CREATE TRIGGER prevent_emp_delete\nBEFORE DELETE ON employees\nFOR EACH ROW\nBEGIN\n    DECLARE dept_count INT;\n    SELECT COUNT(*) INTO dept_count\n    FROM dept_emp\n    WHERE emp_no = OLD.emp_no;\n    IF dept_count &gt; 0 THEN\n        SIGNAL SQLSTATE '45000'\n            SET MESSAGE_TEXT = 'Cannot delete employee who is currently assigned to a department.';\n    END IF;\nEND;\n</code></pre> <p>In this example, a trigger named \"prevent_emp_delete\" is created using the CREATE TRIGGER statement. The trigger is defined to execute \"BEFORE DELETE\" on the \"employees\" table, and is set to execute \"FOR EACH ROW\" that is deleted. The body of the trigger consists of a block of code that checks whether the employee being deleted is currently assigned to a department, and if so, raises an error using the SIGNAL statement to prevent the delete operation.</p>"},{"location":"sql/20_triggers/#examples-of-using-triggers-on-the-employees-database","title":"Examples of using triggers on the employees database","text":""},{"location":"sql/20_triggers/#example-1-audit-trail-for-changes-to-the-employees-table","title":"Example 1: Audit trail for changes to the employees table","text":"<pre><code>CREATE TABLE employees_audit (\n    action VARCHAR(50) NOT NULL,\n    emp_no INT NOT NULL,\n    last_name VARCHAR(50) NOT NULL,\n    first_name VARCHAR(50) NOT NULL,\n    timestamp DATETIME DEFAULT NOW()\n);\n\nDELIMITER //\n\nCREATE TRIGGER employees_audit_insert\nAFTER INSERT ON employees\nFOR EACH ROW\nBEGIN\n    INSERT INTO employees_audit (action, emp_no, last_name, first_name)\n    VALUES ('insert', NEW.emp_no, NEW.last_name, NEW.first_name);\nEND//\n\nCREATE TRIGGER employees_audit_update\nAFTER UPDATE ON employees\nFOR EACH ROW\nBEGIN\n    INSERT INTO employees_audit (action, emp_no, last_name, first_name)\n    VALUES ('update', NEW.emp_no, NEW.last_name, NEW.first_name);\nEND//\n\nCREATE TRIGGER employees_audit_delete\nAFTER DELETE ON employees\nFOR EACH ROW\nBEGIN\n    INSERT INTO employees_audit (action, emp_no, last_name, first_name)\n    VALUES ('delete', OLD.emp_no, OLD.last_name, OLD.first_name);\nEND//\n\nDELIMITER ;\n</code></pre> <p>In this example, a new table \"employees_audit\" is created to store an audit trail of changes to the \"employees\" table. Three triggers are then defined using the CREATE TRIGGER statement to execute after each insert, update, and delete operation on the \"employees\" table. These triggers use the INSERT statement to add a new row to the \"employees_audit\" table that records the action, employee number, last name, first name, and timestamp of the change.</p>"},{"location":"sql/20_triggers/#example-2-preventing-changes-to-the-departments-table","title":"Example 2: Preventing changes to the departments table","text":"<pre><code>CREATE TRIGGER prevent_dept_change\nBEFORE UPDATE ON departments\nFOR EACH ROW\nBEGIN\n    SIGNAL SQLSTATE '45000'\n        SET MESSAGE_TEXT = 'Changes to departments table are not allowed.';\nEND;\n</code></pre> <p>In this example, a trigger named \"prevent_dept_change\" is defined using the CREATE TRIGGER statement to execute before any update operation on the \"departments\" table. The body of the trigger consists of a single statement that raises an error using the SIGNAL statement to prevent the update operation.</p>"},{"location":"sql/20_triggers/#example-3-automatic-promotion-to-manager-for-department-heads","title":"Example 3: Automatic promotion to manager for department heads","text":"<pre><code>CREATE TRIGGER promote_to_manager\nAFTER UPDATE ON dept_manager\nFOR EACH ROW\nBEGIN\n    IF NEW.to_date = '9999-01-01' THEN\n        UPDATE employees SET emp_title = 'Manager' WHERE emp_no = NEW.emp_no;\n    END IF;\nEND;\n</code></pre> <p>In this example, a trigger named \"promote_to_manager\" is defined using the CREATE TRIGGER statement to execute after any update operation on the \"dept_manager\" table. The body of the trigger consists of an IF statement that checks whether the \"to_date\" field for the updated row is set to the special value of '9999-01-01', which indicates that the employee is currently a department head. If so, the trigger uses the UPDATE statement to change the employee's title to \"Manager\" in the \"employees\" table.</p>"},{"location":"sql/20_triggers/#why-triggers-are-important-for-data-analysis-job","title":"Why triggers are important for data analysis job","text":"<p>Triggers are important in data analysis because they allow you to automate tasks and enforce data integrity rules within a database. By using triggers, you can ensure that data is consistent and accurate over time, and that business rules are enforced consistently across different operations and users.</p> <p></p> <p>For example, if you are analyzing sales data in a database, you might use triggers to automatically update certain fields or tables whenever new sales data is added or existing data is updated. You could also use triggers to prevent certain types of changes to the database, or to notify you when certain events occur.</p> <p></p> <p>By automating tasks and enforcing rules using triggers, you can save time and reduce the risk of errors or inconsistencies in your data. This can help you to make more informed decisions and gain deeper insights into the patterns and trends in your data.</p> <p></p> <p>Overall, triggers are an important tool for data analysts and other database professionals who need to ensure the accuracy and integrity of their data. By mastering the use of triggers in SQL, you can become more effective at managing and analyzing data in a wide range of contexts.</p>"},{"location":"sql/20_triggers/#conclusion","title":"Conclusion","text":"<p>Using triggers in SQL is a powerful way to automate tasks, maintain data integrity, and enforce business rules. Triggers can be used to respond to specific events or actions that occur within a database, and can be defined to execute before or after specific operations such as inserts, updates, and deletes. By understanding how to use triggers in SQL, you can ensure that your database remains consistent and accurate over time.</p>"},{"location":"sql/21_er_diagrams/","title":"ER Diagrams","text":""},{"location":"sql/21_er_diagrams/#explanation-of-er-diagrams-and-their-importance","title":"Explanation of ER Diagrams and their Importance","text":"<p>ER (Entity-Relationship) diagrams are a visual representation of the relationships between entities (tables) in a database. They are an important tool for designing and managing databases, as they provide a clear and concise way to understand how different tables are related to each other.</p> <p></p> <p>ER diagrams are used to model and plan database structures, to optimize data retrieval and to make queries more efficient. They are also used to help non-technical stakeholders understand the relationships between data tables, as they provide a simple and visual way to communicate complex data structures.</p>"},{"location":"sql/21_er_diagrams/#overview-of-how-to-use-er-diagrams-to-visualize-data","title":"Overview of How to Use ER Diagrams to Visualize Data","text":"<p>ER diagrams consist of entities (tables) and relationships (connections between tables), and are created using a set of symbols and rules. Entities are represented as rectangles, and relationships are represented as lines connecting the entities.</p> <p></p> <p>Here's an example of an ER diagram for our employees database: </p> <p></p> <p></p> <p>You can see the full documentation of the database on the official page here</p> <p></p> <p>In this diagram, the rectangles represent entities (tables), and the lines connecting the entities represent relationships between them. The relationships are labeled with the type of relationship (e.g. \"belongs to\", \"manages\", etc.), and with cardinality symbols that indicate the minimum and maximum number of instances of one entity that can be related to instances of the other entity.</p> <p></p> <p>ER diagrams can be used to model complex relationships between tables, including one-to-one, one-to-many, and many-to-many relationships. They can also be used to represent subtypes and supertypes, and to define constraints and business rules that govern the relationships between entities.</p> <p></p> <p>By using ER diagrams to visualize data, you can better understand the structure of your database and optimize your queries for maximum efficiency. ER diagrams can also be used to communicate complex data structures to non-technical stakeholders, helping to ensure that everyone involved in your data analysis projects has a common understanding of the data structures and relationships at play.</p>"},{"location":"sql/21_er_diagrams/#in-depth-look-at-how-to-design-an-er-diagram","title":"In-depth Look at How to Design an ER Diagram","text":"<p>The process of designing an ER (Entity-Relationship) diagram involves identifying the entities (tables) that will be included in the database, and determining the relationships between them. This process is crucial for building a database that is efficient, accurate, and easy to work with.</p> <p></p> <p>Here are the steps involved in designing an ER diagram:</p> <ul> <li>Identify the entities: Start by identifying the different entities (tables) that will be included in the database. These might include things like customers, products, orders, and so on.</li> <li>Determine the attributes: For each entity, determine the attributes (columns) that will be included in the table. These might include things like names, addresses, dates, and so on.</li> <li>Determine the relationships: Once you have identified the entities and their attributes, determine the relationships between them. For example, a customer might place many orders, or an order might contain many products.</li> <li>Choose the cardinality: For each relationship, determine the cardinality, or how many instances of one entity can be related to instances of another entity. This might be one-to-one, one-to-many, or many-to-many.</li> <li>Choose the modality: For each relationship, determine the modality, or whether the relationship is mandatory or optional. This might be represented using symbols such as \"1\" for mandatory or \"0\" for optional.</li> <li>Create the ER diagram: Finally, create the ER diagram using symbols and conventions that represent the entities, attributes, and relationships. These might include rectangles for entities, diamonds for relationships, and lines connecting them.</li> </ul>"},{"location":"sql/21_er_diagrams/#explanation-of-different-entities-attributes-and-relationships","title":"Explanation of Different Entities, Attributes, and Relationships","text":"<p>In ER diagrams, entities are represented as rectangles, attributes are represented as ovals, and relationships are represented as diamonds. Here's a brief explanation of each:</p> <ul> <li>Entities: Entities represent tables in the database. Each entity has a name and a set of attributes that define the data it contains.</li> <li>Attributes: Attributes represent the columns within an entity. They define the specific data that the entity contains, such as names, addresses, and dates.</li> <li>Relationships: Relationships represent the connections between entities. They define how different entities are related to each other, and the cardinality and modality of the relationship.</li> </ul>"},{"location":"sql/21_er_diagrams/#some-common-types-of-relationships-that-you-might-encounter-in-er-diagrams-include","title":"Some common types of relationships that you might encounter in ER diagrams include:","text":"<ul> <li>One-to-one: One instance of an entity is related to only one instance of another entity.</li> <li>One-to-many: One instance of an entity is related to multiple instances of another entity.</li> <li>Many-to-many: Multiple instances of an entity are related to multiple instances of another entity.</li> </ul> <p>By understanding the different entities, attributes, and relationships involved in an ER diagram, you can design a database that is efficient, accurate, and easy to work with. This can help you to analyze and manage your data more effectively, and to gain deeper insights into the patterns and trends in your data.</p>"},{"location":"sql/21_er_diagrams/#explanation-of-how-to-convert-er-diagrams-to-database-schemas","title":"Explanation of How to Convert ER Diagrams to Database Schemas","text":"<p>Once you have designed an ER (Entity-Relationship) diagram for your database, the next step is to convert it into a database schema. This involves creating tables and relationships that reflect the structure and relationships defined in the ER diagram.</p> <p></p> <p>Here are the steps involved in converting an ER diagram to a database schema:</p> <ul> <li>Identify the tables: Start by identifying the tables that will be created based on the entities in the ER diagram. For example, if the ER diagram has an entity called \"Employees\", create a table called \"Employees\" in the database.</li> <li>Create the columns: For each table, create the columns that reflect the attributes of the entity in the ER diagram. For example, if the \"Employees\" entity has attributes such as \"Employee Number\", \"First Name\", and \"Last Name\", create columns in the \"Employees\" table with these same names and data types.</li> <li>Define the relationships: Once the tables and columns are created, define the relationships between the tables based on the relationships in the ER diagram. For example, if the \"Employees\" entity is related to the \"Departments\" entity in the ER diagram, create a foreign key column in the \"Employees\" table that references the primary key column in the \"Departments\" table.</li> <li>Specify the constraints: Finally, specify any constraints or rules that are defined in the ER diagram, such as unique constraints or not-null constraints.</li> <li>Overview of How to Create Tables and Relationships Based on the ER Diagram</li> </ul>"},{"location":"sql/21_er_diagrams/#example-of-how-to-convert-the-er-diagram-for-the-employees-database-into-a-database-schema","title":"Example of how to convert the ER diagram for the Employees database into a database schema:","text":"<ul> <li>Identify the tables: Based on the ER diagram, we need to create tables for employees, departments, titles, salaries, and more.</li> <li>Create the columns: For the \"Employees\" table, we need to create columns such as \"emp_no\", \"birth_date\", \"first_name\", \"last_name\", \"gender\", and \"hire_date\". For the \"Departments\" table, we need to create columns such as \"dept_no\" and \"dept_name\". For the other tables, we would create columns based on the attributes defined in the ER diagram.</li> <li>Define the relationships: Based on the ER diagram, we know that employees are related to departments, titles, and salaries. To define these relationships, we would create foreign key columns in the \"Employees\" table that reference the primary key columns in the other tables. For example, the \"Employees\" table would have a foreign key column called \"dept_no\" that references the \"dept_no\" column in the \"Departments\" table.</li> <li>Specify the constraints: We would specify any constraints or rules that are defined in the ER diagram, such as unique constraints or not-null constraints. For example, we might specify that the \"emp_no\" column in the \"Employees\" table must be unique and not-null.</li> </ul> <p>By converting the ER diagram to a database schema in this way, we can create a database that accurately reflects the structure and relationships defined in the ER diagram. This can help us to manage and analyze data more effectively, and to gain deeper insights into the patterns and trends in our data.</p>"},{"location":"sql/21_er_diagrams/#wrap-up","title":"Wrap-up","text":"<p>Let's summarize what we've learn about ER diagrams : </p> <ul> <li>ER diagrams, or Entity-Relationship diagrams, are visual representations of data models that show the relationships between different entities, such as tables in a database.</li> <li>ER diagrams help to simplify complex data structures and make them easier to understand by providing a high-level view of the data and its relationships.</li> <li>ER diagrams can help companies to design more effective databases by providing a clear picture of how data is structured and related, and can help to identify areas for optimization or improvement.</li> <li>ER diagrams are important in the development process of software and databases, as they provide a blueprint for developers to follow when building and maintaining data systems.</li> <li>ER diagrams can be used to facilitate communication between stakeholders, such as developers, designers, project managers, and business users, by providing a common language and visual reference point for discussing the data model.</li> <li>By using ER diagrams to design and maintain their data models, companies can improve the accuracy, efficiency, and reliability of their data systems, which in turn can lead to better decision-making, cost savings, and increased competitiveness in the marketplace.</li> </ul>"},{"location":"sql/29_python_docker_sql/","title":"SQLAlchemy and docker","text":"<p>In this section we will be working with docker.  </p> <p>Do we actually need docker to our journey to SQLAlchemy ? No. The only reason we choose to use Docker, is because, it is fast to setup, secure and lightweight. </p> <p>Docker provides platform which helps us deliver software packages in containers. The software package we need from docker is a database, postgres to be precise.</p> <p>Installing docker is simple, see the installation section if you don't have it installed. For the next part, we will assume you've already installed docker. </p>"},{"location":"sql/29_python_docker_sql/#add-an-existing-sql-database-into-a-container","title":"Add an existing SQL database into a container","text":"<p>In this section we will be looking at an existing database and put it into a docker container in order to query this database with a python script. </p> <p>Here's an example database let's call this script <code>init.sql</code>: </p> <p>```sql title=\"init.sql\" CREATE DATABASE testdb; USE testdb;</p> <p>CREATE TABLE users (   id INT NOT NULL AUTO_INCREMENT,   name VARCHAR(50) NOT NULL,   email VARCHAR(50) NOT NULL,   PRIMARY KEY (id) );</p> <p>INSERT INTO users (name, email) VALUES   ('John Doe', 'johndoe@example.com'),   ('Jane Doe', 'janedoe@example.com'),   ('Bob Smith', 'bobsmith@example.com');</p> <p>GRANT ALL PRIVILEGES ON testdb.* TO 'user'@'%' IDENTIFIED BY 'user-password' WITH GRANT OPTION; FLUSH PRIVILEGES;</p> <pre><code>\nThis SQL script is used to create a new database called `testdb`, create a table called `users` with three columns `id`, `name`, and `email`, insert three records into the users table, and grant privileges to a user to access the testdb database.\n\n### What is grant privileges \n\nThe `GRANT ALL PRIVILEGES` command is used in MySQL to grant a user all possible privileges on a database or a specific table within a database. This command allows the user to perform any action on the specified database or table, including creating, modifying, and deleting data.\n\nHere's a breakdown of the syntax of the `GRANT ALL PRIVILEGES` command:\n```sql \nGRANT ALL PRIVILEGES ON database_name.* TO 'username'@'localhost' IDENTIFIED BY 'password';\nFLUSH PRIVILEGES;\n</code></pre> <ul> <li><code>GRANT ALL PRIVILEGES</code> : This command grants all possible privileges to the user.</li> <li><code>ON database_name.*</code> : This specifies the database and any tables within it that the user will have privileges on. The * wildcard character specifies all tables within the database.</li> <li><code>TO 'username'@'localhost'</code> : This specifies the username and the host from which the user can connect to the database.</li> <li><code>IDENTIFIED BY 'password'</code> : This specifies the password for the user.</li> <li><code>FLUSH PRIVILEGES</code> : This line reloads the grant tables in the mysql database to apply the changes made by the GRANT command.</li> </ul> <p>The <code>GRANT ALL PRIVILEGES</code> command is a powerful command that should be used with caution. It is recommended to only grant the necessary privileges to users to minimize the risk of data loss or security breaches.</p> <p>In our case this database is created in order to be connected by a python script and for that we must have a user, is it not recommended to connect the database as root user.</p>"},{"location":"sql/29_python_docker_sql/#write-a-dockerfile-with-initsql-file","title":"Write a Dockerfile with <code>init.sql</code> file","text":"<p>Let's write a <code>Dockerfile</code> for our sql container : </p> <pre><code>FROM mysql:5.6\n\n# set root password\nENV MYSQL_ROOT_PASSWORD=my-secret-pw\n\n# create database and table\nCOPY init.sql /docker-entrypoint-initdb.d/\n\n# add a new user\nENV MYSQL_USER=user\nENV MYSQL_PASSWORD=user-password\n\nEXPOSE 3306\n</code></pre> <p>As you know in a <code>Dockerfile</code>, the <code>COPY</code> command is used to copy files or directories from the host machine into the Docker container.</p> <p>In the context of our <code>Dockerfile</code>, the line  </p> <pre><code>COPY init.sql /docker-entrypoint-initdb.d/ \n</code></pre> <p>copies the <code>init.sql</code> file from the host machine into the <code>/docker-entrypoint-initdb.d/</code> directory within the Docker container.</p> <p>The <code>/docker-entrypoint-initdb.d/</code> directory is a default directory that is used by the mysql Docker image to automatically execute any SQL scripts that are located in this directory when the container is started up.</p> <p>By copying the <code>init.sql</code> file into the <code>/docker-entrypoint-initdb.d/</code> directory within the Docker container, you are instructing the mysql image to automatically execute this script when the container starts up. This allows you to automatically create our database, tables, and insert data into the database without having to manually execute SQL commands every time the container is started up.</p>"},{"location":"sql/29_python_docker_sql/#run-our-mysql-container","title":"Run our MySQL container","text":"<p>To build our custom MySQL image, you can run the following command in the directory containing the Dockerfile and <code>init.sql</code> script:</p>"},{"location":"sql/29_python_docker_sql/#build-the-image","title":"Build the image","text":"<pre><code>docker build -t my-mysql-image .\n</code></pre> <p>This command will build the Docker image using the Dockerfile in the current directory and tag it as <code>my-mysql-image:latest</code>.</p>"},{"location":"sql/29_python_docker_sql/#start-the-container","title":"Start the container","text":"<p>Once the image is built, you can start a new container using the following command:</p> <pre><code>docker run --name mysql-container -d -p 3306:3306 my-mysql-image\n</code></pre> <p>This command will start a new container (named <code>mysql-container</code>) using the custom MySQL image, now we can connect to our container in order to verify if all the options are passed. </p>"},{"location":"sql/29_python_docker_sql/#connect-to-our-container","title":"Connect to our container","text":"<p>Go to your terminal and run this command in order to enter into the container : </p> <pre><code>docker exec -it mysql-container /bin/bash\n</code></pre> <p>or the equivalent comnmand : </p> <pre><code>docker exec -it &lt;your-container-id&gt; /bin/bash\n</code></pre> <p>Now that you are in the container we can access the MySQL CLI with the following command : </p> <pre><code>mysql -uuser -puser-password\n</code></pre> <p>You should see the following prompt </p> <pre><code>mysql&gt;\n</code></pre> <p>It means that you're currently in the MySQL Shell of the container. You can now view our <code>testdb</code> and <code>users</code> table with the command : </p> <pre><code>mysql&gt; show databases; \n</code></pre> <p>you should see this output : </p> <pre><code>+--------------------+\n| Database           |\n+--------------------+\n| information_schema |\n| testdb             |\n+--------------------+\n2 rows in set (0.00 sec)\n</code></pre> <p>It means our <code>user</code> is able to see our database, you can also do a test query in order to verify the integrity of our database. In this section we have seen how to build a custom MySQL container with a database in it and how to access this database with the docker CLI \ud83d\ude80</p>"},{"location":"sql/29_python_docker_sql/#query-a-docker-mysql-container-with-a-python-script","title":"Query a docker MySQL container with a python script","text":"<p>Now, let's write a python script <code>connect_db.py</code> to connect our database \ud83e\udd73</p> <p>```python title=\"connect_db.py\" from sqlalchemy import create_engine, MetaData, Table</p>"},{"location":"sql/29_python_docker_sql/#create-engine-to-connect-to-mysql","title":"create engine to connect to MySQL","text":"<p>engine = create_engine('mysql://user:user-password@0.0.0.0:3306/testdb')</p>"},{"location":"sql/29_python_docker_sql/#create-metadata-object","title":"create metadata object","text":"<p>metadata = MetaData()</p>"},{"location":"sql/29_python_docker_sql/#reflect-the-users-table","title":"reflect the users table","text":"<p>users_table = Table('users', metadata, autoload=True, autoload_with=engine)</p>"},{"location":"sql/29_python_docker_sql/#select-all-rows-from-the-users-table","title":"select all rows from the users table","text":"<p>select_query = users_table.select()</p>"},{"location":"sql/29_python_docker_sql/#execute-the-query","title":"execute the query","text":"<p>with engine.connect() as conn:     result = conn.execute(select_query)     for row in result:         print(row)</p> <pre><code>\nLet's break down the different parts of the script:\n\n- `create_engine('mysql://root:my-secret-pw@0.0.0.0:3306/testdb')`: This creates a SQLAlchemy engine that connects to the MySQL database running in the Docker container. The username is \"root\", the password is \"my-secret-pw\", the host is \"localhost\", the port is \"3306\", and the database name is \"testdb\".\n- `metadata = MetaData()` : This creates a metadata object that will be used to reflect the database schema.\n- `users_table = Table('users', metadata, autoload=True, autoload_with=engine)` : This reflects the \"users\" table from the database using the metadata object.\n- `select_query = users_table.select()` : This creates a query that selects all rows from the \"users\" table.\n- `with engine.connect() as conn` : result = conn.execute(select_query): This creates a connection to the database using the engine, executes the select query, and stores the result in a variable.\n- `for row in result: print(row)` : This loops through the result set and prints each row.\n\nThis script assumes that you have the necessary dependencies installed, including SQLAlchemy and the MySQL driver for Python. You can install these dependencies using `pip`:\n```bash\npip install sqlalchemy pymysql\n</code></pre> <p>Note that the driver used to connect to the MySQL database is \"pymysql\", which is a Python MySQL client library that works with SQLAlchemy.</p> <p>If you execute this script, you should see this output : </p> <pre><code>(1, 'John Doe', 'johndoe@example.com')\n(2, 'Jane Doe', 'janedoe@example.com')\n(3, 'Bob Smith', 'bobsmith@example.com')\n</code></pre>"},{"location":"sql/29_python_docker_sql/#next-steps","title":"Next steps","text":"<p>In this section we covered a pretty simple database and python script so for the next steps if you want to upgrade this project you can consider : </p> <ul> <li>Add FastAPI CRUD endpoints to interact with the database </li> <li>Add a better database and <code>init.sql</code> script </li> <li>Wrap-up the project with a <code>docker-compose.yml</code> file </li> <li>Code a dashboard route in FastAPI in order to visualize some data of your database </li> <li>Be creative \ud83d\ude03</li> </ul>"},{"location":"sql/29_python_docker_sql/#wrap-up","title":"Wrap-up","text":"<p>Let's summarize whant we have seen in this section :</p> <ul> <li>Docker provides a consistent and portable environment for running applications, including databases like MySQL.</li> <li>We can use Docker to run a MySQL database in a container by pulling the mysql image and specifying the appropriate environment variables and port mappings.</li> <li>We can use the mysql-connector-python library in Python to connect to a MySQL database and perform SQL queries.</li> <li>We can create a SQL script to create tables and insert data into the MySQL database, and include this script in the Docker image to automatically execute it when the container starts up.</li> <li>We have learned how to write a Dockerfile to define the configuration of a Docker container, and how to use it to build a Docker image.</li> <li>Overall, connecting Docker MySQL and Python provides a more efficient and reliable way to manage and run databases and applications, and reduces the complexity and time involved in setting up and maintaining software installations.</li> </ul>"}]}